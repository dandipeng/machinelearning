{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "%matplotlib inline    \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein = pd.read_csv('yeast.data.txt', header =None, sep = \"\\s+\",\n",
    "                     names = [\"sequence\", \"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\",\n",
    "                      \"pox\", \"vac\", \"nuc\", \"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>mcg</th>\n",
       "      <th>gvh</th>\n",
       "      <th>alm</th>\n",
       "      <th>mit</th>\n",
       "      <th>erl</th>\n",
       "      <th>pox</th>\n",
       "      <th>vac</th>\n",
       "      <th>nuc</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADT1_YEAST</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADT2_YEAST</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADT3_YEAST</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAR2_YEAST</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.22</td>\n",
       "      <td>NUC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AATM_YEAST</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sequence   mcg   gvh   alm   mit  erl  pox   vac   nuc class\n",
       "0  ADT1_YEAST  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22   MIT\n",
       "1  ADT2_YEAST  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22   MIT\n",
       "2  ADT3_YEAST  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22   MIT\n",
       "3  AAR2_YEAST  0.58  0.44  0.57  0.13  0.5  0.0  0.54  0.22   NUC\n",
       "4  AATM_YEAST  0.42  0.44  0.48  0.54  0.5  0.0  0.48  0.22   MIT"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1484, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "CYT    463\n",
       "ERL      5\n",
       "EXC     35\n",
       "ME1     44\n",
       "ME2     51\n",
       "ME3    163\n",
       "MIT    244\n",
       "NUC    429\n",
       "POX     20\n",
       "VAC     30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein.groupby(['class']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Outlier detection algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By One-Class SVM, there are 216 outliers.\n",
      "By Isolation Forest, there are 149 outliers.\n",
      "By Local Outlier Factor, there are 149 outliers.\n"
     ]
    }
   ],
   "source": [
    "outliers_fraction = 0.1\n",
    "classifiers = [\n",
    "    (\"One-Class SVM\", svm.OneClassSVM(nu=0.95 * outliers_fraction + 0.05, kernel=\"rbf\")),\n",
    "    (\"Isolation Forest\", IsolationForest(max_samples=len(protein.index),\n",
    "                                        contamination=outliers_fraction)),\n",
    "    (\"Local Outlier Factor\", LocalOutlierFactor(n_neighbors=5,\n",
    "                                               algorithm = 'auto',\n",
    "                                               contamination = outliers_fraction))]\n",
    "\n",
    "X = protein[protein.columns.difference(['sequence','class'])]\n",
    "y = protein.loc[:, 'class']\n",
    "\n",
    "# try different outlier detection algorithms (oda)\n",
    "for oda_name, oda in classifiers:\n",
    "    # fit the data and tag outliers\n",
    "    if oda_name == \"Local Outlier Factor\":\n",
    "        y_pred = oda.fit_predict(X)\n",
    "        scores_pred = oda.negative_outlier_factor_\n",
    "    else:\n",
    "        oda.fit(X)\n",
    "        scores_pred = oda.decision_function(X)\n",
    "        y_pred = oda.predict(X)\n",
    "    threshold = stats.scoreatpercentile(scores_pred,\n",
    "                                        100 * outliers_fraction)\n",
    "    n_errors = y_pred[y_pred == -1].size\n",
    "    print(\"By \"+oda_name+\", there are \"+str(n_errors)+\" outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(a)__ From the above output, first, as the real data set shows, one class `ERL` only has 5 samples, therefore, I set the n_neighbors = 5 when applying _LoF*_method, and all methods show that there are outliers.\n",
    "\n",
    "__(b)__ Three of four methods show that there are **149** outliers. They are  _LOF_ and _Isolation Forest_.\n",
    "\n",
    "__(c)__ By checking the dataset aside of outliers selected through different methods, the _LOF_ keeps the `ERL` class. Thus, I used _LOF_ to remove outliers as the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1335, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove 149 outliers\n",
    "protein_new = protein[y_pred != -1].reset_index(drop=True)\n",
    "protein_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "CYT    425\n",
       "ERL      5\n",
       "EXC     33\n",
       "ME1     38\n",
       "ME2     38\n",
       "ME3    151\n",
       "MIT    219\n",
       "NUC    379\n",
       "POX     19\n",
       "VAC     28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_new.groupby(['class']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training and Test set split\n",
    "Split the data into training set(200/392) and testing set(192/392)\n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "LE = LabelEncoder()\n",
    "protein_new['y'] = LE.fit_transform(protein_new['class'])\n",
    "\n",
    "train, test = train_test_split(protein_new, test_size = 0.3, random_state = 1)\n",
    "\n",
    "## get the train and test data set\n",
    "X_tr = train[train.columns.difference(['sequence','class','y'])]\n",
    "y_tr = train.loc[:, 'y']\n",
    "\n",
    "X_te = test[test.columns.difference(['sequence','class','y'])]\n",
    "y_te = test.loc[:, 'y']\n",
    "\n",
    "## get the train and test data set for \"CYT\"\n",
    "cyt_x_tr = X_tr.loc[train['class'] == \"CYT\"]\n",
    "cyt_x_te = X_te.loc[test['class'] == \"CYT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_tr = sc.fit_transform(X_tr)\n",
    "X_te = sc.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder()\n",
    "y_tr_class = onehotencoder.fit_transform(np.array([y_tr]).T).toarray()\n",
    "y_te_class = onehotencoder.fit_transform(np.array([y_te]).T).toarray()\n",
    "\n",
    "cyt_y_tr_class = y_tr_class[train['class'] == \"CYT\"]\n",
    "cyt_y_te_class = y_te_class[test['class'] == \"CYT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import LambdaCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 3)                 27        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                40        \n",
      "=================================================================\n",
      "Total params: 79\n",
      "Trainable params: 79\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, input_dim= X_tr.shape[1], kernel_initializer='random_uniform',\n",
    "                bias_initializer='random_uniform',activation='sigmoid'))\n",
    "model.add(Dense(3, activation = \"sigmoid\"))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 401 samples\n",
      "Epoch 1/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.8868 - acc: 0.2623 - val_loss: 1.7298 - val_acc: 0.3292 0s - loss: 1.9139 - acc: 0.25\n",
      "293/293 [==============================] - 0s 32us/step\n",
      "132/132 [==============================] - 0s 57us/step\n",
      "Epoch 2/500\n",
      "934/934 [==============================] - 1s 826us/step - loss: 1.7336 - acc: 0.3084 - val_loss: 1.7011 - val_acc: 0.3292\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 40us/step\n",
      "Epoch 3/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7144 - acc: 0.2998 - val_loss: 1.6816 - val_acc: 0.3292\n",
      "293/293 [==============================] - 0s 32us/step\n",
      "132/132 [==============================] - 0s 51us/step\n",
      "Epoch 4/500\n",
      "934/934 [==============================] - 1s 902us/step - loss: 1.6960 - acc: 0.3073 - val_loss: 1.6654 - val_acc: 0.2768\n",
      "293/293 [==============================] - 0s 24us/step\n",
      "132/132 [==============================] - 0s 39us/step\n",
      "Epoch 5/500\n",
      "934/934 [==============================] - 1s 853us/step - loss: 1.6768 - acc: 0.3051 - val_loss: 1.6491 - val_acc: 0.2793\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 51us/step\n",
      "Epoch 6/500\n",
      "934/934 [==============================] - 1s 944us/step - loss: 1.6556 - acc: 0.2966 - val_loss: 1.6222 - val_acc: 0.3292\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 7/500\n",
      "934/934 [==============================] - 1s 826us/step - loss: 1.6309 - acc: 0.3051 - val_loss: 1.5927 - val_acc: 0.3292\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 8/500\n",
      "934/934 [==============================] - 1s 815us/step - loss: 1.5999 - acc: 0.3244 - val_loss: 1.5762 - val_acc: 0.2993\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 50us/step\n",
      "Epoch 9/500\n",
      "934/934 [==============================] - 1s 812us/step - loss: 1.5726 - acc: 0.3191 - val_loss: 1.5372 - val_acc: 0.3067\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 49us/step\n",
      "Epoch 10/500\n",
      "934/934 [==============================] - 1s 820us/step - loss: 1.5396 - acc: 0.3480 - val_loss: 1.5034 - val_acc: 0.3566\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 11/500\n",
      "934/934 [==============================] - 1s 825us/step - loss: 1.5150 - acc: 0.3576 - val_loss: 1.4810 - val_acc: 0.4015\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 42us/step\n",
      "Epoch 12/500\n",
      "934/934 [==============================] - 1s 938us/step - loss: 1.4913 - acc: 0.3887 - val_loss: 1.4689 - val_acc: 0.3716\n",
      "293/293 [==============================] - 0s 14us/step\n",
      "132/132 [==============================] - 0s 46us/step\n",
      "Epoch 13/500\n",
      "934/934 [==============================] - 1s 835us/step - loss: 1.4736 - acc: 0.3801 - val_loss: 1.4505 - val_acc: 0.4040\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 44us/step\n",
      "Epoch 14/500\n",
      "934/934 [==============================] - 1s 821us/step - loss: 1.4598 - acc: 0.3919 - val_loss: 1.4374 - val_acc: 0.4140\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 46us/step\n",
      "Epoch 15/500\n",
      "934/934 [==============================] - 1s 855us/step - loss: 1.4484 - acc: 0.3983 - val_loss: 1.4383 - val_acc: 0.3666\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 47us/step\n",
      "Epoch 16/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4396 - acc: 0.4154 - val_loss: 1.4245 - val_acc: 0.4115\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 63us/step\n",
      "Epoch 17/500\n",
      "934/934 [==============================] - 1s 908us/step - loss: 1.4327 - acc: 0.4186 - val_loss: 1.4168 - val_acc: 0.4364\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 60us/step\n",
      "Epoch 18/500\n",
      "934/934 [==============================] - 1s 860us/step - loss: 1.4262 - acc: 0.4143 - val_loss: 1.4107 - val_acc: 0.4165\n",
      "293/293 [==============================] - 0s 14us/step\n",
      "132/132 [==============================] - 0s 44us/step\n",
      "Epoch 19/500\n",
      "934/934 [==============================] - 1s 799us/step - loss: 1.4207 - acc: 0.3983 - val_loss: 1.4083 - val_acc: 0.4015\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 20/500\n",
      "934/934 [==============================] - 1s 815us/step - loss: 1.4139 - acc: 0.3961 - val_loss: 1.4020 - val_acc: 0.4289\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 21/500\n",
      "934/934 [==============================] - 1s 805us/step - loss: 1.4100 - acc: 0.4315 - val_loss: 1.3975 - val_acc: 0.4364\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 59us/step\n",
      "Epoch 22/500\n",
      "934/934 [==============================] - 1s 825us/step - loss: 1.4028 - acc: 0.4304 - val_loss: 1.3949 - val_acc: 0.4414\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 23/500\n",
      "934/934 [==============================] - 1s 814us/step - loss: 1.3977 - acc: 0.4347 - val_loss: 1.3900 - val_acc: 0.4165\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 40us/step\n",
      "Epoch 24/500\n",
      "934/934 [==============================] - 1s 794us/step - loss: 1.3901 - acc: 0.4604 - val_loss: 1.3813 - val_acc: 0.4489\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 50us/step\n",
      "Epoch 25/500\n",
      "934/934 [==============================] - 1s 822us/step - loss: 1.3862 - acc: 0.4390 - val_loss: 1.3764 - val_acc: 0.4663\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 26/500\n",
      "934/934 [==============================] - 1s 826us/step - loss: 1.3795 - acc: 0.4540 - val_loss: 1.3717 - val_acc: 0.4339\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 39us/step\n",
      "Epoch 27/500\n",
      "934/934 [==============================] - 1s 794us/step - loss: 1.3726 - acc: 0.4518 - val_loss: 1.3639 - val_acc: 0.4589\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 28/500\n",
      "934/934 [==============================] - 1s 817us/step - loss: 1.3670 - acc: 0.4561 - val_loss: 1.3611 - val_acc: 0.4040\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 42us/step\n",
      "Epoch 29/500\n",
      "934/934 [==============================] - 1s 804us/step - loss: 1.3611 - acc: 0.4454 - val_loss: 1.3553 - val_acc: 0.4190\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 30/500\n",
      "934/934 [==============================] - 1s 814us/step - loss: 1.3541 - acc: 0.4657 - val_loss: 1.3444 - val_acc: 0.4763\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 31/500\n",
      "934/934 [==============================] - 1s 809us/step - loss: 1.3469 - acc: 0.4764 - val_loss: 1.3381 - val_acc: 0.4838\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 56us/step\n",
      "Epoch 32/500\n",
      "934/934 [==============================] - 1s 786us/step - loss: 1.3409 - acc: 0.4615 - val_loss: 1.3277 - val_acc: 0.4863\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 40us/step\n",
      "Epoch 33/500\n",
      "934/934 [==============================] - 1s 779us/step - loss: 1.3357 - acc: 0.4722 - val_loss: 1.3277 - val_acc: 0.4464\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 34/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.3302 - acc: 0.4647 - val_loss: 1.3211 - val_acc: 0.4439\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 35/500\n",
      "934/934 [==============================] - 1s 750us/step - loss: 1.3223 - acc: 0.4700 - val_loss: 1.3070 - val_acc: 0.5237\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 36/500\n",
      "934/934 [==============================] - 1s 764us/step - loss: 1.3177 - acc: 0.4679 - val_loss: 1.3012 - val_acc: 0.4663\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 37/500\n",
      "934/934 [==============================] - 1s 756us/step - loss: 1.3102 - acc: 0.4775 - val_loss: 1.2990 - val_acc: 0.4589\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 38/500\n",
      "934/934 [==============================] - 1s 761us/step - loss: 1.3047 - acc: 0.4936 - val_loss: 1.2883 - val_acc: 0.4963\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 39/500\n",
      "934/934 [==============================] - 1s 761us/step - loss: 1.2972 - acc: 0.4829 - val_loss: 1.2834 - val_acc: 0.4613\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 40/500\n",
      "934/934 [==============================] - 1s 750us/step - loss: 1.2927 - acc: 0.4818 - val_loss: 1.2788 - val_acc: 0.4663\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 41/500\n",
      "934/934 [==============================] - 1s 766us/step - loss: 1.2858 - acc: 0.4818 - val_loss: 1.2681 - val_acc: 0.4888\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 42/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.2806 - acc: 0.5054 - val_loss: 1.2646 - val_acc: 0.5062\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 39us/step\n",
      "Epoch 43/500\n",
      "934/934 [==============================] - 1s 748us/step - loss: 1.2753 - acc: 0.4979 - val_loss: 1.2585 - val_acc: 0.5112\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 44/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.2703 - acc: 0.4979 - val_loss: 1.2556 - val_acc: 0.4638\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 45/500\n",
      "934/934 [==============================] - 1s 771us/step - loss: 1.2631 - acc: 0.4979 - val_loss: 1.2498 - val_acc: 0.4838\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 46/500\n",
      "934/934 [==============================] - 1s 753us/step - loss: 1.2595 - acc: 0.5054 - val_loss: 1.2477 - val_acc: 0.5262\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 47/500\n",
      "934/934 [==============================] - 1s 756us/step - loss: 1.2535 - acc: 0.5075 - val_loss: 1.2442 - val_acc: 0.5087\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 48/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.2471 - acc: 0.4979 - val_loss: 1.2355 - val_acc: 0.5112\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 49/500\n",
      "934/934 [==============================] - 1s 756us/step - loss: 1.2444 - acc: 0.5128 - val_loss: 1.2326 - val_acc: 0.5087\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 50/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.2386 - acc: 0.5150 - val_loss: 1.2280 - val_acc: 0.5087\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 51/500\n",
      "934/934 [==============================] - 1s 773us/step - loss: 1.2350 - acc: 0.5107 - val_loss: 1.2275 - val_acc: 0.5087\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 52/500\n",
      "934/934 [==============================] - 1s 924us/step - loss: 1.2297 - acc: 0.5128 - val_loss: 1.2230 - val_acc: 0.4963\n",
      "293/293 [==============================] - 0s 28us/step\n",
      "132/132 [==============================] - 0s 42us/step\n",
      "Epoch 53/500\n",
      "934/934 [==============================] - 1s 824us/step - loss: 1.2257 - acc: 0.5107 - val_loss: 1.2205 - val_acc: 0.4963\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 54/500\n",
      "934/934 [==============================] - 1s 828us/step - loss: 1.2224 - acc: 0.5021 - val_loss: 1.2204 - val_acc: 0.5112\n",
      "293/293 [==============================] - 0s 25us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 55/500\n",
      "934/934 [==============================] - 1s 770us/step - loss: 1.2179 - acc: 0.5011 - val_loss: 1.2170 - val_acc: 0.4863\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 56/500\n",
      "934/934 [==============================] - 1s 760us/step - loss: 1.2148 - acc: 0.4989 - val_loss: 1.2146 - val_acc: 0.5262\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 57/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.2113 - acc: 0.5128 - val_loss: 1.2211 - val_acc: 0.4913\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 58/500\n",
      "934/934 [==============================] - 1s 769us/step - loss: 1.2089 - acc: 0.5150 - val_loss: 1.2087 - val_acc: 0.5062\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 59/500\n",
      "934/934 [==============================] - 1s 758us/step - loss: 1.2045 - acc: 0.5321 - val_loss: 1.2140 - val_acc: 0.4913\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 60/500\n",
      "934/934 [==============================] - 1s 764us/step - loss: 1.2035 - acc: 0.5257 - val_loss: 1.2047 - val_acc: 0.5212\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 61/500\n",
      "934/934 [==============================] - 1s 757us/step - loss: 1.2016 - acc: 0.5150 - val_loss: 1.2103 - val_acc: 0.5337\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 26us/step\n",
      "Epoch 62/500\n",
      "934/934 [==============================] - 1s 754us/step - loss: 1.1993 - acc: 0.5278 - val_loss: 1.2009 - val_acc: 0.5037\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 63/500\n",
      "934/934 [==============================] - 1s 766us/step - loss: 1.1956 - acc: 0.5236 - val_loss: 1.2004 - val_acc: 0.5087\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 64/500\n",
      "934/934 [==============================] - 1s 764us/step - loss: 1.1944 - acc: 0.5107 - val_loss: 1.2022 - val_acc: 0.5137\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 26us/step\n",
      "Epoch 65/500\n",
      "934/934 [==============================] - 1s 757us/step - loss: 1.1922 - acc: 0.5139 - val_loss: 1.1981 - val_acc: 0.5187\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 66/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.1899 - acc: 0.5193 - val_loss: 1.1948 - val_acc: 0.5112\n",
      "293/293 [==============================] - 0s 17us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 24us/step\n",
      "Epoch 67/500\n",
      "934/934 [==============================] - 1s 769us/step - loss: 1.1894 - acc: 0.5246 - val_loss: 1.1976 - val_acc: 0.4913\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 68/500\n",
      "934/934 [==============================] - 1s 751us/step - loss: 1.1874 - acc: 0.5268 - val_loss: 1.1955 - val_acc: 0.5411\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 69/500\n",
      "934/934 [==============================] - 1s 826us/step - loss: 1.1866 - acc: 0.5289 - val_loss: 1.1906 - val_acc: 0.5312\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 70/500\n",
      "934/934 [==============================] - 1s 758us/step - loss: 1.1831 - acc: 0.5343 - val_loss: 1.1981 - val_acc: 0.4938\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 71/500\n",
      "934/934 [==============================] - 1s 757us/step - loss: 1.1840 - acc: 0.5268 - val_loss: 1.1899 - val_acc: 0.5212\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 72/500\n",
      "934/934 [==============================] - 1s 761us/step - loss: 1.1820 - acc: 0.5300 - val_loss: 1.1868 - val_acc: 0.5337\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 73/500\n",
      "934/934 [==============================] - 1s 741us/step - loss: 1.1794 - acc: 0.5407 - val_loss: 1.2022 - val_acc: 0.4813\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 74/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.1812 - acc: 0.5300 - val_loss: 1.1895 - val_acc: 0.5312\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 75/500\n",
      "934/934 [==============================] - 1s 754us/step - loss: 1.1776 - acc: 0.5289 - val_loss: 1.1847 - val_acc: 0.5112\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 76/500\n",
      "934/934 [==============================] - 1s 744us/step - loss: 1.1748 - acc: 0.5375 - val_loss: 1.1865 - val_acc: 0.5087\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 77/500\n",
      "934/934 [==============================] - 1s 760us/step - loss: 1.1768 - acc: 0.5343 - val_loss: 1.1852 - val_acc: 0.5087\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 78/500\n",
      "934/934 [==============================] - 1s 771us/step - loss: 1.1748 - acc: 0.5300 - val_loss: 1.1877 - val_acc: 0.5162\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 79/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.1749 - acc: 0.5300 - val_loss: 1.1803 - val_acc: 0.5387\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 80/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.1736 - acc: 0.5375 - val_loss: 1.1797 - val_acc: 0.5411\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 81/500\n",
      "934/934 [==============================] - 1s 751us/step - loss: 1.1710 - acc: 0.5482 - val_loss: 1.1835 - val_acc: 0.5362\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 82/500\n",
      "934/934 [==============================] - 1s 755us/step - loss: 1.1717 - acc: 0.5321 - val_loss: 1.1831 - val_acc: 0.5112\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 83/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.1707 - acc: 0.5364 - val_loss: 1.1810 - val_acc: 0.5112\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 84/500\n",
      "934/934 [==============================] - 1s 745us/step - loss: 1.1698 - acc: 0.5460 - val_loss: 1.1805 - val_acc: 0.5137\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 85/500\n",
      "934/934 [==============================] - 1s 760us/step - loss: 1.1699 - acc: 0.5343 - val_loss: 1.1760 - val_acc: 0.5287\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 86/500\n",
      "934/934 [==============================] - 1s 766us/step - loss: 1.1680 - acc: 0.5493 - val_loss: 1.1750 - val_acc: 0.5436\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 87/500\n",
      "934/934 [==============================] - 1s 768us/step - loss: 1.1656 - acc: 0.5471 - val_loss: 1.1887 - val_acc: 0.5012\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 88/500\n",
      "934/934 [==============================] - 1s 803us/step - loss: 1.1658 - acc: 0.5450 - val_loss: 1.1759 - val_acc: 0.5137\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 89/500\n",
      "934/934 [==============================] - 1s 753us/step - loss: 1.1663 - acc: 0.5546 - val_loss: 1.1739 - val_acc: 0.5212\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 90/500\n",
      "934/934 [==============================] - 1s 780us/step - loss: 1.1662 - acc: 0.5535 - val_loss: 1.1760 - val_acc: 0.5137\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 91/500\n",
      "934/934 [==============================] - 1s 790us/step - loss: 1.1661 - acc: 0.5396 - val_loss: 1.1735 - val_acc: 0.5411\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 92/500\n",
      "934/934 [==============================] - 1s 749us/step - loss: 1.1637 - acc: 0.5514 - val_loss: 1.1776 - val_acc: 0.5362\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 93/500\n",
      "934/934 [==============================] - 1s 769us/step - loss: 1.1624 - acc: 0.5503 - val_loss: 1.1755 - val_acc: 0.5137\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 94/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.1635 - acc: 0.5503 - val_loss: 1.1736 - val_acc: 0.5312\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 26us/step\n",
      "Epoch 95/500\n",
      "934/934 [==============================] - 1s 749us/step - loss: 1.1624 - acc: 0.5482 - val_loss: 1.1747 - val_acc: 0.5212\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 96/500\n",
      "934/934 [==============================] - 1s 973us/step - loss: 1.1596 - acc: 0.5407 - val_loss: 1.1687 - val_acc: 0.5212\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 97/500\n",
      "934/934 [==============================] - 1s 760us/step - loss: 1.1600 - acc: 0.5482 - val_loss: 1.1738 - val_acc: 0.5187\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 98/500\n",
      "934/934 [==============================] - 1s 757us/step - loss: 1.1609 - acc: 0.5364 - val_loss: 1.1719 - val_acc: 0.5237\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 99/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.1600 - acc: 0.5503 - val_loss: 1.1708 - val_acc: 0.5112\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 100/500\n",
      "934/934 [==============================] - 1s 761us/step - loss: 1.1606 - acc: 0.5418 - val_loss: 1.1689 - val_acc: 0.5287\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 101/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.1576 - acc: 0.5460 - val_loss: 1.1687 - val_acc: 0.5187\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 102/500\n",
      "934/934 [==============================] - 1s 765us/step - loss: 1.1586 - acc: 0.5525 - val_loss: 1.1676 - val_acc: 0.5212\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 103/500\n",
      "934/934 [==============================] - 1s 751us/step - loss: 1.1580 - acc: 0.5557 - val_loss: 1.1665 - val_acc: 0.5212\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 104/500\n",
      "934/934 [==============================] - 1s 765us/step - loss: 1.1565 - acc: 0.5450 - val_loss: 1.1703 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 105/500\n",
      "934/934 [==============================] - 1s 777us/step - loss: 1.1552 - acc: 0.5471 - val_loss: 1.1708 - val_acc: 0.5087\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 106/500\n",
      "934/934 [==============================] - 1s 757us/step - loss: 1.1534 - acc: 0.5632 - val_loss: 1.1832 - val_acc: 0.4913\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 107/500\n",
      "934/934 [==============================] - 1s 770us/step - loss: 1.1559 - acc: 0.5514 - val_loss: 1.1705 - val_acc: 0.5012\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 108/500\n",
      "934/934 [==============================] - 1s 769us/step - loss: 1.1534 - acc: 0.5557 - val_loss: 1.1714 - val_acc: 0.5536\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 109/500\n",
      "934/934 [==============================] - 1s 751us/step - loss: 1.1534 - acc: 0.5621 - val_loss: 1.1666 - val_acc: 0.5162\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 110/500\n",
      "934/934 [==============================] - 1s 764us/step - loss: 1.1525 - acc: 0.5493 - val_loss: 1.1683 - val_acc: 0.5436\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 111/500\n",
      "934/934 [==============================] - 1s 761us/step - loss: 1.1500 - acc: 0.5664 - val_loss: 1.1631 - val_acc: 0.5262\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 112/500\n",
      "934/934 [==============================] - 1s 771us/step - loss: 1.1514 - acc: 0.5632 - val_loss: 1.1650 - val_acc: 0.5237\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 113/500\n",
      "934/934 [==============================] - 1s 757us/step - loss: 1.1504 - acc: 0.5664 - val_loss: 1.1631 - val_acc: 0.5162\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 114/500\n",
      "934/934 [==============================] - 1s 756us/step - loss: 1.1468 - acc: 0.5621 - val_loss: 1.1739 - val_acc: 0.5262\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 115/500\n",
      "934/934 [==============================] - 1s 765us/step - loss: 1.1478 - acc: 0.5728 - val_loss: 1.1628 - val_acc: 0.5187\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 116/500\n",
      "934/934 [==============================] - 1s 768us/step - loss: 1.1473 - acc: 0.5814 - val_loss: 1.1651 - val_acc: 0.5262\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 117/500\n",
      "934/934 [==============================] - 1s 757us/step - loss: 1.1463 - acc: 0.5739 - val_loss: 1.1591 - val_acc: 0.5212\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 118/500\n",
      "934/934 [==============================] - 1s 768us/step - loss: 1.1428 - acc: 0.5803 - val_loss: 1.1632 - val_acc: 0.5312\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 119/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.1414 - acc: 0.5707 - val_loss: 1.1663 - val_acc: 0.5436\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 120/500\n",
      "934/934 [==============================] - 1s 750us/step - loss: 1.1426 - acc: 0.5803 - val_loss: 1.1689 - val_acc: 0.5262\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 121/500\n",
      "934/934 [==============================] - 1s 766us/step - loss: 1.1399 - acc: 0.5653 - val_loss: 1.1586 - val_acc: 0.5237\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 122/500\n",
      "934/934 [==============================] - 1s 761us/step - loss: 1.1397 - acc: 0.5878 - val_loss: 1.1659 - val_acc: 0.5237\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 123/500\n",
      "934/934 [==============================] - 1s 760us/step - loss: 1.1386 - acc: 0.5824 - val_loss: 1.1636 - val_acc: 0.5312\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 124/500\n",
      "934/934 [==============================] - 1s 764us/step - loss: 1.1367 - acc: 0.5782 - val_loss: 1.1569 - val_acc: 0.5536\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 125/500\n",
      "934/934 [==============================] - 1s 743us/step - loss: 1.1381 - acc: 0.5803 - val_loss: 1.1569 - val_acc: 0.5461\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 126/500\n",
      "934/934 [==============================] - 1s 757us/step - loss: 1.1354 - acc: 0.5835 - val_loss: 1.1551 - val_acc: 0.5287\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 127/500\n",
      "934/934 [==============================] - 1s 774us/step - loss: 1.1354 - acc: 0.5910 - val_loss: 1.1570 - val_acc: 0.5312\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 128/500\n",
      "934/934 [==============================] - 1s 752us/step - loss: 1.1333 - acc: 0.5857 - val_loss: 1.1557 - val_acc: 0.5337\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 129/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.1310 - acc: 0.5878 - val_loss: 1.1529 - val_acc: 0.5436\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 130/500\n",
      "934/934 [==============================] - 1s 765us/step - loss: 1.1309 - acc: 0.5931 - val_loss: 1.1521 - val_acc: 0.5511\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 131/500\n",
      "934/934 [==============================] - 1s 866us/step - loss: 1.1305 - acc: 0.5931 - val_loss: 1.1512 - val_acc: 0.5337\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 26us/step\n",
      "Epoch 132/500\n",
      "934/934 [==============================] - 1s 748us/step - loss: 1.1252 - acc: 0.5953 - val_loss: 1.1648 - val_acc: 0.5162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 133/500\n",
      "934/934 [==============================] - 1s 758us/step - loss: 1.1280 - acc: 0.5760 - val_loss: 1.1550 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 134/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.1276 - acc: 0.5878 - val_loss: 1.1488 - val_acc: 0.5411\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 135/500\n",
      "934/934 [==============================] - 1s 761us/step - loss: 1.1244 - acc: 0.5835 - val_loss: 1.1476 - val_acc: 0.5461\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 136/500\n",
      "934/934 [==============================] - 1s 747us/step - loss: 1.1247 - acc: 0.5857 - val_loss: 1.1479 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 137/500\n",
      "934/934 [==============================] - 1s 858us/step - loss: 1.1233 - acc: 0.5974 - val_loss: 1.1467 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 34us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 138/500\n",
      "934/934 [==============================] - 1s 854us/step - loss: 1.1213 - acc: 0.6006 - val_loss: 1.1485 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 139/500\n",
      "934/934 [==============================] - 1s 792us/step - loss: 1.1205 - acc: 0.5964 - val_loss: 1.1426 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 29us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 140/500\n",
      "934/934 [==============================] - 1s 855us/step - loss: 1.1188 - acc: 0.5974 - val_loss: 1.1434 - val_acc: 0.5337\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 141/500\n",
      "934/934 [==============================] - 1s 790us/step - loss: 1.1158 - acc: 0.5910 - val_loss: 1.1497 - val_acc: 0.5636\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 142/500\n",
      "934/934 [==============================] - 1s 788us/step - loss: 1.1159 - acc: 0.5942 - val_loss: 1.1533 - val_acc: 0.5137\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 143/500\n",
      "934/934 [==============================] - 1s 764us/step - loss: 1.1169 - acc: 0.5857 - val_loss: 1.1406 - val_acc: 0.5511\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 144/500\n",
      "934/934 [==============================] - 1s 746us/step - loss: 1.1153 - acc: 0.5899 - val_loss: 1.1384 - val_acc: 0.5436\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 145/500\n",
      "934/934 [==============================] - 1s 765us/step - loss: 1.1129 - acc: 0.6017 - val_loss: 1.1327 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 146/500\n",
      "934/934 [==============================] - 1s 767us/step - loss: 1.1105 - acc: 0.6017 - val_loss: 1.1464 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 30us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 147/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.1101 - acc: 0.5857 - val_loss: 1.1419 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 148/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.1103 - acc: 0.6017 - val_loss: 1.1291 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 149/500\n",
      "934/934 [==============================] - 1s 764us/step - loss: 1.1091 - acc: 0.5931 - val_loss: 1.1290 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 150/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.1074 - acc: 0.5985 - val_loss: 1.1238 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 151/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.1064 - acc: 0.5942 - val_loss: 1.1221 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 27us/step\n",
      "Epoch 152/500\n",
      "934/934 [==============================] - 1s 748us/step - loss: 1.1051 - acc: 0.5974 - val_loss: 1.1226 - val_acc: 0.5536\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 153/500\n",
      "934/934 [==============================] - 1s 766us/step - loss: 1.1034 - acc: 0.5996 - val_loss: 1.1244 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 154/500\n",
      "934/934 [==============================] - 1s 825us/step - loss: 1.1038 - acc: 0.5921 - val_loss: 1.1233 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 155/500\n",
      "934/934 [==============================] - 1s 850us/step - loss: 1.1030 - acc: 0.5942 - val_loss: 1.1219 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 156/500\n",
      "934/934 [==============================] - 1s 775us/step - loss: 1.1012 - acc: 0.5899 - val_loss: 1.1177 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 157/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.1012 - acc: 0.5985 - val_loss: 1.1177 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 28us/step\n",
      "Epoch 158/500\n",
      "934/934 [==============================] - 1s 768us/step - loss: 1.0992 - acc: 0.5921 - val_loss: 1.1229 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 159/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.1005 - acc: 0.5921 - val_loss: 1.1144 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 41us/step\n",
      "132/132 [==============================] - 0s 95us/step\n",
      "Epoch 160/500\n",
      "934/934 [==============================] - 1s 784us/step - loss: 1.0952 - acc: 0.5964 - val_loss: 1.1388 - val_acc: 0.5387\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 161/500\n",
      "934/934 [==============================] - 1s 768us/step - loss: 1.1001 - acc: 0.5964 - val_loss: 1.1191 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 162/500\n",
      "934/934 [==============================] - 1s 764us/step - loss: 1.0976 - acc: 0.5953 - val_loss: 1.1150 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 163/500\n",
      "934/934 [==============================] - 1s 741us/step - loss: 1.0963 - acc: 0.6060 - val_loss: 1.1135 - val_acc: 0.5486\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 28us/step\n",
      "Epoch 164/500\n",
      "934/934 [==============================] - 1s 760us/step - loss: 1.0958 - acc: 0.5931 - val_loss: 1.1158 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 165/500\n",
      "934/934 [==============================] - 1s 766us/step - loss: 1.0967 - acc: 0.5996 - val_loss: 1.1111 - val_acc: 0.5835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 166/500\n",
      "934/934 [==============================] - 1s 745us/step - loss: 1.0933 - acc: 0.5931 - val_loss: 1.1132 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 167/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.0943 - acc: 0.5942 - val_loss: 1.1135 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 168/500\n",
      "934/934 [==============================] - 1s 760us/step - loss: 1.0927 - acc: 0.5953 - val_loss: 1.1101 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 169/500\n",
      "934/934 [==============================] - 1s 867us/step - loss: 1.0932 - acc: 0.5921 - val_loss: 1.1252 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 170/500\n",
      "934/934 [==============================] - 1s 758us/step - loss: 1.0927 - acc: 0.5931 - val_loss: 1.1122 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 171/500\n",
      "934/934 [==============================] - 1s 744us/step - loss: 1.0924 - acc: 0.6006 - val_loss: 1.1171 - val_acc: 0.5436\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 172/500\n",
      "934/934 [==============================] - 1s 770us/step - loss: 1.0932 - acc: 0.5931 - val_loss: 1.1107 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 173/500\n",
      "934/934 [==============================] - 1s 757us/step - loss: 1.0920 - acc: 0.5996 - val_loss: 1.1100 - val_acc: 0.5536\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 174/500\n",
      "934/934 [==============================] - 1s 745us/step - loss: 1.0893 - acc: 0.6017 - val_loss: 1.1038 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 175/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.0906 - acc: 0.5964 - val_loss: 1.1078 - val_acc: 0.5636\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 176/500\n",
      "934/934 [==============================] - 1s 760us/step - loss: 1.0902 - acc: 0.5964 - val_loss: 1.1072 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 177/500\n",
      "934/934 [==============================] - 1s 751us/step - loss: 1.0901 - acc: 0.5867 - val_loss: 1.1150 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 178/500\n",
      "934/934 [==============================] - 1s 772us/step - loss: 1.0882 - acc: 0.5931 - val_loss: 1.1050 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 179/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.0898 - acc: 0.5910 - val_loss: 1.1060 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 180/500\n",
      "934/934 [==============================] - 1s 756us/step - loss: 1.0893 - acc: 0.5921 - val_loss: 1.1109 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 181/500\n",
      "934/934 [==============================] - 1s 764us/step - loss: 1.0879 - acc: 0.5921 - val_loss: 1.1098 - val_acc: 0.5636\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 182/500\n",
      "934/934 [==============================] - 1s 769us/step - loss: 1.0872 - acc: 0.5824 - val_loss: 1.1058 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 183/500\n",
      "934/934 [==============================] - 1s 768us/step - loss: 1.0871 - acc: 0.5974 - val_loss: 1.1131 - val_acc: 0.5362\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 184/500\n",
      "934/934 [==============================] - 1s 760us/step - loss: 1.0891 - acc: 0.5985 - val_loss: 1.1113 - val_acc: 0.5536\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 185/500\n",
      "934/934 [==============================] - 1s 746us/step - loss: 1.0856 - acc: 0.5953 - val_loss: 1.0995 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 23us/step\n",
      "132/132 [==============================] - 0s 45us/step\n",
      "Epoch 186/500\n",
      "934/934 [==============================] - 1s 764us/step - loss: 1.0877 - acc: 0.5953 - val_loss: 1.1090 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 187/500\n",
      "934/934 [==============================] - 1s 764us/step - loss: 1.0854 - acc: 0.5974 - val_loss: 1.1060 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 188/500\n",
      "934/934 [==============================] - 1s 744us/step - loss: 1.0817 - acc: 0.6049 - val_loss: 1.1093 - val_acc: 0.5511\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 189/500\n",
      "934/934 [==============================] - 1s 760us/step - loss: 1.0863 - acc: 0.6006 - val_loss: 1.1037 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 190/500\n",
      "934/934 [==============================] - 1s 766us/step - loss: 1.0842 - acc: 0.6039 - val_loss: 1.1050 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 191/500\n",
      "934/934 [==============================] - 1s 753us/step - loss: 1.0828 - acc: 0.6017 - val_loss: 1.1033 - val_acc: 0.5935\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 39us/step\n",
      "Epoch 192/500\n",
      "934/934 [==============================] - 1s 755us/step - loss: 1.0842 - acc: 0.6017 - val_loss: 1.1027 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 28us/step\n",
      "Epoch 193/500\n",
      "934/934 [==============================] - 1s 755us/step - loss: 1.0830 - acc: 0.6039 - val_loss: 1.1027 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 194/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.0833 - acc: 0.5878 - val_loss: 1.1010 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 195/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.0788 - acc: 0.5996 - val_loss: 1.1119 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 196/500\n",
      "934/934 [==============================] - 1s 753us/step - loss: 1.0849 - acc: 0.6039 - val_loss: 1.1004 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 197/500\n",
      "934/934 [==============================] - 1s 778us/step - loss: 1.0795 - acc: 0.6039 - val_loss: 1.1073 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 198/500\n",
      "934/934 [==============================] - 1s 761us/step - loss: 1.0830 - acc: 0.5964 - val_loss: 1.0951 - val_acc: 0.5611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 199/500\n",
      "934/934 [==============================] - 1s 754us/step - loss: 1.0822 - acc: 0.5942 - val_loss: 1.0986 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 200/500\n",
      "934/934 [==============================] - 1s 756us/step - loss: 1.0818 - acc: 0.5974 - val_loss: 1.0947 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 201/500\n",
      "934/934 [==============================] - 1s 761us/step - loss: 1.0807 - acc: 0.6017 - val_loss: 1.0944 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 202/500\n",
      "934/934 [==============================] - 1s 744us/step - loss: 1.0820 - acc: 0.5974 - val_loss: 1.0948 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 203/500\n",
      "934/934 [==============================] - 1s 754us/step - loss: 1.0791 - acc: 0.5985 - val_loss: 1.1146 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 204/500\n",
      "934/934 [==============================] - 1s 755us/step - loss: 1.0800 - acc: 0.6017 - val_loss: 1.0962 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 205/500\n",
      "934/934 [==============================] - 1s 750us/step - loss: 1.0805 - acc: 0.6092 - val_loss: 1.0983 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 206/500\n",
      "934/934 [==============================] - 1s 757us/step - loss: 1.0799 - acc: 0.5985 - val_loss: 1.0965 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 207/500\n",
      "934/934 [==============================] - 1s 750us/step - loss: 1.0800 - acc: 0.6017 - val_loss: 1.0900 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 208/500\n",
      "934/934 [==============================] - 1s 760us/step - loss: 1.0802 - acc: 0.5974 - val_loss: 1.1003 - val_acc: 0.5636\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 209/500\n",
      "934/934 [==============================] - 1s 772us/step - loss: 1.0799 - acc: 0.6028 - val_loss: 1.0941 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 210/500\n",
      "934/934 [==============================] - 1s 791us/step - loss: 1.0776 - acc: 0.5996 - val_loss: 1.0976 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 46us/step\n",
      "Epoch 211/500\n",
      "934/934 [==============================] - 1s 784us/step - loss: 1.0755 - acc: 0.6060 - val_loss: 1.1095 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 212/500\n",
      "934/934 [==============================] - 1s 778us/step - loss: 1.0786 - acc: 0.6006 - val_loss: 1.0917 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 213/500\n",
      "934/934 [==============================] - 1s 761us/step - loss: 1.0757 - acc: 0.5953 - val_loss: 1.0995 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 22us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 214/500\n",
      "934/934 [==============================] - 1s 764us/step - loss: 1.0797 - acc: 0.6049 - val_loss: 1.0914 - val_acc: 0.5960\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 215/500\n",
      "934/934 [==============================] - 1s 783us/step - loss: 1.0766 - acc: 0.5964 - val_loss: 1.1041 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 216/500\n",
      "934/934 [==============================] - 1s 750us/step - loss: 1.0768 - acc: 0.5985 - val_loss: 1.1091 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 46us/step\n",
      "Epoch 217/500\n",
      "934/934 [==============================] - 1s 761us/step - loss: 1.0788 - acc: 0.6049 - val_loss: 1.0963 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 218/500\n",
      "934/934 [==============================] - 1s 743us/step - loss: 1.0761 - acc: 0.5996 - val_loss: 1.1069 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 219/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.0777 - acc: 0.5974 - val_loss: 1.0946 - val_acc: 0.6010\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 220/500\n",
      "934/934 [==============================] - 1s 748us/step - loss: 1.0766 - acc: 0.5964 - val_loss: 1.1042 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 221/500\n",
      "934/934 [==============================] - 1s 748us/step - loss: 1.0764 - acc: 0.6049 - val_loss: 1.0902 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 222/500\n",
      "934/934 [==============================] - 1s 758us/step - loss: 1.0764 - acc: 0.6028 - val_loss: 1.0983 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 223/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.0772 - acc: 0.5974 - val_loss: 1.1007 - val_acc: 0.5636\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 224/500\n",
      "934/934 [==============================] - 1s 764us/step - loss: 1.0764 - acc: 0.6071 - val_loss: 1.1008 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 225/500\n",
      "934/934 [==============================] - 1s 772us/step - loss: 1.0775 - acc: 0.5985 - val_loss: 1.0983 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 226/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.0749 - acc: 0.6060 - val_loss: 1.0986 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 227/500\n",
      "934/934 [==============================] - 1s 752us/step - loss: 1.0751 - acc: 0.5942 - val_loss: 1.0960 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 228/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.0783 - acc: 0.6049 - val_loss: 1.1003 - val_acc: 0.5636\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 27us/step\n",
      "Epoch 229/500\n",
      "934/934 [==============================] - 1s 760us/step - loss: 1.0766 - acc: 0.6092 - val_loss: 1.0966 - val_acc: 0.5935\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 230/500\n",
      "934/934 [==============================] - 1s 901us/step - loss: 1.0759 - acc: 0.6028 - val_loss: 1.1019 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 231/500\n",
      "934/934 [==============================] - 1s 787us/step - loss: 1.0765 - acc: 0.5953 - val_loss: 1.0943 - val_acc: 0.5860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 232/500\n",
      "934/934 [==============================] - 1s 774us/step - loss: 1.0740 - acc: 0.6049 - val_loss: 1.0993 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 233/500\n",
      "934/934 [==============================] - 1s 819us/step - loss: 1.0756 - acc: 0.6006 - val_loss: 1.0970 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 40us/step\n",
      "Epoch 234/500\n",
      "934/934 [==============================] - 1s 823us/step - loss: 1.0758 - acc: 0.6017 - val_loss: 1.0922 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 235/500\n",
      "934/934 [==============================] - 1s 751us/step - loss: 1.0740 - acc: 0.6028 - val_loss: 1.0953 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 236/500\n",
      "934/934 [==============================] - 1s 757us/step - loss: 1.0737 - acc: 0.6017 - val_loss: 1.0946 - val_acc: 0.5985\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 237/500\n",
      "934/934 [==============================] - 1s 756us/step - loss: 1.0743 - acc: 0.6017 - val_loss: 1.0952 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 238/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.0725 - acc: 0.5985 - val_loss: 1.1018 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 239/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.0744 - acc: 0.6006 - val_loss: 1.0963 - val_acc: 0.5511\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 240/500\n",
      "934/934 [==============================] - 1s 737us/step - loss: 1.0732 - acc: 0.6092 - val_loss: 1.0905 - val_acc: 0.5461\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 241/500\n",
      "934/934 [==============================] - 1s 760us/step - loss: 1.0759 - acc: 0.5996 - val_loss: 1.0901 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 242/500\n",
      "934/934 [==============================] - 1s 773us/step - loss: 1.0732 - acc: 0.5996 - val_loss: 1.0908 - val_acc: 0.5960\n",
      "293/293 [==============================] - 0s 24us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 243/500\n",
      "934/934 [==============================] - 1s 745us/step - loss: 1.0734 - acc: 0.6060 - val_loss: 1.0985 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 244/500\n",
      "934/934 [==============================] - 1s 760us/step - loss: 1.0748 - acc: 0.6017 - val_loss: 1.1029 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 245/500\n",
      "934/934 [==============================] - 1s 779us/step - loss: 1.0744 - acc: 0.5985 - val_loss: 1.0966 - val_acc: 0.5985\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 246/500\n",
      "934/934 [==============================] - 1s 752us/step - loss: 1.0729 - acc: 0.5996 - val_loss: 1.0974 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 247/500\n",
      "934/934 [==============================] - 1s 765us/step - loss: 1.0730 - acc: 0.6017 - val_loss: 1.1103 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 25us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 248/500\n",
      "934/934 [==============================] - 1s 750us/step - loss: 1.0750 - acc: 0.5953 - val_loss: 1.0917 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 249/500\n",
      "934/934 [==============================] - 1s 755us/step - loss: 1.0741 - acc: 0.6049 - val_loss: 1.0898 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 250/500\n",
      "934/934 [==============================] - 1s 760us/step - loss: 1.0734 - acc: 0.6006 - val_loss: 1.0905 - val_acc: 0.5935\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 251/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.0746 - acc: 0.5985 - val_loss: 1.0903 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 252/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.0736 - acc: 0.6006 - val_loss: 1.0921 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 253/500\n",
      "934/934 [==============================] - 1s 756us/step - loss: 1.0744 - acc: 0.5964 - val_loss: 1.0888 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 254/500\n",
      "934/934 [==============================] - 1s 740us/step - loss: 1.0718 - acc: 0.6017 - val_loss: 1.0894 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 255/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.0717 - acc: 0.6071 - val_loss: 1.0997 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 256/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.0729 - acc: 0.6017 - val_loss: 1.0963 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 257/500\n",
      "934/934 [==============================] - 1s 753us/step - loss: 1.0727 - acc: 0.6006 - val_loss: 1.0988 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 258/500\n",
      "934/934 [==============================] - 1s 787us/step - loss: 1.0736 - acc: 0.6039 - val_loss: 1.0892 - val_acc: 0.5935\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 259/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.0730 - acc: 0.5974 - val_loss: 1.0874 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 260/500\n",
      "934/934 [==============================] - 1s 771us/step - loss: 1.0711 - acc: 0.5985 - val_loss: 1.0968 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 261/500\n",
      "934/934 [==============================] - 1s 758us/step - loss: 1.0713 - acc: 0.6017 - val_loss: 1.0929 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 262/500\n",
      "934/934 [==============================] - 1s 757us/step - loss: 1.0707 - acc: 0.5964 - val_loss: 1.1071 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 263/500\n",
      "934/934 [==============================] - 1s 766us/step - loss: 1.0726 - acc: 0.6039 - val_loss: 1.0992 - val_acc: 0.5985\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 264/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.0727 - acc: 0.6049 - val_loss: 1.0889 - val_acc: 0.5736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 265/500\n",
      "934/934 [==============================] - 1s 755us/step - loss: 1.0724 - acc: 0.6049 - val_loss: 1.0883 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 266/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.0707 - acc: 0.5974 - val_loss: 1.0930 - val_acc: 0.5935\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 267/500\n",
      "934/934 [==============================] - 1s 765us/step - loss: 1.0713 - acc: 0.6081 - val_loss: 1.0901 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 268/500\n",
      "934/934 [==============================] - 1s 755us/step - loss: 1.0727 - acc: 0.5985 - val_loss: 1.0941 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 269/500\n",
      "934/934 [==============================] - 1s 758us/step - loss: 1.0709 - acc: 0.5974 - val_loss: 1.0932 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 270/500\n",
      "934/934 [==============================] - 1s 758us/step - loss: 1.0708 - acc: 0.6049 - val_loss: 1.1043 - val_acc: 0.5511\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 271/500\n",
      "934/934 [==============================] - 1s 757us/step - loss: 1.0727 - acc: 0.6017 - val_loss: 1.0944 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 272/500\n",
      "934/934 [==============================] - 1s 761us/step - loss: 1.0703 - acc: 0.6049 - val_loss: 1.0876 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 273/500\n",
      "934/934 [==============================] - 1s 761us/step - loss: 1.0685 - acc: 0.6017 - val_loss: 1.1071 - val_acc: 0.5536\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 274/500\n",
      "934/934 [==============================] - 1s 745us/step - loss: 1.0711 - acc: 0.5996 - val_loss: 1.0942 - val_acc: 0.5636\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 275/500\n",
      "934/934 [==============================] - 1s 758us/step - loss: 1.0721 - acc: 0.5910 - val_loss: 1.0888 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 276/500\n",
      "934/934 [==============================] - 1s 742us/step - loss: 1.0707 - acc: 0.6028 - val_loss: 1.0942 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 277/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.0708 - acc: 0.6039 - val_loss: 1.0944 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 278/500\n",
      "934/934 [==============================] - 1s 769us/step - loss: 1.0692 - acc: 0.5964 - val_loss: 1.0892 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 24us/step\n",
      "132/132 [==============================] - 0s 40us/step\n",
      "Epoch 279/500\n",
      "934/934 [==============================] - 1s 764us/step - loss: 1.0685 - acc: 0.6028 - val_loss: 1.1061 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 280/500\n",
      "934/934 [==============================] - 1s 759us/step - loss: 1.0714 - acc: 0.6006 - val_loss: 1.1038 - val_acc: 0.5636\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 281/500\n",
      "934/934 [==============================] - 1s 757us/step - loss: 1.0677 - acc: 0.6006 - val_loss: 1.0862 - val_acc: 0.5985\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 282/500\n",
      "934/934 [==============================] - 1s 753us/step - loss: 1.0716 - acc: 0.5996 - val_loss: 1.0870 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 283/500\n",
      "934/934 [==============================] - 1s 756us/step - loss: 1.0695 - acc: 0.6039 - val_loss: 1.0906 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 284/500\n",
      "934/934 [==============================] - 1s 753us/step - loss: 1.0691 - acc: 0.5942 - val_loss: 1.0897 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 285/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.0689 - acc: 0.6060 - val_loss: 1.0860 - val_acc: 0.5960\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 286/500\n",
      "934/934 [==============================] - 1s 756us/step - loss: 1.0669 - acc: 0.5942 - val_loss: 1.1053 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 287/500\n",
      "934/934 [==============================] - 1s 751us/step - loss: 1.0702 - acc: 0.6071 - val_loss: 1.0972 - val_acc: 0.5536\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 288/500\n",
      "934/934 [==============================] - 1s 772us/step - loss: 1.0709 - acc: 0.5964 - val_loss: 1.0909 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 289/500\n",
      "934/934 [==============================] - 1s 764us/step - loss: 1.0710 - acc: 0.6060 - val_loss: 1.0863 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 290/500\n",
      "934/934 [==============================] - 1s 908us/step - loss: 1.0697 - acc: 0.5931 - val_loss: 1.0978 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 291/500\n",
      "934/934 [==============================] - 1s 863us/step - loss: 1.0698 - acc: 0.5974 - val_loss: 1.0948 - val_acc: 0.5636\n",
      "293/293 [==============================] - 0s 35us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 292/500\n",
      "934/934 [==============================] - 1s 843us/step - loss: 1.0704 - acc: 0.6039 - val_loss: 1.0958 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 22us/step\n",
      "132/132 [==============================] - 0s 43us/step\n",
      "Epoch 293/500\n",
      "934/934 [==============================] - 1s 919us/step - loss: 1.0683 - acc: 0.6081 - val_loss: 1.0859 - val_acc: 0.5985\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 28us/step\n",
      "Epoch 294/500\n",
      "934/934 [==============================] - 1s 765us/step - loss: 1.0713 - acc: 0.5942 - val_loss: 1.0962 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 295/500\n",
      "934/934 [==============================] - 1s 747us/step - loss: 1.0693 - acc: 0.6081 - val_loss: 1.0890 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 296/500\n",
      "934/934 [==============================] - 1s 769us/step - loss: 1.0701 - acc: 0.6039 - val_loss: 1.0875 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 297/500\n",
      "934/934 [==============================] - 1s 767us/step - loss: 1.0708 - acc: 0.6028 - val_loss: 1.0892 - val_acc: 0.5711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 298/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.0678 - acc: 0.5910 - val_loss: 1.0875 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 299/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.0707 - acc: 0.5942 - val_loss: 1.0901 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 300/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.0698 - acc: 0.6049 - val_loss: 1.0840 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 301/500\n",
      "934/934 [==============================] - 1s 781us/step - loss: 1.0700 - acc: 0.6017 - val_loss: 1.0851 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 24us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 302/500\n",
      "934/934 [==============================] - 1s 813us/step - loss: 1.0678 - acc: 0.5931 - val_loss: 1.0935 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 303/500\n",
      "934/934 [==============================] - 1s 745us/step - loss: 1.0693 - acc: 0.6049 - val_loss: 1.0877 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 304/500\n",
      "934/934 [==============================] - 1s 762us/step - loss: 1.0700 - acc: 0.5942 - val_loss: 1.0874 - val_acc: 0.5960\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 305/500\n",
      "934/934 [==============================] - 1s 768us/step - loss: 1.0668 - acc: 0.6071 - val_loss: 1.0889 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 306/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0698 - acc: 0.5985 - val_loss: 1.0924 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 25us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 307/500\n",
      "934/934 [==============================] - 1s 858us/step - loss: 1.0695 - acc: 0.5974 - val_loss: 1.0876 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 24us/step\n",
      "Epoch 308/500\n",
      "934/934 [==============================] - 1s 780us/step - loss: 1.0684 - acc: 0.6092 - val_loss: 1.0931 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 24us/step\n",
      "Epoch 309/500\n",
      "934/934 [==============================] - 1s 757us/step - loss: 1.0673 - acc: 0.6028 - val_loss: 1.0892 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 27us/step\n",
      "Epoch 310/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.0684 - acc: 0.6006 - val_loss: 1.0849 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 311/500\n",
      "934/934 [==============================] - 1s 734us/step - loss: 1.0674 - acc: 0.6039 - val_loss: 1.0999 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 27us/step\n",
      "Epoch 312/500\n",
      "934/934 [==============================] - 1s 737us/step - loss: 1.0686 - acc: 0.6092 - val_loss: 1.0868 - val_acc: 0.5960\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 26us/step\n",
      "Epoch 313/500\n",
      "934/934 [==============================] - 1s 729us/step - loss: 1.0663 - acc: 0.5942 - val_loss: 1.0886 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 314/500\n",
      "934/934 [==============================] - 1s 740us/step - loss: 1.0688 - acc: 0.5996 - val_loss: 1.0910 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 315/500\n",
      "934/934 [==============================] - 1s 739us/step - loss: 1.0665 - acc: 0.6103 - val_loss: 1.0939 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 316/500\n",
      "934/934 [==============================] - 1s 728us/step - loss: 1.0679 - acc: 0.6060 - val_loss: 1.0940 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 317/500\n",
      "934/934 [==============================] - 1s 754us/step - loss: 1.0642 - acc: 0.6071 - val_loss: 1.1034 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 318/500\n",
      "934/934 [==============================] - 1s 758us/step - loss: 1.0682 - acc: 0.6081 - val_loss: 1.0913 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 319/500\n",
      "934/934 [==============================] - 1s 784us/step - loss: 1.0683 - acc: 0.6049 - val_loss: 1.0919 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 27us/step\n",
      "Epoch 320/500\n",
      "934/934 [==============================] - 1s 742us/step - loss: 1.0679 - acc: 0.6006 - val_loss: 1.0862 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 27us/step\n",
      "Epoch 321/500\n",
      "934/934 [==============================] - 1s 754us/step - loss: 1.0685 - acc: 0.6092 - val_loss: 1.0980 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 322/500\n",
      "934/934 [==============================] - 1s 803us/step - loss: 1.0701 - acc: 0.5996 - val_loss: 1.0865 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 28us/step\n",
      "Epoch 323/500\n",
      "934/934 [==============================] - 1s 741us/step - loss: 1.0692 - acc: 0.5974 - val_loss: 1.0848 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 324/500\n",
      "934/934 [==============================] - 1s 734us/step - loss: 1.0656 - acc: 0.5996 - val_loss: 1.0907 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 22us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 325/500\n",
      "934/934 [==============================] - 1s 744us/step - loss: 1.0655 - acc: 0.6060 - val_loss: 1.1259 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 326/500\n",
      "934/934 [==============================] - 1s 830us/step - loss: 1.0671 - acc: 0.5931 - val_loss: 1.0895 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 327/500\n",
      "934/934 [==============================] - 1s 746us/step - loss: 1.0628 - acc: 0.6049 - val_loss: 1.0938 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 328/500\n",
      "934/934 [==============================] - 1s 749us/step - loss: 1.0679 - acc: 0.5942 - val_loss: 1.0796 - val_acc: 0.6010: 0s - loss: 1.0697 - acc: \n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 27us/step\n",
      "Epoch 329/500\n",
      "934/934 [==============================] - 1s 727us/step - loss: 1.0676 - acc: 0.6081 - val_loss: 1.0970 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 330/500\n",
      "934/934 [==============================] - 1s 740us/step - loss: 1.0680 - acc: 0.5964 - val_loss: 1.0837 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 24us/step\n",
      "Epoch 331/500\n",
      "934/934 [==============================] - 1s 891us/step - loss: 1.0672 - acc: 0.5996 - val_loss: 1.0898 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 332/500\n",
      "934/934 [==============================] - 1s 842us/step - loss: 1.0672 - acc: 0.6028 - val_loss: 1.0882 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 23us/step\n",
      "Epoch 333/500\n",
      "934/934 [==============================] - 1s 852us/step - loss: 1.0673 - acc: 0.6039 - val_loss: 1.0865 - val_acc: 0.5910\n",
      "293/293 [==============================] - ETA:  - 0s 30us/step\n",
      "132/132 [==============================] - 0s 40us/step\n",
      "Epoch 334/500\n",
      "934/934 [==============================] - 1s 867us/step - loss: 1.0688 - acc: 0.5996 - val_loss: 1.0812 - val_acc: 0.6060\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 27us/step\n",
      "Epoch 335/500\n",
      "934/934 [==============================] - 1s 797us/step - loss: 1.0657 - acc: 0.5985 - val_loss: 1.0894 - val_acc: 0.5960\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 336/500\n",
      "934/934 [==============================] - 985s 1s/step - loss: 1.0676 - acc: 0.5899 - val_loss: 1.0870 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 13us/step\n",
      "132/132 [==============================] - 0s 17us/step\n",
      "Epoch 337/500\n",
      "934/934 [==============================] - 1s 875us/step - loss: 1.0689 - acc: 0.6071 - val_loss: 1.0891 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 24us/step\n",
      "Epoch 338/500\n",
      "934/934 [==============================] - 1s 912us/step - loss: 1.0661 - acc: 0.5985 - val_loss: 1.0890 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 339/500\n",
      "934/934 [==============================] - 1s 750us/step - loss: 1.0677 - acc: 0.5953 - val_loss: 1.0881 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 82us/step\n",
      "132/132 [==============================] - 0s 161us/step\n",
      "Epoch 340/500\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.0646 - acc: 0.6017 - val_loss: 1.1010 - val_acc: 0.5237\n",
      "293/293 [==============================] - 0s 33us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 341/500\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.0665 - acc: 0.5910 - val_loss: 1.1045 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 52us/step\n",
      "132/132 [==============================] - 0s 48us/step\n",
      "Epoch 342/500\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.0645 - acc: 0.6071 - val_loss: 1.1074 - val_acc: 0.5486\n",
      "293/293 [==============================] - 0s 31us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 343/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0663 - acc: 0.6103 - val_loss: 1.0849 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 37us/step\n",
      "132/132 [==============================] - 0s 66us/step\n",
      "Epoch 344/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0664 - acc: 0.5996 - val_loss: 1.0941 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 345/500\n",
      "934/934 [==============================] - 1s 961us/step - loss: 1.0675 - acc: 0.6028 - val_loss: 1.0836 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 346/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0656 - acc: 0.6071 - val_loss: 1.0832 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 47us/step\n",
      "Epoch 347/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0679 - acc: 0.5996 - val_loss: 1.0912 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 37us/step\n",
      "132/132 [==============================] - 0s 55us/step\n",
      "Epoch 348/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0662 - acc: 0.6081 - val_loss: 1.0970 - val_acc: 0.5711TA: 0s - loss: 1.0569 - acc: 0\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 39us/step\n",
      "Epoch 349/500\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.0690 - acc: 0.6006 - val_loss: 1.0854 - val_acc: 0.5960\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 350/500\n",
      "934/934 [==============================] - 1s 988us/step - loss: 1.0663 - acc: 0.6039 - val_loss: 1.0803 - val_acc: 0.6035\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 351/500\n",
      "934/934 [==============================] - 1s 974us/step - loss: 1.0668 - acc: 0.6060 - val_loss: 1.0925 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 24us/step\n",
      "132/132 [==============================] - 0s 49us/step\n",
      "Epoch 352/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0665 - acc: 0.6071 - val_loss: 1.0985 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 32us/step\n",
      "132/132 [==============================] - 0s 39us/step\n",
      "Epoch 353/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0681 - acc: 0.6049 - val_loss: 1.0855 - val_acc: 0.5860- loss: 1.0949 - acc: 0.5\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 42us/step\n",
      "Epoch 354/500\n",
      "934/934 [==============================] - 1s 860us/step - loss: 1.0656 - acc: 0.5985 - val_loss: 1.0865 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 24us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 355/500\n",
      "934/934 [==============================] - 1s 917us/step - loss: 1.0672 - acc: 0.6060 - val_loss: 1.0851 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 23us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 356/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0642 - acc: 0.6049 - val_loss: 1.0932 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 40us/step\n",
      "Epoch 357/500\n",
      "934/934 [==============================] - 1s 941us/step - loss: 1.0669 - acc: 0.6039 - val_loss: 1.0846 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 358/500\n",
      "934/934 [==============================] - 1s 924us/step - loss: 1.0678 - acc: 0.6028 - val_loss: 1.0857 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 22us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 359/500\n",
      "934/934 [==============================] - 1s 932us/step - loss: 1.0647 - acc: 0.6092 - val_loss: 1.0863 - val_acc: 0.5935\n",
      "293/293 [==============================] - 0s 36us/step\n",
      "132/132 [==============================] - 0s 98us/step\n",
      "Epoch 360/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0674 - acc: 0.5985 - val_loss: 1.0881 - val_acc: 0.5935\n",
      "293/293 [==============================] - 0s 32us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 361/500\n",
      "934/934 [==============================] - 1s 908us/step - loss: 1.0668 - acc: 0.6039 - val_loss: 1.0796 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 23us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 362/500\n",
      "934/934 [==============================] - 1s 904us/step - loss: 1.0665 - acc: 0.5985 - val_loss: 1.0887 - val_acc: 0.5935\n",
      "293/293 [==============================] - 0s 17us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 363/500\n",
      "934/934 [==============================] - 1s 758us/step - loss: 1.0651 - acc: 0.6028 - val_loss: 1.0933 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 39us/step\n",
      "Epoch 364/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.0633 - acc: 0.6103 - val_loss: 1.1037 - val_acc: 0.5337\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 365/500\n",
      "934/934 [==============================] - 1s 862us/step - loss: 1.0665 - acc: 0.5985 - val_loss: 1.0820 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 26us/step\n",
      "132/132 [==============================] - 0s 28us/step\n",
      "Epoch 366/500\n",
      "934/934 [==============================] - 1s 826us/step - loss: 1.0660 - acc: 0.5964 - val_loss: 1.0856 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 367/500\n",
      "934/934 [==============================] - 1s 796us/step - loss: 1.0646 - acc: 0.6017 - val_loss: 1.0843 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 28us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 368/500\n",
      "934/934 [==============================] - 1s 802us/step - loss: 1.0651 - acc: 0.6028 - val_loss: 1.0873 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 369/500\n",
      "934/934 [==============================] - 1s 979us/step - loss: 1.0658 - acc: 0.5974 - val_loss: 1.0842 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 370/500\n",
      "934/934 [==============================] - 1s 867us/step - loss: 1.0669 - acc: 0.5974 - val_loss: 1.0875 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 371/500\n",
      "934/934 [==============================] - 1s 920us/step - loss: 1.0658 - acc: 0.5921 - val_loss: 1.0851 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 42us/step\n",
      "Epoch 372/500\n",
      "934/934 [==============================] - 1s 879us/step - loss: 1.0656 - acc: 0.6039 - val_loss: 1.0834 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 28us/step\n",
      "Epoch 373/500\n",
      "934/934 [==============================] - 1s 848us/step - loss: 1.0659 - acc: 0.5996 - val_loss: 1.0894 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 14us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 374/500\n",
      "934/934 [==============================] - 1s 908us/step - loss: 1.0650 - acc: 0.6092 - val_loss: 1.0810 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 375/500\n",
      "934/934 [==============================] - 1s 852us/step - loss: 1.0606 - acc: 0.5899 - val_loss: 1.1011 - val_acc: 0.5935\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 376/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0658 - acc: 0.5942 - val_loss: 1.0948 - val_acc: 0.5511\n",
      "293/293 [==============================] - 0s 37us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 377/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0646 - acc: 0.6006 - val_loss: 1.0771 - val_acc: 0.6035\n",
      "293/293 [==============================] - 0s 25us/step\n",
      "132/132 [==============================] - 0s 53us/step\n",
      "Epoch 378/500\n",
      "934/934 [==============================] - 1s 986us/step - loss: 1.0643 - acc: 0.6071 - val_loss: 1.0923 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 22us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 379/500\n",
      "934/934 [==============================] - 1s 997us/step - loss: 1.0678 - acc: 0.6028 - val_loss: 1.0888 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 48us/step\n",
      "Epoch 380/500\n",
      "934/934 [==============================] - 1s 984us/step - loss: 1.0640 - acc: 0.6017 - val_loss: 1.0907 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 381/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0652 - acc: 0.6006 - val_loss: 1.0891 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 24us/step\n",
      "132/132 [==============================] - 0s 50us/step\n",
      "Epoch 382/500\n",
      "934/934 [==============================] - 1s 929us/step - loss: 1.0653 - acc: 0.6049 - val_loss: 1.0850 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 34us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 383/500\n",
      "934/934 [==============================] - 1s 990us/step - loss: 1.0591 - acc: 0.6071 - val_loss: 1.1261 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 25us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 384/500\n",
      "934/934 [==============================] - 1s 879us/step - loss: 1.0684 - acc: 0.5996 - val_loss: 1.0885 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 26us/step\n",
      "132/132 [==============================] - 0s 47us/step\n",
      "Epoch 385/500\n",
      "934/934 [==============================] - 1s 972us/step - loss: 1.0671 - acc: 0.5985 - val_loss: 1.0815 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 24us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 386/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0674 - acc: 0.5942 - val_loss: 1.0837 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 387/500\n",
      "934/934 [==============================] - 1s 987us/step - loss: 1.0647 - acc: 0.6071 - val_loss: 1.0844 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 23us/step\n",
      "Epoch 388/500\n",
      "934/934 [==============================] - 1s 779us/step - loss: 1.0668 - acc: 0.6006 - val_loss: 1.0883 - val_acc: 0.6010\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 389/500\n",
      "934/934 [==============================] - 1s 884us/step - loss: 1.0640 - acc: 0.6017 - val_loss: 1.1036 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 390/500\n",
      "934/934 [==============================] - 1s 900us/step - loss: 1.0667 - acc: 0.6071 - val_loss: 1.0851 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 24us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 391/500\n",
      "934/934 [==============================] - 1s 895us/step - loss: 1.0647 - acc: 0.6006 - val_loss: 1.0852 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 392/500\n",
      "934/934 [==============================] - 1s 848us/step - loss: 1.0638 - acc: 0.6049 - val_loss: 1.0986 - val_acc: 0.5985\n",
      "293/293 [==============================] - 0s 22us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 393/500\n",
      "934/934 [==============================] - 1s 843us/step - loss: 1.0623 - acc: 0.6124 - val_loss: 1.0821 - val_acc: 0.6035\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 394/500\n",
      "934/934 [==============================] - 1s 819us/step - loss: 1.0652 - acc: 0.5910 - val_loss: 1.0868 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 395/500\n",
      "934/934 [==============================] - 1s 789us/step - loss: 1.0654 - acc: 0.5942 - val_loss: 1.0850 - val_acc: 0.5636\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 27us/step\n",
      "Epoch 396/500\n",
      "934/934 [==============================] - 1s 832us/step - loss: 1.0656 - acc: 0.6071 - val_loss: 1.0859 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 40us/step\n",
      "Epoch 397/500\n",
      "934/934 [==============================] - 1s 809us/step - loss: 1.0644 - acc: 0.5985 - val_loss: 1.0845 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 398/500\n",
      "934/934 [==============================] - 1s 864us/step - loss: 1.0650 - acc: 0.6092 - val_loss: 1.0865 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 39us/step\n",
      "Epoch 399/500\n",
      "934/934 [==============================] - 1s 859us/step - loss: 1.0642 - acc: 0.6039 - val_loss: 1.0891 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 23us/step\n",
      "132/132 [==============================] - 0s 40us/step\n",
      "Epoch 400/500\n",
      "934/934 [==============================] - 1s 845us/step - loss: 1.0654 - acc: 0.6071 - val_loss: 1.0821 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 401/500\n",
      "934/934 [==============================] - 1s 804us/step - loss: 1.0642 - acc: 0.5953 - val_loss: 1.0941 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 402/500\n",
      "934/934 [==============================] - 1s 768us/step - loss: 1.0647 - acc: 0.6081 - val_loss: 1.0819 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 23us/step\n",
      "132/132 [==============================] - 0s 62us/step\n",
      "Epoch 403/500\n",
      "934/934 [==============================] - 1s 895us/step - loss: 1.0623 - acc: 0.6028 - val_loss: 1.0875 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 404/500\n",
      "934/934 [==============================] - 1s 778us/step - loss: 1.0616 - acc: 0.5985 - val_loss: 1.0923 - val_acc: 0.5337\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 42us/step\n",
      "Epoch 405/500\n",
      "934/934 [==============================] - 1s 805us/step - loss: 1.0643 - acc: 0.6081 - val_loss: 1.0803 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 406/500\n",
      "934/934 [==============================] - 1s 866us/step - loss: 1.0656 - acc: 0.5996 - val_loss: 1.0856 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 39us/step\n",
      "Epoch 407/500\n",
      "934/934 [==============================] - 1s 916us/step - loss: 1.0644 - acc: 0.6028 - val_loss: 1.0948 - val_acc: 0.5910: 0s - loss: 1.0373 - acc: 0.\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 408/500\n",
      "934/934 [==============================] - 1s 936us/step - loss: 1.0617 - acc: 0.5931 - val_loss: 1.0808 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 42us/step\n",
      "132/132 [==============================] - 0s 49us/step\n",
      "Epoch 409/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0641 - acc: 0.6039 - val_loss: 1.0841 - val_acc: 0.5486\n",
      "293/293 [==============================] - 0s 30us/step\n",
      "132/132 [==============================] - 0s 60us/step\n",
      "Epoch 410/500\n",
      "934/934 [==============================] - 1s 979us/step - loss: 1.0611 - acc: 0.6081 - val_loss: 1.0885 - val_acc: 0.5636\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 411/500\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.0646 - acc: 0.6006 - val_loss: 1.0873 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 24us/step\n",
      "132/132 [==============================] - 0s 27us/step\n",
      "Epoch 412/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0644 - acc: 0.6071 - val_loss: 1.0809 - val_acc: 0.5935\n",
      "293/293 [==============================] - 0s 22us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 413/500\n",
      "934/934 [==============================] - 1s 948us/step - loss: 1.0611 - acc: 0.6081 - val_loss: 1.0843 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 27us/step\n",
      "132/132 [==============================] - 0s 54us/step\n",
      "Epoch 414/500\n",
      "934/934 [==============================] - 1s 786us/step - loss: 1.0639 - acc: 0.6092 - val_loss: 1.0823 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 22us/step\n",
      "132/132 [==============================] - 0s 44us/step\n",
      "Epoch 415/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0652 - acc: 0.6017 - val_loss: 1.0790 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 27us/step\n",
      "132/132 [==============================] - 0s 44us/step\n",
      "Epoch 416/500\n",
      "934/934 [==============================] - 1s 811us/step - loss: 1.0637 - acc: 0.5899 - val_loss: 1.0817 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 44us/step\n",
      "Epoch 417/500\n",
      "934/934 [==============================] - 1s 872us/step - loss: 1.0647 - acc: 0.6049 - val_loss: 1.0882 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 418/500\n",
      "934/934 [==============================] - 1s 865us/step - loss: 1.0639 - acc: 0.5942 - val_loss: 1.0827 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 419/500\n",
      "934/934 [==============================] - 1s 819us/step - loss: 1.0635 - acc: 0.6060 - val_loss: 1.0793 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 65us/step\n",
      "Epoch 420/500\n",
      "934/934 [==============================] - 1s 813us/step - loss: 1.0649 - acc: 0.6060 - val_loss: 1.0993 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 421/500\n",
      "934/934 [==============================] - 1s 895us/step - loss: 1.0645 - acc: 0.6028 - val_loss: 1.0832 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 26us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 422/500\n",
      "934/934 [==============================] - 1s 827us/step - loss: 1.0597 - acc: 0.6049 - val_loss: 1.0786 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 423/500\n",
      "934/934 [==============================] - 1s 892us/step - loss: 1.0601 - acc: 0.6039 - val_loss: 1.0855 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 25us/step\n",
      "132/132 [==============================] - 0s 39us/step\n",
      "Epoch 424/500\n",
      "934/934 [==============================] - 1s 868us/step - loss: 1.0634 - acc: 0.6039 - val_loss: 1.0962 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 425/500\n",
      "934/934 [==============================] - 1s 797us/step - loss: 1.0638 - acc: 0.6049 - val_loss: 1.0967 - val_acc: 0.5536\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 426/500\n",
      "934/934 [==============================] - 1s 927us/step - loss: 1.0642 - acc: 0.6006 - val_loss: 1.0874 - val_acc: 0.5985\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 26us/step\n",
      "Epoch 427/500\n",
      "934/934 [==============================] - 1s 840us/step - loss: 1.0631 - acc: 0.6081 - val_loss: 1.0876 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 27us/step\n",
      "Epoch 428/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934/934 [==============================] - 1s 875us/step - loss: 1.0625 - acc: 0.5996 - val_loss: 1.0800 - val_acc: 0.5960\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 429/500\n",
      "934/934 [==============================] - 1s 797us/step - loss: 1.0638 - acc: 0.5953 - val_loss: 1.0929 - val_acc: 0.5536\n",
      "293/293 [==============================] - 0s 23us/step\n",
      "132/132 [==============================] - 0s 45us/step\n",
      "Epoch 430/500\n",
      "934/934 [==============================] - 1s 786us/step - loss: 1.0638 - acc: 0.6081 - val_loss: 1.0846 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 431/500\n",
      "934/934 [==============================] - 1s 791us/step - loss: 1.0642 - acc: 0.6049 - val_loss: 1.0834 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 432/500\n",
      "934/934 [==============================] - 1s 810us/step - loss: 1.0627 - acc: 0.5996 - val_loss: 1.0781 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 433/500\n",
      "934/934 [==============================] - 1s 891us/step - loss: 1.0635 - acc: 0.6049 - val_loss: 1.0867 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 25us/step\n",
      "132/132 [==============================] - 0s 48us/step\n",
      "Epoch 434/500\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.0637 - acc: 0.6049 - val_loss: 1.0822 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 435/500\n",
      "934/934 [==============================] - 1s 840us/step - loss: 1.0637 - acc: 0.6049 - val_loss: 1.0853 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 13us/step\n",
      "132/132 [==============================] - 0s 19us/step\n",
      "Epoch 436/500\n",
      "934/934 [==============================] - 1s 958us/step - loss: 1.0599 - acc: 0.6039 - val_loss: 1.0817 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 437/500\n",
      "934/934 [==============================] - 1s 972us/step - loss: 1.0649 - acc: 0.6060 - val_loss: 1.0778 - val_acc: 0.5935\n",
      "293/293 [==============================] - 0s 26us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 438/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0614 - acc: 0.5985 - val_loss: 1.0940 - val_acc: 0.5935\n",
      "293/293 [==============================] - 0s 22us/step\n",
      "132/132 [==============================] - 0s 82us/step\n",
      "Epoch 439/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0625 - acc: 0.6049 - val_loss: 1.0871 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 39us/step\n",
      "Epoch 440/500\n",
      "934/934 [==============================] - 1s 923us/step - loss: 1.0616 - acc: 0.5985 - val_loss: 1.0768 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 23us/step\n",
      "132/132 [==============================] - 0s 28us/step\n",
      "Epoch 441/500\n",
      "934/934 [==============================] - 1s 976us/step - loss: 1.0650 - acc: 0.6071 - val_loss: 1.0838 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 22us/step\n",
      "132/132 [==============================] - 0s 49us/step\n",
      "Epoch 442/500\n",
      "934/934 [==============================] - 1s 961us/step - loss: 1.0623 - acc: 0.6060 - val_loss: 1.0901 - val_acc: 0.5960\n",
      "293/293 [==============================] - 0s 23us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 443/500\n",
      "934/934 [==============================] - 1s 932us/step - loss: 1.0631 - acc: 0.6113 - val_loss: 1.0886 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 24us/step\n",
      "132/132 [==============================] - 0s 46us/step\n",
      "Epoch 444/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0642 - acc: 0.6092 - val_loss: 1.0871 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 23us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 445/500\n",
      "934/934 [==============================] - 1s 936us/step - loss: 1.0643 - acc: 0.6060 - val_loss: 1.0808 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 446/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0649 - acc: 0.6092 - val_loss: 1.0783 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 23us/step\n",
      "132/132 [==============================] - 0s 44us/step\n",
      "Epoch 447/500\n",
      "934/934 [==============================] - 1s 896us/step - loss: 1.0609 - acc: 0.6039 - val_loss: 1.0825 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 448/500\n",
      "934/934 [==============================] - 1s 923us/step - loss: 1.0615 - acc: 0.5964 - val_loss: 1.0782 - val_acc: 0.5885s - loss: 1.0474 - acc: 0\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 48us/step\n",
      "Epoch 449/500\n",
      "934/934 [==============================] - 1s 823us/step - loss: 1.0630 - acc: 0.6060 - val_loss: 1.0785 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 53us/step\n",
      "Epoch 450/500\n",
      "934/934 [==============================] - 1s 830us/step - loss: 1.0623 - acc: 0.5931 - val_loss: 1.0901 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 451/500\n",
      "934/934 [==============================] - 1s 864us/step - loss: 1.0634 - acc: 0.6124 - val_loss: 1.0808 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 452/500\n",
      "934/934 [==============================] - 1s 832us/step - loss: 1.0643 - acc: 0.5964 - val_loss: 1.0863 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 453/500\n",
      "934/934 [==============================] - 1s 797us/step - loss: 1.0607 - acc: 0.5974 - val_loss: 1.0909 - val_acc: 0.5935\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 454/500\n",
      "934/934 [==============================] - 1s 806us/step - loss: 1.0605 - acc: 0.6039 - val_loss: 1.0957 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 25us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 455/500\n",
      "934/934 [==============================] - 1s 832us/step - loss: 1.0638 - acc: 0.6017 - val_loss: 1.0779 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 14us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 456/500\n",
      "934/934 [==============================] - 1s 817us/step - loss: 1.0641 - acc: 0.5953 - val_loss: 1.0808 - val_acc: 0.5960\n",
      "293/293 [==============================] - 0s 14us/step\n",
      "132/132 [==============================] - 0s 39us/step\n",
      "Epoch 457/500\n",
      "934/934 [==============================] - 1s 821us/step - loss: 1.0627 - acc: 0.6049 - val_loss: 1.0838 - val_acc: 0.5736\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 458/500\n",
      "934/934 [==============================] - 1s 792us/step - loss: 1.0643 - acc: 0.5985 - val_loss: 1.0765 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 459/500\n",
      "934/934 [==============================] - 1s 807us/step - loss: 1.0625 - acc: 0.5985 - val_loss: 1.0796 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 460/500\n",
      "934/934 [==============================] - 1s 792us/step - loss: 1.0628 - acc: 0.6039 - val_loss: 1.0775 - val_acc: 0.5860\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 461/500\n",
      "934/934 [==============================] - 1s 811us/step - loss: 1.0627 - acc: 0.6060 - val_loss: 1.0755 - val_acc: 0.5960\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 462/500\n",
      "934/934 [==============================] - 1s 775us/step - loss: 1.0576 - acc: 0.6039 - val_loss: 1.1139 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 463/500\n",
      "934/934 [==============================] - 1s 826us/step - loss: 1.0629 - acc: 0.6039 - val_loss: 1.0844 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 25us/step\n",
      "Epoch 464/500\n",
      "934/934 [==============================] - 1s 776us/step - loss: 1.0624 - acc: 0.5889 - val_loss: 1.0793 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 465/500\n",
      "934/934 [==============================] - 1s 775us/step - loss: 1.0631 - acc: 0.6039 - val_loss: 1.0782 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 53us/step\n",
      "Epoch 466/500\n",
      "934/934 [==============================] - 1s 794us/step - loss: 1.0629 - acc: 0.6060 - val_loss: 1.0907 - val_acc: 0.5960\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 49us/step\n",
      "Epoch 467/500\n",
      "934/934 [==============================] - 1s 931us/step - loss: 1.0602 - acc: 0.5899 - val_loss: 1.0841 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 22us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 468/500\n",
      "934/934 [==============================] - 1s 833us/step - loss: 1.0556 - acc: 0.6081 - val_loss: 1.0790 - val_acc: 0.6035\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 39us/step\n",
      "Epoch 469/500\n",
      "934/934 [==============================] - 1s 837us/step - loss: 1.0629 - acc: 0.6049 - val_loss: 1.0870 - val_acc: 0.6035\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 50us/step\n",
      "Epoch 470/500\n",
      "934/934 [==============================] - 1s 858us/step - loss: 1.0629 - acc: 0.6039 - val_loss: 1.0772 - val_acc: 0.5935\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 49us/step\n",
      "Epoch 471/500\n",
      "934/934 [==============================] - 1s 768us/step - loss: 1.0615 - acc: 0.6167 - val_loss: 1.0805 - val_acc: 0.5636\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 33us/step\n",
      "Epoch 472/500\n",
      "934/934 [==============================] - 1s 756us/step - loss: 1.0598 - acc: 0.6049 - val_loss: 1.0894 - val_acc: 0.6035\n",
      "293/293 [==============================] - 0s 14us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 473/500\n",
      "934/934 [==============================] - 1s 781us/step - loss: 1.0612 - acc: 0.6028 - val_loss: 1.0865 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 474/500\n",
      "934/934 [==============================] - 1s 765us/step - loss: 1.0614 - acc: 0.6071 - val_loss: 1.0869 - val_acc: 0.5561\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 475/500\n",
      "934/934 [==============================] - 1s 767us/step - loss: 1.0611 - acc: 0.5964 - val_loss: 1.0778 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 39us/step\n",
      "Epoch 476/500\n",
      "934/934 [==============================] - 1s 785us/step - loss: 1.0605 - acc: 0.6028 - val_loss: 1.0886 - val_acc: 0.5536\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 477/500\n",
      "934/934 [==============================] - 1s 771us/step - loss: 1.0612 - acc: 0.6081 - val_loss: 1.0750 - val_acc: 0.5711\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 478/500\n",
      "934/934 [==============================] - 1s 763us/step - loss: 1.0618 - acc: 0.6124 - val_loss: 1.0844 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 37us/step\n",
      "Epoch 479/500\n",
      "934/934 [==============================] - 1s 768us/step - loss: 1.0601 - acc: 0.6146 - val_loss: 1.0739 - val_acc: 0.6035\n",
      "293/293 [==============================] - 0s 17us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 480/500\n",
      "934/934 [==============================] - 1s 774us/step - loss: 1.0628 - acc: 0.6039 - val_loss: 1.0891 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 23us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 481/500\n",
      "934/934 [==============================] - 1s 792us/step - loss: 1.0589 - acc: 0.6049 - val_loss: 1.0892 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 482/500\n",
      "934/934 [==============================] - 1s 792us/step - loss: 1.0579 - acc: 0.6060 - val_loss: 1.0733 - val_acc: 0.5885\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 42us/step\n",
      "Epoch 483/500\n",
      "934/934 [==============================] - 1s 790us/step - loss: 1.0601 - acc: 0.6028 - val_loss: 1.0756 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 484/500\n",
      "934/934 [==============================] - 1s 800us/step - loss: 1.0601 - acc: 0.6017 - val_loss: 1.0768 - val_acc: 0.5810\n",
      "293/293 [==============================] - 0s 25us/step\n",
      "132/132 [==============================] - 0s 30us/step\n",
      "Epoch 485/500\n",
      "934/934 [==============================] - 1s 815us/step - loss: 1.0612 - acc: 0.6103 - val_loss: 1.0780 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 19us/step\n",
      "132/132 [==============================] - 0s 36us/step\n",
      "Epoch 486/500\n",
      "934/934 [==============================] - 1s 887us/step - loss: 1.0606 - acc: 0.6113 - val_loss: 1.0806 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 25us/step\n",
      "132/132 [==============================] - 0s 47us/step\n",
      "Epoch 487/500\n",
      "934/934 [==============================] - 1s 925us/step - loss: 1.0628 - acc: 0.5964 - val_loss: 1.0785 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 488/500\n",
      "934/934 [==============================] - 1s 907us/step - loss: 1.0625 - acc: 0.6028 - val_loss: 1.0953 - val_acc: 0.5960\n",
      "293/293 [==============================] - 0s 16us/step\n",
      "132/132 [==============================] - 0s 28us/step\n",
      "Epoch 489/500\n",
      "934/934 [==============================] - 1s 854us/step - loss: 1.0601 - acc: 0.6103 - val_loss: 1.0823 - val_acc: 0.5835\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 38us/step\n",
      "Epoch 490/500\n",
      "934/934 [==============================] - 1s 869us/step - loss: 1.0615 - acc: 0.5996 - val_loss: 1.0831 - val_acc: 0.5686\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 491/500\n",
      "934/934 [==============================] - 1s 825us/step - loss: 1.0605 - acc: 0.5985 - val_loss: 1.0859 - val_acc: 0.5461\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 34us/step\n",
      "Epoch 492/500\n",
      "934/934 [==============================] - 1s 776us/step - loss: 1.0629 - acc: 0.6017 - val_loss: 1.0860 - val_acc: 0.5935\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 29us/step\n",
      "Epoch 493/500\n",
      "934/934 [==============================] - 1s 845us/step - loss: 1.0612 - acc: 0.6135 - val_loss: 1.0812 - val_acc: 0.5885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 0s 22us/step\n",
      "132/132 [==============================] - 0s 31us/step\n",
      "Epoch 494/500\n",
      "934/934 [==============================] - 1s 805us/step - loss: 1.0604 - acc: 0.6028 - val_loss: 1.0800 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 35us/step\n",
      "Epoch 495/500\n",
      "934/934 [==============================] - 1s 780us/step - loss: 1.0584 - acc: 0.6167 - val_loss: 1.0777 - val_acc: 0.5910\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 40us/step\n",
      "Epoch 496/500\n",
      "934/934 [==============================] - 1s 795us/step - loss: 1.0616 - acc: 0.6071 - val_loss: 1.0884 - val_acc: 0.5611\n",
      "293/293 [==============================] - 0s 25us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 497/500\n",
      "934/934 [==============================] - 1s 811us/step - loss: 1.0612 - acc: 0.6081 - val_loss: 1.0837 - val_acc: 0.5761\n",
      "293/293 [==============================] - 0s 20us/step\n",
      "132/132 [==============================] - 0s 80us/step\n",
      "Epoch 498/500\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0618 - acc: 0.6049 - val_loss: 1.0827 - val_acc: 0.5586\n",
      "293/293 [==============================] - 0s 18us/step\n",
      "132/132 [==============================] - 0s 32us/step\n",
      "Epoch 499/500\n",
      "934/934 [==============================] - 1s 920us/step - loss: 1.0583 - acc: 0.6092 - val_loss: 1.0920 - val_acc: 0.5786\n",
      "293/293 [==============================] - 0s 21us/step\n",
      "132/132 [==============================] - 0s 41us/step\n",
      "Epoch 500/500\n",
      "934/934 [==============================] - 1s 887us/step - loss: 1.0607 - acc: 0.6092 - val_loss: 1.0756 - val_acc: 0.5661\n",
      "293/293 [==============================] - 0s 15us/step\n",
      "132/132 [==============================] - 0s 36us/step\n"
     ]
    }
   ],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.weights = []\n",
    "        self.cyt_tr_hist = []\n",
    "        self.cyt_te_hist = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.weights.append(model.layers[2].get_weights())\n",
    "        self.cyt_tr_hist.append(model.evaluate(cyt_x_tr,cyt_y_tr_class)[0])\n",
    "        self.cyt_te_hist.append(model.evaluate(cyt_x_te,cyt_y_te_class)[0])\n",
    "        \n",
    "\n",
    "history = LossHistory()\n",
    "\n",
    "model_hist = model.fit(X_tr, y_tr_class, validation_data=(X_te,y_te_class),\n",
    "                  batch_size = 1, nb_epoch = 200,callbacks = [history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CYT_his = []\n",
    "for record in history.weights:\n",
    "    CYT_his.append([record[1][0],record[0][0][0],record[0][1][0],record[0][2][0]])\n",
    "\n",
    "CYT_w = DataFrame.from_records(CYT_his,columns=[\"bias\",\"w1\",\"w2\",\"w3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.682404</td>\n",
       "      <td>-0.112895</td>\n",
       "      <td>0.056038</td>\n",
       "      <td>0.872768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.767818</td>\n",
       "      <td>-0.103707</td>\n",
       "      <td>0.138264</td>\n",
       "      <td>0.967024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.763326</td>\n",
       "      <td>-0.135007</td>\n",
       "      <td>0.175587</td>\n",
       "      <td>1.010575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.700335</td>\n",
       "      <td>-0.196370</td>\n",
       "      <td>0.186410</td>\n",
       "      <td>1.031065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.634555</td>\n",
       "      <td>-0.268309</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>1.072522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias        w1        w2        w3\n",
       "0  0.682404 -0.112895  0.056038  0.872768\n",
       "1  0.767818 -0.103707  0.138264  0.967024\n",
       "2  0.763326 -0.135007  0.175587  1.010575\n",
       "3  0.700335 -0.196370  0.186410  1.031065\n",
       "4  0.634555 -0.268309  0.207100  1.072522"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CYT_w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn8AAAJ7CAYAAACS3/ftAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd4FNX+x/H32U3vhSR0kC7YxYbSVGxYLupVr9gLtp9i77031GsBO6iIvaDXe7GCCojSRKX3EhLSQ7Ip287vj92EYgIhJGzK5/U8+2w7M/OdnYX95MycGWOtRURERERaB0eoCxARERGRPUfhT0RERKQVUfgTERERaUUU/kRERERaEYU/ERERkVZE4U9ERESkFVH4E2khjDFRxphKY4w1xry5k7ZPBdtZY8zbO2n72FZtOzZgvT22mu9RDTXfPTX/ps4Yc2xjbDcRaf4U/kRaCGttBTA7+HTgTpoPrOXxjtqusdZuqE9tzZUClIi0RAp/Ii3LT8H7HsaYdjU1MMbEAAcFn1YCXWsLNsaYKKD/dvMWEZFmTOFPpGXZOqDV1qN3OBAOrABmBF8bVEvbQ4HIGua926y1K6y1Jnib3pDzFhGR2in8ibQsMwBf8HFt4a/q9enBW13agnr+RERaBIU/kRbEWlsCLAg+bcjwl22tXV5TAxPwT2PM58aYzOCgkwJjzI/GmCuNMeG1TFenARnGmDOMMT8YYwqNMaXGmD+NMXcGB7jU+Zg8Y0y4MeYGY8w8Y0xJ8DbLGHOZMcZs1zbMGGOBb7d6ef1Wy7LGGG8N87/aGDPVGJNrjPEEP4elxpgvjDHXGmNSd1TjTupPMsbcboz5OTj/SmPM+uDzO4wxXXcyfZwx5n5jzEJjTJkxpihY64idTLefMeau4PbMCa5XsTFmQXDgUK2f+/bbp741BOfV3RjzZnCdK4L3bxlj+gbf3xBczt07mEdM8DvwU/AzdBtjsowxnxljTthZDSIthrVWN910a0E34FnAEugBTNruvTCgNPh+LyAO8AJ+IHW7tk6gONj2w1qWlQJMC7ap7fYr0KaGaXts1eaoGt43wCs7mO884PStnnfcwfxPBGbuYF4v1/A57WidLODdqn088FsdpvlHPbfpMCB/J/P+eLtpjt3qvUOBJTuY9vZalntwHdapGDi6lul3u4at5uOqZToXcDywIfj87lrmcQCwbifr8hrgDPW/Yd10a+ybev5EWp6q3bMO4Mjt3jsIiAVyrLXLrLWlBHoKDbB979v+QMJ286wW7NH7HzCYwA/wfcB+BALhXsD/AYUEfvQ/NMbs6v831wGjgo9nAEcDbYCewL1AP+CpOs7rRWBf4HYCoTcVGMCWYx6vMMYcXdXYWuslEOhO2WoevYOvVd0St3rvTuAQAoH7IeBAIB3oFFzOVcDPBEL2LjHGHAF8ReBzLQBuI7DuKUAX4FTgDaBsB7N5D0gGriawbdoAxwGLgu8/ZIzpVcN0FpgF3ErguNCeBD67vYHzCATwBOAjY0z6TlalXjUEexY/BWIIfJ+uAjoDGcAIAqHvXQLbpEbBXtGpBLbHGuByAn8cpBD4XowhsG0uA+7ZyXqINH+hTp+66aZbw94I/Kj6CfxwP77dezcFX/90q9f+HXzt6e3ajmZLj8h+NSzn1uB7buDIWmrZH6ighl4vdtDzRyCgVvU6zgIia5j3SLbttdlRz5+nphoJBIbsYJuJNbx/bG3z367dgmCbpxp4WzqApcF5bwK676Bt2A5qLwZ61jBN5622z8P1qC88uH0scM9OPr961UAg2FZtw/41vJ8OZG61nL/1/AH/Db63lhp6oYNtrgi2qQDaNuR21E23pnZTz59IC2OtzQMWB59ufyxf1fOft3ptxk7aFgJ/1rCo64L3Y621M2p4H2vtAuCD4NOROyh7e/9gS6/jbdbayhrm/S5bzmu4M+/VVKMNHCP5SfDpIbtQ3/bCgveZuzGPmpxIoKcS4GZr7craGtpAb2Vt/m1rOGbTWrsO+D74dJfX31rrASYFnw7bSfNdrsEYEwGcHXw60Vo7p4bpc4BHaluoMaYngc8RYHTw30dNXiXQKxgJnFH7aog0fwp/Ii1TVbjrb4yJhsDADLbs2p1eQ9uDjDGxW71e3dZaa7eeuTFmb6BD8Om04IH8Nd7YEhz7U3cDgvdF7HiU8eQ6zu9/O3hvafC+bR3nVZP5wfvbjTHDjTHO3ZjX1o4J3pezJUTXR73X3wScYYz5yBizyhjj2nrgC4GeYwjsFm/oGvYn0AsM8MUOpt/R9+DY4L0XmLWD72ks8Eew7a58V0WanbCdNxGRZugnAruxIoDDCAzK2JvA8VoutoQVrLVZxpjVBI7DOgL4LnjsVUawyda9hFW2/qH/rI41pe1C/V2D98u3D57bWVLH+W3cwXtVx8rF1HFeNbmXwPGBGcB/gAJjzM8EQvZUa+3ces63e/B+sbXWvRv11Wv9g38MfM6WALUjiTt5vz41dN3q8VJqYa3NNMaUEhjAtL2q72oYkLWTGqvsyndVpNlRz59Iy/TjVo8Hbnc/q4ZdhNuf8mVn5/fb2Q99TaJ2oW1Vb49rJ+1K6zg/386bYHbepGbW2lUEBtO8QyDIpACnERiQMscYs9wY8696zLpq13dJfWsLqu/6P8eW4/bGA8MJHEuZypaBL9cG2+6sM6E+NWzdE13f70Jjf1dFmh2FP5EWyFqbCawOPt0+0NV0NY3awp8LqKnXausf2j52y5U6dnTblT0NVT/0sTtsVXNPT0hYa1daay8gMKL1KOAWYAqB3Y09gEnGmGt2cbZVoa/WkayNJbgr9ILg00ettZdYa/8bXM8Ca22pDYwWj27EMrYOfPX9LlR9V7Pr+D011tq69HSKNFsKfyItV1WP3RHGmDBqHuxRpSr8HR48hUtV219qGUiwaqvHB+52pX+3Nnjfc/sTMG9nZ8eZ7XHWWre1doa19mlr7YkEdt2uCL59307WZ3tV0+0dHPywJ/UlcNgABE7TUpt9G7GGtVs9rulUNAAYY9pTe/ir+q62NcbsznGdIi2Gwp9Iy1UV8uII7ILsTPCg9xraLiZwEuFoAueN6xZ8vbbBFguAnODjixui2O1UjcxNovarj0BgvRqTZ6vH9RrEERzN+mrwaRqBU/HUVdUVRqKBs+qz/N0QudXjGtfdGJNA4PvSWBawpfdvR8vZ0ffgm60eN8Z3VaTZUfgTabm2Dm53Bu9/t9b+7dip4KCKmdu1hZp7CbHW+gkcDwZwnDHm2praVTGBS7F1rlPVAZPZssvz8Zp6vYLH0B26C/Osj/ytHrevqUFwNGytvVJBVQM3vMDmXVj+12wZ6PC0MWav2hoGe3cb0ta9u38LV8EezBep3zF1dRI8xc+HwafnGWMOqqGONsBdO5jHQrYEwLuNMYfvaJnGmAxjTKOtk0hToPAn0kIFz6lWNbqx6kezxjAXVLXrt6qtm5p7CauMYUtgfN4Y87Ex5nhjTDsTuA5tN2PMycaYFwhcVuv0Xai9lMAVQ2DLCOQhxpjU4DVe7yIwAGFVrTNpGMvYcszYHcaYnsaYSBO49m9Vb5gTWGKM+dYYc5Ux5iBjTLoxJi34+Bm2XKnk05rOWVibYMi+mEAPZAbwmzHmZmPM3sHPuKMx5iRjzCsETobcYILHjVb1wN5tjLnbGNPbGNPGGDOYwImTz2fLFToay/0EtkE48I0x5orgeqcZY04j8L2NYseh+gogj8Bo4mkmcE3iw4LrkmqM6WuMGWmMeZ/AruZaQ7ZIixDqs0zrpptujXcjcG64ra+CcfoO2g7Yru30Osw/kcD513Z2/VcLXLXdtHW5tu/rO5jffAIn46163nZX5r9Vu8uCbby1vP9kLcv3Bt+vy3WALYGBM2n13I7HEzjZ9o7mv6Nr++7o6iQPB9usqOG9fgQuKVfbMt8lcKm0Gj+/hqhhq/Uvq6WGMuAEtlzlo7brFPdlx9cWrrr5gX6h/rerm26NeVPPn0jLtv0xezWN9K0yh8ClrWqb9m+stcXW2lMJXN3hHQI9cWUEeqpyCfQcPQDsb60dtwt1YwMuI3Cs248ELg9WBiwk0Ct4JNteK3d3T4dSm9sJXM3kVwK9S9ucd9AGBsT0J3DN3SkEegtLCHwG2QR23V4GHGatza1PAdbarwnsOr6PwFVNigj0zK4n0Jt7G3Bjfea9k+UuJNAT/CaBcOUhcKzn98BIa23VJfYaVXD99wMmEDhfoDtYz7sEPtcpbBnwUeP3wFq7iMDglIsJnIuxaj4VBD7H/xG4HnXH4HqLtFjG2kb/dysi0iiMMbcQ6JkrstYmh7oeCQ1jTBpbBiD9w1pb1yu/iLRK6vkTkebslOB9fa+gIS3DKVs91ndBZCcU/kSkyTLGpOzgvXPZchqYD2trJ83fTr4HGQQOLYDAeSk37JmqRJov7fYVkSbLGJNH4DivLwgcrO8jcA7CkQSOz3ISOMbuAGtteYjKlEZmjHmNwKl23gZ+IzD4JRU4Brgb6BRsOsxa+11IihRpRhT+RKTJMsZ42fHJldcDx1trF++hkiQEjDGvA5fuoIkfuMFa+/weKkmkWWvok4KKiDSkcwmcxuMQAue5SyYw4nYJgd7AsdbaxhrlK03HvwmMnB5KoJcvjUAvcCaBkeDPW2v/Cl15Is2Lev52ICkpyfbo0SPUZUg9uFwuYmN3dh14aaq0/Zo3bb/mTduv+Zo7d26etTZtZ+3U87cDGRkZzJkzJ9RlSD1MmzaNIUOGhLoMqSdtv+ZN26950/Zrvowxa+vSTqN9RURERFoRhT8RERGRVkThT0RERKQVUfgTERERaUUU/kRERERaEYU/ERERkVZE4U9ERESkFVH4ExEREWlFFP5EREREWhGFPxEREZFWROFPREREpBVR+BMRERFpRRT+RERERFoRhT8RERGRVkThT0RERKQVUfgTERERaUUU/kRERERaEYU/ERERkVZE4U9ERESkFVH4ExEREWlFFP5EREREWhGFPxEREZFWROFPpJXxu93k/PvfZN54I66ZM2ttl//Gm+SMGYO1dsu05eW1z7eigtKff96mPUDF4sVUrlpV5/qsteD317m9iIjsGoU/kVbC73aTdf/9rBgylPxxL+Oa+QvrLh9F6fQZ5L/+OpUrV2I9Hjbedjv5b7xJ7nPPkf/a6xROfBd/RQVlc+aw7LDDKf7ySyAQ0rIffZS8V14FIO/ll1l/+SgKJrxVHQArV69mzbkjWXXqaeSPn1CnOvPGjaPNXXfjLytrlM+hJv7KSryFhXtseSIioaTwJ9ICFX36GZk33Yzf5SJv3DgK3n6HdZdcQtH7HxB7xBF0ev11un89BWdiIusvu4ycp8ewavjJrLv4EoonTybnqaewPh9R/fqx6ZFHWDnsOPLGvYx1u8m+735yX3iRrLvvpvDtd8gbOxbf5s2UfP0NGEPOE0+w9OD+lEydysabb8EREUHcoEHkPPEEBZMmAeDbvBl/WRnuDZlYa9k85WtcM2fiKyqi4PU3cBYWUvTpZ9XrY62l5IeprDz+BLLuva/69fI//2L9lVcF5uP3U/zVV3hycmr8TPxuN7nPP483L2+b1wvf/4Bl/Q9hxTHH7jQA+kpdbP72Wzybclhx/PGUzZ5d300kIhIyYaEuQER2n3v9ejY98QQVfy3EERmJe+1aAEyYk+LJXwDgTEmh3aOPknT6iOrp2j34AHljx5F+800UffY5m7/8kthBA/Hm5hG9/35k3H47Jd9/T9btd+CaMYP4YcNwr19P3tixYC2xA47ANfMXcp97Dvfq1aTfeismMoLCie+y4f+uBZ+PDi88T/zQoWy4bjSbHnqY0mnTcP30c3UNUfvuS8Wff1bX6C8rw5ueTsH48cQNPIqNt9+Bd9MmPBs3YqKiKPrkE+KHHYs3N4+8V17Gs3YdlatXEZ6eQdns2SSccgodnnqyev6uWb+S+9xzJJx8Mnljx+ErLaXtnXcCgRCaM2YM4V06416xkpJvviUsI53offelcNJ7xA0dSvQ+/fBt3oytrCRv3DgKJ71H7MCBeNauI//1N4g55JC6baMNmTiiowhLTd3mdb/LhSM2tvp56fQZOCIj6jzfuvJkZ1Py3fckjzwXvF6y7r6b5JEjid5vPwCs3w9eLz6Xi7Dk5JrXYd06fAUFRB9wQIPVVblqNYUTJ5Jx+22YiIh6zmMVnqws4o48ssHqEmnJzPbH58gWvXv3tkuXLg11GVIP06ZNY8iQIaEuo9FYnw/jdAKwecrXbLzzTowxxA8bhq+khLCUFIo+/xw8HiK6daPz+PGEpbXBOGrv7Ld+PyXffkfs4YfhiI8HYzDGAJD7/PPkjR3HXp9+QlTfvvjdbvB6MdHRrD79DCoXLwZj6PnTj4SlpVH++++sGXkeSaePoN1DDwGBYwLXXXoZ5XPnknT22YS3b4/f5SL/9deJPfww4gYPpmz+70T16cMyv4/k51/AkZiIdbuJGziQ2IFHEXvEEaw84UTweqvrTrv+ego//AAAZ3wC7vXr6TVjOr7iYqzXR+ZNN1Kx4A8ICwOvF0dsLO0efgiMoeSbb9n83/+y12efsmH09Xjz8rBlZeBwgN9PePv2xB9/PIXvvw/GYD0e8Hi2fGjG0O0/XxLZvTt5r7yKv7SU9JtuxJOdTeG7k0i94gqccbH4iopYefwJWGtp9+CDJJxwPJWrV7PpscdwTZ9Bp5fHYd1uwtu3Z83I88Dvp+t7k4jq27d6Uf6KChxRUVu2l7XV22en3xdrWXfhRZT99htdP/oIW1nB2vPOJ/rgg2n34ANsvPU23KtXg9MJfj89fvgeR0wMZXPnEXPQgdWhbM3I86j46y+6Tf6ciK5dq+fvzcsj+4EHidpnH1Ivv4wff/qJwYMHg9+Pv7yckm++JeHk4ZjwcDbedhsxBx1MWHo67rVrca9eTdGHH9Jx7Fjijx5ap/XZ3tqLLqZs9my6vDWBmP796zWPuqj6vazL526D3xMTHr7by/UWFGC9XsLT03d7XnXR0v//bMmMMXOttTv9R6DwtwMKf81XS/7PK/ell8h/5VXiBg/Gs2kTFX/8QdT++9HxuecIb9euut26y0fh+vln2lz7f6Rdc81uLdP6/bhXriSyZ8+/vVexaBEl3/9ARNeuJJ5ycvXrnuxswtLTtwmc/rIyKlevJrpfv+rX3OvWEda2LY6ten2mTZtG7+9/oOijj0i/+SZSL7us+r2cZ56lculS2lxzNRhD9L77Vr/nmvUr6y66iKj996Pir4UQHDziTE7GV1hI3NChlE6duqV4p5OUCy4g47ZbyRnzDPmvvUbsoIE4YmOJ6rM3uc89B9aSeNppVK5YQeWqVSSePJyijz4mddQoCsaPx3o8ROy1VyA8AV3em0T+q69ROnUqKRddRMbtt5H96KMUTnyXyF69qFyyhOgDDqBiyRJMRASOmJhAUC0vD4ROY3CmJOOIiGSvTz7GmZREyQ8/sOG60cQffTSJ/ziNnDHP4C8tJeXCC0k5/zz8ZWU4ExOx1lLx10Ki+u6NcTrxZGaS+8KLlP/xB+7goJvUK6/AOJyB3lsI1BAbG/jDobCQkm+/pc3VV1E8+Qs8mZmkXHIJyeecjb+0lNWnnwFARI/uxA8bRmS37pgwJ5ueeBJvbi74fDhTU9l88MF0O/ggcsY8gzMlBW92Nhl33I4zJYWNt9xKeMeOmPBw3GvW4IiNxV9aSsJJJ9H+8cfIevBBEo47jrhBg2r8LlYsW0b2PfcSte++pF5+OSYinOVHDQSfj7CMDLr950uc8fFbvodZWdXfmdgjjyTpjNMp+e47Us4/n5Jp00gYNqw63FYFauvz4SssJKxNm+r5lP/5F5mjR5P4j9NIu+666va+ggI2/+c/JP3rX9Xf4U1PPUXhpPeI7N6dLpPe3ea7XTZ/PkUff0zSGWcQc9BB1a978/NxzZxJ3KBBOBMTt1nntRdehCc7i+5ffYWtrMQ1axZxQ4du82/Lut3gdFb/UVgTf0UFJiwME7Zlp19Nf0S05P8/WzqFvwag8Nd8tcT/vDybcih8bxL5L79CVL9+eAsKCEtJIfEf/yDp7LO2+YEBKPr8c7LuuZfu//mSiC5dQlR1/UybNo1Bhx9O6U8/EX/00dv8WO2I9flYefwJ+IqKSDrrLLw5OVQuXUL7J59k0+NP0P7JJymfPx9ncjLO+DjC0tIIS0sDAiEh7+VXSL/pRpwJCQBsnjIFZ0ICsQMGYN1uvEVFOKKjKZjwFqmXXoJ7wwZKf/yRkq+/IbJ7N0pnzAQDvtw8wtq3w7sph6g+fahYuJCks86i7T13kzfuZVwzZhDRtStpN96Ie/Vq1l1yCfHDhlE+bx7xxx9P4ikns/a88wlr25awlBQqli8nLDUVb24utqICZ0oKUX1645r5C464OLCWbv/9isKJ75L/2mukXX89iaeczOqzz8FfUkLM4YcR0aEDlctX4CsqxBEXj7+8HL/LRUTnzrR77FHC09Ox1rLy2GF4MjMxMTHEHHggrt9+C3y4fj/4fGTceQeF707CvX599ajsiG7daP/Uk7hXraJ48he4pk/HREcTlpqKMzUFf0kp/opyrNuDv7QUW1GxzXYL79gRb14eqaMuJ+/5FyA8nE4vvVgdAAs/+oiCCW8RP+xYCt+dBA4HtqwMZ1IS8cOGUThpEm3vv4/sBx4k8dRTiT9uGHFDhuBeu461556Lv6KCqH36UT5nbiBsulyEpafjzckh4847SLngAgA23nYb3rx8nIkJbP7fFOKGDqXtffeCMaw64UT8ZWU44uLo+uEH5Dw9hsrly3EmJ1Pxxx+0fehBks48k8olS1g94nSi+x9M+Zy5xPTvj7NNG+IGDSJqn36s/seIwB8kaW3oNnky1u2mbM5ccv/9bzzr12Oio2n3wP2UzZmL9XhIOuN01l54Efh8tH/6acrmzKbo/Q9o+8ADeDZuJOmM0wlv25Y1547E+ny0e/BBXL/8gq+wkPSbbgSHA+Nw4C8rqw7vHV94nsiePdn8zTdsevQxOr3yMlG9e2/z76+2/z93pcd5e/6KCgonTqRs9hzaPfLwNuFaGobCXwNQ+Gu+WlL4sx4P2Q89TNEnn4DPR/xxx9H+6af+Fvb+Np21+PLyqsNNc7I7289XVIQJD9/mOLo9ZfOUKRRMeIuIHt1JHz2anKefxr12HfHDjiX5/PNr3Wbe3FycbdqAzxfovTGGzVOmUDjxXUxEBCYqirb33I0jNhbXrFlE77cfYRkZFLzxBmVz5+GaPp2w9HQ8mZk44uIwkZE4k5Lw5uTQddK71T22BW+/w6ZHHwVjSL1iFGnXXfe3QwFynn6a/NffCATI00ew+tTTiNy7D5UrVhDVsxed33wDCAygca9Zg3dTDjGHHoIjMjLwekUFi4YejbOwkK4ff0z0Pv3YPGUKmdffgDMlhQ7PPcu6Sy4FY0g8+WRKf/iBjmNfCgQcr5foAw7Aut1UrllDm1GX4yspoeDtdzBhYdjycqL7H0z7x5/AX+Ziw9XX4NmwgfD27en+/XdseuhhCoODipLOOgvX9On4Kyvp8s47RHTtwrpLLqV8/nzihg6lZEpgwJMzrQ3dPv+ciqVLWXPGmdWfQ9zRR+OaNQtHVBRRe++N69dfaf/oI2y89TYI9p45ExLw5uTgTEzExMZgXWUQFoatrKTHD9+T99JYiidPxkRH483KIqpvXyqWLaPzq6+w/sqrMFFRgdMneTw4k5PJuOsu8t94g8rFizGRkRinE+vzYSsrccTH44iOxpufHwjdwd/uyF69iDnkEArffbf60IYqba67lvxXXyO8YwecCYmUz5uHM3g8Z8eXXmLDtdfiy88ncu+9affgg0T164txOJg5dixdVq0mvFNH0q67Dl9+PmFt2lC5ajXrR43a0uPsdlM+bz7eTdmEd+hAeIcOFE6aRPyxxxK9//7Vp4ZyREdjrSXz+hso+frrQG1XX1Xdg9pc5Tz3HLEDBhB76KGhLqWawl8DUPhrvlpK+POXlZF5y62Ufv89ySNHknLB+c2uF68+Wsr221M2PfY4BW+9RdK/ziHhuONYd/ElmJgYOr/y8jYDR/zl5eQ89RSuX3+jwzPPENW719/m5dm0icKJE2lzzTU4oqLwV1ZiIiICvXXW4oiJ2Wk90996i31iY0k6MxCmrNdLwcSJxA8ZQkTXrmy8/Q5wOmj3wAP4S0txJiVRNmcOOWOeIePOOwlLT2fNv87BuzELHA4ie/Sg84Tx+EtKCO/cubrnyV9ZScmUKYS3b0/MIYfgr6yk7NdfKf7Pf9j8xZc4U1Lo9Nqr1YcZ+Csr8RUUENa2LZ4NGyj79Vey7r4ncFyeMZiIiOAxm5tIu3407tWryRw9msrlK0g652za3ncf6y64EF9RIR3+/TzO5CQqlyzBk5VN1p13Et6lM77CIlIvuZg2V15Z/XlYr5eVJw3Hs24dccccQ6eXXqT8998pfP8DHPHxJJ0+goiuXQPhrrCQ/NdeJ2nEP6hYvJiNt96GMzGRjuPGkv3ww3g35ZBx++1k3XUXiaedStFHHwOQePrpJJ5yMhWLFpNwwvGsOXck3k2bcMTHE73ffpTNmUPyyJEk/fNM1pzzL/zFxeB0kvZ/15D7wovg9xOx114kDB9O7rhxOCIjsWVlxA4aiOunn4kdPIjK5csD28TppP3jj1MwYQIVCxdu2fBOZ+APGCD64IOpXLIEf1kZsUceSXi7doHDOG65mbI5cyn/4w96TP0BT2YmYW3aULFoMf6SzcQfe+zfv5MbN+Jes4biyZOpXL6CqP32JePOO3FERGC9XkxYGN7cXLx5eUT26rXNru/KVavIeeJJ0m+9hcju3Xf63d2a9fnIeXoMtrKCtvfeu21NmZmsOOZYYg47jC5vTdil+VbxlZRsc4hCQ1D4awAKf81Xcw8PfrebTQ8/gmvWLDzr15Nx552knH9eqMvaY5r79tvT/JWVlM2eQ+yRAwAofOcdog86mOh9+u1kysbRENvP73bjLynBmZIC1G2QRfW05eXkjx9P4vDhO/xjyV9WxobrRhPevj3enBzihg4l+eyz/tamePJkEoYPx5mQEBjIERa2TT3W6w3sJh48KDBYqoZ1iTTXAAAgAElEQVR6iz79jKw776Tjiy/UGHBqYn0+1vzzLKL23Zd2D9xffQJ043RWDwAqmzcPR0xMIPRs1Yub++JL5L34Imk33ECbK0Zh/f7q98v//BPXL7OIGzyIqN698WRm4vptNoXvvEPFokV409Pp89FHrDn7bLzZ2UQffDCejRsJS0kh7cYbyHniSSqXLYOwMNo9+CDRBx5A+e8LKJ8/n+Rzzsb1yy8Uvv8Bkb17Edm9B4XvvIO/vJyUCy8k/bZbcc2YyfrLLiP95pvIfWks4e3a4cnKwno8pI2+jrI5c0gaMQJvTi4mMpJNDz+M9XgChyIcsD+umb8QO3gQicOHk3Xf/SSf9U8KJ72H9XiIGzyYjuPG4l65EhMeTt64lymePBlnmzZ0GjeWiC5dAr3jDkf1AB5bUUHFokVEH3RQ9XbzFhaSdedd1ccId5n07jbHaBZ+8CHZ990HxtB5wgTC2qTuNFzmPPsc7rVr6fjcsxRMmsSmhx6m3cMPkXTGGX/f9n4/vqIiwoLf/635Sl0YQ417NxT+GoDCX/PV3MPD5m++IfO60UQffDBtrhhV68HvLVVz336tnbbf31lrA4Oz9ttvl4Ks9XqrDwXYFb7NmymYOJHUiy/GER1d5xrLf/+dOevWMei003D98gsl335Lxu23b3MaHr/bTfEnnxDesRNxA4/a6Xw9mzbhKyqqPq7QWsuaM/8Z6DU0BpxOnLGxWAj0SG63+zqqb1/Sb7mZyD59CEtOpvDDD8m+736wFhMejvV4iOzZk7ihQ8l/9VWcqan48vMDPZEOB3FHHUXF0iV4s7LBWqL69SN2wBFs/t+UwNkRkpJwr11L4umnYyIjqFy+nIo//gRrSbt+NPlvjscRG0t4+/aBQw8OPJCKxYupWLgQf2kpAI7ERLp98QXhGYER2Z7MTDbefTepl11G3rhxRPXqTdGnn2IrKuj48jgyr72u+hCBuIEDSb/5purDM6y1ZN54I6VTpwVG1nfpgq/URdZddxF7xOEUTHiL8Pbt6PzmmwBULF0aCJKPPExk164Kf7tL4a/5au4/Ppk334Jr+nR6Tv+5zoMdWpLmvv1aO22/5m1PbL/SH39k/RVXEj9sGCkXnI8jPh7Pxo2U/vQTaaNHU7l4MeGdOlHx55/EHnVU9SCsKsWTJ1M46T3aPfYYpdOmkXDycMLS0si66268mzYRf8LxFH38MRUL/qDbl18QlpZG/vgJGKeDwg8+xFdcTMyBB2IiI6lctoyY/v3Z/N//4oiNJbJXL6L335+kM04nsmdPij75lPw33sCZlIRxOChfsCAwGOef/8STmYn1+ShfsAATFkZYRgbtH3+M7Pvup2LRom12hVcx0dE4IgOj+QvefofiL77ARETQefx4fEWFFLz1duDYSIeDuEGDSB01ivxXXqH0xx+3momhx7RphKUks+Ha6yidNo3YgQPp8vprCn+7S+Gv+WrOPz5+t5vlA44k/vjjaP/II6EuJySa8/YTbb/mbk9sP2stRe+/T9ygQYR36NAoy/C7XFSuWbPNqaUg2Jvq929zih8Ab3Y2YW3a7PTcjJUrVpD7/Au0ufIKIvfeG2MMxV99RcmUrymbPRtfUdGW4ylfGkvCccOoXL2G8IwMPJmZVC5fTvott5B66SUAVCxZwtpzR1Zf0tIRG0vy+efhiIoOnG4qKP2WW6hcuZKwlGTyX3+D8E6dAucmLS8nsmdPKpcvp+/SJXUKf62vS0GkCfJkZeHNyye8XVsyb74lcN6zE04MdVkiIo3CGEPyv/7VqMtwxMb+LfgBf9ubUrVLfevzpO5IZI8edHz+39u8ljh8OInDh1O+cCGFb79DysUXEdWnD4mnnkpYRkagkbUUvvc+hR9+ELjSTlBUnz50++o/bP76a5zxCSSceAKOmBistcT0Pxjf5hKi+vUlvGo+BK4EVLlkCbEDjsBfUUnHl14k//XX4dZb67QOCn8iTUD2w48ETvA6ZDDlc+eSce89xB6lS1WJiDQn0f36Ef3E49XPt+/VTLngfFIuOP9v04W3a0fqRRdt85oxptYr1rS9917ca9Zsc7nOjFtuUfgTaS6sx0PZrFnY8nJK/jeFxDPPIOXcc3c+oYiItEoxBx1IzEEH1nv62i/0KSKNzltYSNmcOfhdrupTWmz/15+IiEhDUs+fSIh4c3NZ9Y8RgYODjaHL22/h3rCByB49Ql2aiIi0YAp/IiFgfT423n4H/tJSHHFxRHbrRmSPHgp+IiLS6BT+REJg02OP45oxg7YPPED8ccOqr9MpIiLS2FrFMX/GmEeNMTZ4uznU9UjrVjZ3LoUTJ5Jy4QUkn30WYcnJNV7CR0REpDG0+PBnjDkEuBVQ14o0CXnjXsaZmkra9deHuhQREWmFWnT4M8ZEAhOATcDk0FYjAmWzZ+OaPp3Uiy+q8/U2RUREGlKLDn/Ag0Bf4EqgOMS1SCvnr6wk6557Ce/YkWSdx09EREKkxYY/Y8xhwE3AJGvtl6GuR6Rg/ATca9bQ9oH7ccTEhLocERFppVpk+DPGRAFvAQXA6BCXI4K3oID8114j7phjiDtSl20TEZHQaamnenkE6A2cY63NC3Ux0rp5CwvZcNXV+CsrSb/pxlCXIyIirVyL6/kzxgwArgc+t9Z+EOp6RPJeeIGKRYvo8OwzRHbrFupyRESklWtRPX/GmGhgPLAZuLqe8xgFjAJIS0tj2rRpDVaf7DmlpaVNZtulfvsdvr37MC88HJpITU1dU9p+suu0/Zo3bb+Wr0WFP+BRoBdwibU2qz4zsNa+CrwK0Lt3bztkyJCGq072mGnTphHqbWf9frzZ2azIzaXDZZdygL5LddYUtp/Un7Zf86bt1/K1tPA3AvADFxpjLtzuvT7B+6uMMScDK6y1l+3R6qTVKPr0M3KffRbr9wMQc9hhIa5IREQkoKWFPwgcxzh4B+93C96S9kw50tqUzZlD1p13Ern33lQuXYozKYnIXr1CXZaIiAjQwsKftbZrbe8ZYyYAFwK3WGuf3lM1SetiPZ7AiZw7dKDruxMpmzsX63ZjHC1ubJWIiDRTLSr8iYTa5ilf4169mo4vvoAjJoa4gQNDXZKIiMg21B0h0kCsteSPf5OIbt2IO/roUJcjIiJSI4U/kQZS8s23VC5aTMrFF2k3r4iINFmtZrevtfYi4KIQlyEtiN/lwl9eTvmff7LpkUfxl5UR2bs3SSNGhLo0ERGRWrWa8CfS0LIffZSS777HGReHb/NmrM9H2/vvw4Tpn5WIiDRd+pUSqafyefPxFxfjLy6m49ixxA0dgjEm1GWJiIjskMKfSD34Sl2416wh7thjiN5nXwU/ERFpNhT+ROqhcslisJakM88kXpdBEhGRZkRDEkXqoWLhQgCi+vYNcSUiIiK7RuFPpB7KFy4kLC2N8PT0UJciIiKyS7TbV2QXlC9ciDMhgdKp03T1DhERaZYU/kTqwL12LdbnZ80/z8KEhWHdblIvuzTUZYmIiOwyhT+RnXD9+hvrLrwQZ2oqJjwcExFB3OBBOt5PRESaJYU/kZ3YPOV/APjy80m+4HzSrrkGExUV4qpERETqR+FPZAes30/p9z8QP+xYkv75T2IOOQRHdHSoyxIREak3hT+RWniyssh59lm8OTnEH3sscYMGhbokERGR3abwJ1KLTU88SekPPxBzxOHEHXNMqMsRERFpEAp/Itsp+vhjKhYvoeTbb0m58EIybr0l1CWJiIg0GIU/ka24168n+4EHsR4PGEPyv84JdUkiIiINSuFPJMi9YQMb77gDwsJo/9hj4PMS0alTqMsSERFpUAp/0qp5CwrIGTMGZ1IShZPeA6DtPfeQePLwEFcmIiLSOBT+pNXyu1ysv3wUFYsXg99PzKGH0v7JJwhv2zbUpYmIiDQahT9pdazXi7+sjLyXXqJi0SI6vTyOqP32w5mYiHE4Ql2eiIhIo1L4k1Yn79VXyXvxJQCSzjmbuMGDQ1yRiIjInqPwJ61O6fc/4ExNIbJHD9Kvvz7U5YiIiOxR2sclrYq3sJCKRYtIPuccuowfjzMxMdQliYiI7FEKf9Ki+cvLyX7wIcpmzwag7NdfwVpiBwwIcWUiIiKhod2+0mL5SkvJvOFGXD//TMnUqXT/z5eU/vwzjrg4ovfdN9TliYiIhIR6/qTFca9bR8Ibb7DqxJNwzZhB8nnn4c3KIueZZyn5+hvijzkaE6a/e0REpHXSL6A0a56NG3GmpOCIisLvdlM+bx7Z9z9AZHY2UYcfTpsrryD6gAPwl5dR+O67ACSecUaIqxYREQkdhT9ptvzl5az6xwhijziCDs+MYf2oKyibNQsTHk7R6Ovod9ll1W3Tb76Z0u++x5GYSMwhh4SwahERkdBS+JNmw1qLv7QUZ3w8AKU//oR/82ZKvv6a9VeXUzZrFuk330TCKaeSvXjRNtOGJSfT6c03MGFhGGNCUb6IiEiToGP+pFnwFRWx4cqrWHbEAIo+/hhvYSGbv/oKZ5s2hHfqhGvmLyRfcD4pl15KeEZ6jfOI7tePqN6993DlIiIiTYt6/qRJ823ejCM2luyHH6F05kwie/Uk6+574O57AEgeOZK00deBMdU9giIiIlI7hT9pciqXLyeie3c2XPN/lE6dSkS3brjXriXlggtIv+F6Sn6YijcnB7+rlMTTT8eZkBDqkkVERJoNhT9pMqy15D73b/JfeYXUK66gdOpU4gYPxvXLL+BwkHLRhZiICBJOOD7UpYqIiDRbCn8SEv7ycjxZ2YR37IAjIgKAwncnkf/KKxAeTv4bbwCQduONpG4uxltQSHhGRihLFhERaREU/mSPK5s7lw2jr8eXl0dkr150eedtiid/Qc5TTxE3eDBR++xD3ksvEZaeTmSvnhqdKyIi0oA02lf2KF9REesvH4UzNpa060dTuWwZK44dxqZHHyVqn31o9/hj1bt1Y488UsFPRESkgannTxpcxbJlOCIiiOjalaLPPqfg7bdp99BDRHTtQuF77+EvK6PD888T1bsXlatWUfrjT3R69RXiBg0CwJmURPqttxI3aGCI10RERKTlUfiTBmGtxRiDNy+PtedfQETXLqTfcANZd98N1rLmzDMDDY0hdvAgonr3AqD9449jPR4ckZHV8zLGkHrJxaFYDRERkRZP4U92m2vmTDJvu432jz1O8aef4C8upuLPv8h99jnC0tPpMv5Niv/7X4wzDPeqlaRccmn1tMbhwGwV/ERERKRxKfzJLrPWUjDhLcpmzSLprH+SeeNN2MpKcp58ksply4gdcASumb9QvmABqZddSkTXrqRdfXWoyxYREREU/qQOrMfD+iuvIrxjR9KuH03uM89S9NFHAJT++CMRe+1FzGGHUvT+B5jwcNo99hirThqO3+Ui/nidk09ERKQpUfiTHXJvyKTst99wzZgBQPGnn2I9HlIvv5zoAw+k4M03affYo+DzUfT+ByScdBLhGRnEHnkkFUuWELXPPiFeAxEREdmawp/8jfX58BUW4tmwgTXn/AscDiL79KH9k09Q8MYbOJOSSLvxBowxxB89tHq6Tq+9RtQ+/QBo9/BD+CsqdKoWERGRJkbhT/6m8N1J5Dz9NDGHHoqJjCSiWzfSb7qJqF69aP/EE7VOFzfwqOrHzoQEXXNXRESkCVL4EwCKPvsc9+rVJJ5yMpv/9z+s241r+nQSTjqRDs88E+ryREREpIEo/LUSrlm/UrlyBSkjR+IrKsJfWcmGa6/DV1hIwgnHk//mePD5KJw0Cb/LhTM1FV9+PgnDh4e6dBEREWlACn+tRM4zz1Dx55+4V66k8L33iezRHfe69UT17Uv+a6/jTEqi47ixrLvwIrCWji+8gHv1auKGDAl16SIiItKAFP5aAU9WFhV//AFA4aT3MJGRVC5fQdoNN5B6ycXkvvgSMf0PJubAA8m48w5Kp/1I9IEHEHPQgSGuXERERBqawl8rUPLd9wDEDhiA67ff6PrB+3iysogbOBATFkb6DddXt00+5xySzzknVKWKiIhII1P4a+G8hYUUTHyHyJ496fjSi3iysojs1o2oPn1CXZqIiIiEgMJfC2H9fnzFxYGTLX/8CUlnn0XRhx9R9OGHeHNz6fzmGziio4ns1i3UpYqIiEgIKfy1EEUffED2Aw9iYmKwZWUUfvgB3o1ZxPTvT9sHHyCmf/9QlygiIiJNgMJfM2atBWsxDgclP0zFmZpK7GGHEt6xE/mvvkrc4MF0HDcW43CEulQRERFpIhT+mrH1l4/CmRBP+8cfp2zOHJJGjKDtvfdgrSX28MOI3n9/BT8RERHZhsJfM+UvL8c1axZ4vcQcehi2vJyYIw4HwBhD7IABIa5QREREmiJ1CzVT5X/8CV4vAJseewwcDmIPPTTEVYmIiEhTp56/ZsZfUYGJjKR83lwwhtQrr6Dst9nEH3sszsTEUJcnIiIiTZzCXzPiXr+eVScNx0REYCIjiezZk/TRo0NdloiIiDQj2u3bjGyeMgXr8RA3dCi+zZuJPeqoUJckIiIizYx6/pqwkqlTcf3yCykXXEhExw6UfPcdUf360eHpp2h7z904oqNDXaKIiIg0M+r5a6KsteQ8/gSFb7/D6hEjKP/jDyoW/EH8sGEAOBMTMRERIa5SREREmhuFvyaqfP7vuNeuJfXyy7EVFaw973xMRAQJJ50Y6tJERESkGdNu3yaq+PPPMdHRpF5xBTgd5L/8Cu3HPE1E586hLk1ERESaMYW/Jqp0+s/EDRyIMy6WtOuuI+nMM4no2DHUZYmIiEgzp92+TZBn40a8G7OI6d8fAONwKPiJiIhIg1D4a4LK5s0HIPrgg0JciYiIiLQ0Cn9NhLWW4i++wFtQQPm8uThiYojq3TvUZYmIiEgLo2P+mojKpUvZeOttRPbpgy8/n+gD9seEafOIiIhIw1LPXxNR9ttvAFQuWwYOB22uvTbEFYmIiEhLpK6lJsL122+Ed+pEp1deISw9DWdcXKhLEhERkRZIPX9NgPX7KZs9h5hDDyGy214KfiIiItJo1PMXYtbjIe/lV/AXFxNzyCGhLkdERERaOIW/EHJvyGTDNddQuXQp8SecQMKJunSbiIiINC6FvxAqePNN3GvW0PGlF4k/5phQlyMiIiKtgI75CxFrLaU//kjsgAEKfiIiIrLHqOcvBPLfHE/5/Pl4MjNJvfyyUJcjIiIirYjC3x7mzc0l97nnsG43AHEDB4a4IhEREWlNFP72sIK338Z6vbS55hr8LhfhHTqEuiQRERFpRRT+9qDyvxZSMOEtEoYPJ+3a/wt1OSIiItIKacDHHmKtZePtt+FMTSXjzjtCXY6IiIi0Ugp/e4h7xQrcK1bS5uqrCEtODnU5IiIi0kop/O0hpT/9BEDcoEEhrkRERERaM4W/PaT0x5+I7NWL8LZtQ12KiIiItGIKf3tAxdKllM2bR9xg9fqJiIhIaCn8NTJfqYsNV19DWEoKyeefH+pyREREpJXTqV4a2eb/foUnM5POb71FeHp6qMsRERGRVk49f42s+PPJRPToTsyhh4S6FBERERGFv8bk+uUXyufNI2nECIwxoS5HREREROGvsbhmzWLdJZcS3qUziSNGhLocEREREUDH/DUa16xZ4HCw1yef4oyLDXU5IiIiIoB6/hqNe+1awjt2UPATERGRJkXhr5G4164lonOXUJchIiIisg2Fv0ZgrcWzZi0RXRT+REREpGlR+GsEvrw8/GVlCn8iIiLS5LSo8GeMCTfGHGOMGWOMmWWMyTLGuI0xmcaYj40xQ/ZEHe61awGI6KrwJyIiIk1LSxvtOxj4Nvg4G5gLuIC+wBnAGcaYh6y19zZmEdXhTz1/IiIi0sS0qJ4/wA98Agyy1raz1p5srT3bWrsvcA7gA+4xxgxtzCJcv/6KiYwkvH37xlyMiIiIyC5rUeHPWvuDtfZMa+3PNbz3ATAh+PS8xqqhYvFiNn/5H5JHjsSEtbSOVREREWnuWlT4q4P5wfuOjbWA/PHjcSQk0ObKKxprESIiIiL11trCX8/gfVZjLaB8/u/EHn44zoSExlqEiIiISL21mvBnjGkLXBR8+kljLMNbUIBn/Xqi99u3MWYvIiIisttaRfgzxoQBE4FE4Htr7ZeNsZzyP/4AIHq//Rpj9iIiIiK7rbWMSHgZOAZYz04GexhjRgGjANLS0pg2bVqdFxL75ZfEGsPs/HzsLkwnDa+0tHSXtp00Ldp+zZu2X/Om7dfyGWttqGtoVMaYfwPXETjv3yBr7fK6Ttu7d2+7dOnSOi9r3eWj8G7aRLcvJu96odKgpk2bxpAhQ0JdhtSTtl/zpu3XvGn7NV/GmLnW2v47a9eid/saY8YQCH65wDG7Evx2lbWWikWLiOrXr7EWISIiIrLbWmz4M8Y8CdwI5APDrLWLGnN53txcfPn5RO29d2MuRkRERGS3tMjwZ4x5HLgFKCQQ/BY09jIrlywBIGrvPo29KBEREZF6a3HhzxjzEHAbUEQg+M3fySQNomJxIPxF9lH4ExERkaarRY32NcacCtwdfLoCuNYYU1PTJdbaxxty2RWLFxPesSPO+PiGnK2IiIhIg2pR4Q9I2epx/+CtJj8CDRz+FmmXr4iIiDR5LWq3r7V2grXW1OE2pCGX6y0sxLN2HVH76uTOIiIi0rS1qPAXKuW//w5A9AH7h7gSERERkR1T+GsA5b8vAKeT6H32CXUpIiIiIjuk8NcAyn//nag+fXDExIS6FBEREZEdUvjbTdbjofzPP4k+4IBQlyIiIiKyUwp/u6l8wQJsWRkxhx8W6lJEREREdkrhbzeV/jwdnE5iDz881KWIiIhIK+PyuBj/13gqfZV1nqalnedvj3P9/DPRBx6gkzuLiIhIo1m/eT3psencNO0mUqJSePDIBwH4dPmnPDP3GcId4XWel3r+doO3sJCKRYuIO+qoUJciIiIie9DERRNZlL+ozu1zy3JZXbwagL/y/uLC/13IquJVNbZdX7KeD5d+iLUWgKzSLE6bfBojJo/gxw0/8s3ab/D6vQB8u/ZbAMYvHF/nWhT+doNn/XoAInv1DnElIiIisqcUVxbzxOwneO2P1+o8zd0z7uaKb6/A7XNz1/S7mJczj5um3cRnyz+j1F1a3c5ay13T7+KhWQ+xIHcBABMXT8RnfawvWU+YIwyXx8UXK7/ghfkvMD9nPoe2PZScspw616LdvrvBszELgPD27UJciYiIiOwpC/MXAjAraxZ55XkAtIluU/2+2+dm3IJxnN37bL5d+y1p0Wn8mvUrPuvjydlPsqp4FRfvczHvLnqXe2fey9drv2bsMWMxGCYtmcT8nPkYDBMWTuAM9xl8svwTju96PCd2PZG4iDgu+foS7pt5X/Xy7jr8LpYVLuNETqxT/Qp/u8GTFQx/7RT+REREWhJrLWPmjKHUU8r9A+7f5r2FeYHwV+op5eTPTiYxIpEvRnxBpDMSgI+WfcTrf77OkoIlzMicgcVWT/vh0g/pm9qXGw++kcv3vZzPV3zOk7Of5J4Z95Dtyua37N84pO0h9Evtx4SFE/h+3fd0iu/ENQdcQ5eELgD0TO7J8sLlPDDgAXok9aBbYje6JXar87op/O0GT9ZGHDExOBISQl2KiIiINBBrLc/Oe5a3Fr0FwMi9R9IzuWf1+3/m/UlGTAZ55Xm4PC5cHhePzHqEPil9OLX7qdW7g6dnTsdhHDiNk7ToNACyXFmc0u0UAOIj4jlv7/PIKcth4qKJxITHcM/h93BGzzMo85aRHpNOWnQaQzsPrQ6WAOftfR5LCpYwoscIjDG7vH4Kf7vBm5VFWPt29frgRUREpOnx+r08NOshPl3+Kad2P5Wv13zN8/Ofp010G6aum0p8RDy55bkM7TSUxMjE6l26n634DIBX/niFosoibj3kVp6c/SRDOg7hxL1OJCY8hu/WfscXK7/ghL1OqF6eMYab+t/ExftcTKQzktjwWCAQDM/ve36NNZ7e8/TdWkeFv93g2ZhFeLv2oS5DREREarGxdCPt42r/rf7f6v/xwvwXuOaAa1hZtJLZ2bP5Pfd3Ru03iv874P8Ic4Tx6fJPiXBEcEznYyisLGTN5jUc2vZQRvQcAcCZvc5kQ+kGvlv7HW8tfIsnBz3JcV2Ow2A4ssOR7JW4FwB9UvpwUreTtjk+sEpKVErjfAA1UPjbDZ6sLKL69Qt1GSIiIlKDr9d8zc0/3szF/S7m+oOvx2d9hJkwjDH8sO4HftrwE1+t+gqP38PtP99OmAmjXVw77jviPs7sdSYAtx1yG2f3PpuuCV2JCY8BIK88b5uwlhiZSGJkIv1S+3Hl/ldW76I9r+9529STHpNOekz6Hlr72in81ZO/ogJfQYFG+oqIiITYquJV/HfVfxnQfgAHZRyE2+em3FvOlNVTcBon4xeO59fsX1m7eS37ttmXDnEd+GT5J8SFx9EloQtjhozh16xfGdxxMBmxGdvMOyY8hr6pfbd5raaeuypbH5vXVCn81ZNG+oqIiOwZ1lpe//N1vl37Ld2TuvPgkQ9SXFnMywteZkD7Adz84814/B4+Xf4p1x54LWMXjMXlduG1Xs7sdSZ9U/syZs4Y9k/bn/k585m3aR7n9jmXm/vfTLgzcGWMqpG0rYHCXz15g+EvTOFPRESkTmZmzuT1v17nkSMfod3/s3efgVGUaQDH/7MlvfeekIQUAoReQu+gFLEAFhRFlCagIGc5UVHgzoKCDaSDSheQEkrovSUESEII6b0nm7KbbHbnPkRWIgiEAxJ0fl+S3ZmdebY/+5bntfjj+7NYU0yVrgoXc5ebb5N1gk1XN7EvdR8h9iHsSNqBrYktldpKNidsZn38ehxNHfmg0wdMPTiVWSdm0cy+GRXaCtRaNb29ehPmFmaYGVtWXQbUTqj4p5KSv3tkaPlzkyZ8SCQSiURyJ2eyzzDpwCRq9DX8FPcTb7d/m/SydAfolwoAACAASURBVOxN7Hnz0Jukl6WzpP8SzmSfYYDPAMKTwzGSG/HxyY8xU5gxrsU43mj9BvPOzGNN7BoAunt0J78ynzfbvklnt87M6jyLKl0VowJHcSr7FBuvbqS9S3sAQ2WOf3LSd52U/N0jbVY2CAJKp4YfuCmRSCQSSWOm1Wn55NQnuJm70cS6CVsStvBay9cYtWMUzubOJBQnADBi+wiqdFV8dvYztHotAMF2wawetBoThQkA73R4B3sTe3an7Oajzh/haOZoOM/1SRoAXdy70MW9y0O8l48OKfm7R9rsbBSOjghGRg0dikQikUgkDS6nIocfon+gg0sH+vv053T2aY5kHCHQNpCcyhxSVCl83+f72vp1GaP58MSHqKpVqKpVGMuNaeHQggv5F5gYOpEzOWcY3Ww0SaVJDPYdbEj8AGSCjNdDX+f10Ncb8N4+2qTk7x5ps7OkyR4SiUQi+cfQ1Gj4/OznDPEbQiunVkSkRrD00lJyKnJwNnemtKqUzPJMfk34lc/Pfk6hphClTGlowRvqN5RuHt0QRZFgu2D2p+3HVGFKV/eueFt5M67FOPLV+XhbeTOBCQD0pndD3uW/LVlDB/CoqsmqXd1DIpFIJJJHgSiKdS6nl6Uz59QcwwSI63SijpNZJ7mQd4Gy6jJ2p+xGq9OyIHIBG65uYNrBaVwtvsq/j/+bCm0FPT17YqYwQylTsnrQahb2Woi7hTvjWozj1HOnGBMyhn7e/fiw84dA7di754OfByDMLYz5Pecztc1UzJRm/6gZtw1Javm7B6Ioos3OxqJPn4YORSKRSCSSOxJFkfER4zFVmPJ5989RypV8d+E7Q4Hjj8I+Muz3Q94PxKfFY6owpaNrRw6lH8LG2IaSqhJ6e/bmeNZxRmwfAcCC3gvwtfa96Xy9vHoZ/p/ebvpN2wc2GUh4SjgjA0c+mDssuS0p+bsHuqIixOpqqdtXIpFIJI1CWXUZckGOmdIMTY2G7Ipsmlg3QV2jxkRuQmReJCeyTgAw88hMprWdxp7kPdib2LM5YTOqahXOZs4oZUriNfGMbjaatXFrOZR+iG7u3VDKlLRzacfIwJEklCSwMHIhLR1b3jLxuxvGcmMW9V10Px8CST1Iyd890GZdL/MiJX8SiUQiebDmnZ5HkaaIz3t8TqoqlaWXljKj3Qy2XtvK476PY2tsy4vhL6Kp0TCt7TS+Pv81WRVZfNXzK6Yfmo6FkQXmSnOsjKx4ufnLLIhcQERaBApBwfKBy9masJVtiduo1Fai0WlwV7ozve105IKc3xJ/Y07XOdia2BriCbEPYXG/xQ34iEj+X1Lydw+06WkAKFxuLkYpkUgkEkl9aXVarpZcJdguGJnwx3B8URQJTw6nuKqYCaETWHxxMbuSd3Eh7wIpqhQSSxLp6NqRayXXEBCYcXgGXpZeiKLI+8feRxAEurp35WD6QcaEjOHVFq/S1KYp53PPM8BnAL7WvrzV7i3eavcWOr2OU9mnyI3LRS6T81bbt5jYaiKmCtMGfGQkD4KU/N0D1Z69yG1tMWnatKFDkUgkEskjJqU0BXcLd8OyYgBzTs9hc8JmPC09mdt1LitjViKKIgN8BlBcVQzAV5FfcSzjGKYKU1JUKRjLjdmetJ3jmcfxt/HnzbZvklyazLNBzzJp/yROZZ9igM8A5nWbV+f8PTx70MOzx01xyWVyurh34VDCIaB2YoaU+P09SbN966mmuJjyAwewHjpEqvEnkUgkEgrUBXUuxxTE8OqeV5l5eCZ6UW+4vkpXxcSIiQzZOoS3j7yNKIqUVZex/PJyNidspr93f8qry3kx/EWOZhzlXO453jv2HgAdXWonXgD82O9HhvkN48d+PwKglCv5tOundPfozkshL2EkN2Ko31AAnmr61EN4BCSPGqnlr55U4eGIWi3WTz7Z0KFIJBKJ5CFKU6Vhb2qPudLccN2WhC18eOJDNg7ZSKBdIFqdlon7J1Ktq6ZcW45SriTILoh2zu3IqsjiaOZRurh3YX/afqYdnMblwsvkVebR3qU987rNIzo/mhmHZzCz/UyqddXMOjELOxM7FvdbTExhDCYKEwJsA2jl1AqArcO24mjqiJnSrE6sg30H42fjRzP7Zg/1MZI8GqTkr57KDx/GyMcHk8DAhg5FIpFIJA/JnpQ9vHPkHfp69+XzHp+TrkrnXO45von6BhGRXcm7cLVw5Wz2WYo0RXzX5zv2pOzht8Tf+C3xNwQEguyCsDSy5Jve3/DDhR9Ye2UtjmaOrBm0xpDMtXdpz6ERhxAEAa1Oy48XfyTUKRS5TE5Lx5Y3xfVXdfEEQZASP8lfkpK/etBXVVF5+gw2zzzT0KH8Y+n0OuQyueFyoboQSyNLjORSF7xE8k+l0+vQ6rV1lgC7Ha1ei1yQczzzOJ3dOqOQ1X4VFqgLEEURvajnbO5Z+nv3x0huRG5FLu8cfQeFTEFEWgQX8y8y7eA08tX5AHhYePBrwq+sjl2NQlDgYOpAmFsY3T26837H9ymrLmPEjhHEFcUx2HcwSpmSKW2mMLHVROSCHEEQ6sR3/bJSrmTd4HUoZUokkvtJGvNXD5XnziFqNFh069rQodRbqiqVM9ln7um2NfoaZh6ZyU+xPxkqxFfpqsirzANqZ6NdKbpiGNuy/sp69qTsMWwrry6vc7wCdQHfRH3DgsgFpKpS62yLzo/m/WPvk65KZ0/KHr678B0xBTEcyzzG4C2D6bquK5cLLgNQXl3OsG3DmHt67j3dL4lE8vcw9/Rchm0dRomm5KZtNfoaFkYuZPy+8ayKWcWPF3+kx/oezD45m4n7J7Lt2jbDvpP3T2Z0+GjeOfoO7x59lyFbhnA25yxbrm2hRl/DZ90/o0Zfw+jw0VTrq/muz3cs67+M11q+RklVCc5mzgiCwIiAEYaE0kxphrO5M+NajAOgt9cfy5UpZIqbEr8/sza2vqlLVyL5f0ktf/VQceIEglKJWfv2DR1KvX1y8hMu5F9gx/AdhtIA2xO342npSRvnNpRUlSAgYGtiS2xhLOuurGNsi7G8ffhtvK282Z2ym/DkcNLL0gmwDeCbqG8oqy7ju77fsSF+A/tS9/F+x/cxU5rx6elP8bHyoZt7N9479h5HMo7wbZ9vCXMLQ1Wt4unfnqa4qhgZMrZd28aO4TswU5qx9spaQyKnkCnYnrgdrV7LT7E/YSQ3wsrICmtjayZGTGRmh5kUa4oprSpl27VtjGs5jvzKfBJKEvCx8iGiNILgimCczJzIrczFwdTB8GEskUgaD1EUqdJV3XWrHdQWNLZQWiAIAjX6Gvam7qWkqoQPTnzAwl4LDQmVXtTzztF32JOyBx8rH74494XhGJsTNgOwLXEbTwU8xdXiq8QUxgCQWZ7JiIARnMk5w9g9YzFRmNDJtRO9vHoR5hZGkaaIz7p/RhPrJgCoa9RklGfwdNOnsTe1v+VnzaigUbhbuN9ylq1E8rAJf17rT/KHwMBAMT4+3nA5fdJktOnp+P627Ta3anzyKvPou7EvIiJ2JnYUaYpobt+cy4W1LWgDfQZyPvc8ZdVlTG49mZiCGMJTwvGx8iFFlQLUjkNpZteMVbGrAGjr3Jb0snTyKvNQyBRYGVlhZ2JHZnkmUPth2NerLwfSD+Bs5kyhupDmDs2xMrbicPph1jy2BlEUGR0+miC7ILIrsimtKqWXZy8qayo5k30GEZH/dPsPn576lMqaStY+vhZzpTnTD00nvrj2efG38SdFlYKzmTPZFdl1ZtYpBAUWRhaUVJUwtvlYprWdBtR+IZRVl2FtbP2wngJJPR06dIiePXs2dBiSe1Sf5y88OZyPTnzEjuE7cDRzvOP+18feNbNvxsdhH1NaXcqY3WPo4NKBMzlnWNBrAe4W7gTYBvBz3M/89+x/mdZmGi83f5nZJ2dzIe8C73Z8lw3xG3A2d2ZN7BraOrdFVa0iuTSZIb5DSCpNYsXAFWh1Wn6I/oH18ev5sseXdPPohl7U16nD93ckvf8eXYIgnBdFsd2d9pOaQupBm5mJ0t29ocO4JZ1eR3ZFNh6WHjdt2528GxERbytvUlWpuJq7crnwMkP9hmJvYs+KmBWYKkwJdQxl/vn5hvElKaoUenr2JNgumCF+Q/C09MTPxo/KmkqeDXqWi/kX+fHij0xqPYnT2af56vxXyAQZ87rO419H/0VEWgSP+z7OjHYzWBy9mFPZp4jMi2So31BCHUMBGOI7hL2pexngM4AA2wCeC3qObYnbOJ19GidTJwY1GYSruSt5lXmGwcsbhmxgb+pe1satZWKriRSqC/kt6Te6uXfjMd/HSC9LpzyxnAKHAoo0RSSUJLA+fj3jWo7DXGnO/HPz2XB1A+sHrzf8cpdIJA9HUkkS1sbWROZFklyaTGxhLJU1lUSkRTAycCSLohfR3aM7zR2aG26TUppCeHI4jmaOfHrqUwJsA8goz2DS/kmEOoWilCmZ33M+L+x6gTcPvYle1DPIZxARaRH09OjJK81fQRAEPgr7CFEUEQSBjq4dya/M59eEXylQF5BRlkEfrz7M7jLbsI9SpmR6u+m81fYtQ2vi3z3xk/wzSC1/t3Fjy58oilxt3wHrJ57A5d/vN3BkN1sVs4ovzn1BD48eJJYk8kmXT0grSyOnIoef4n7C29KbDzp/wL7Ufbza4lUOpB2gv09/jGRGLL20lBD7EALtAhn06yDUNWqG+w9ny7UtrB60mtZOre94/uzybAZsHsBjvo8xp8scuq3vRll1GUv6L6GTayegdpD1kfQjdHDtgKWRJVA7HqdaV11nTEuBuoA+G/swKnAU73Z8954ejxt/uUbnR/PCrhd4p8M7DPEbQt+NfVHXqHEydcJMaUaYWxiTW082xCRpeFLLw6PtxudPU6NhX+o+BvgMoEJbwaBfB9HBpQMZ5RkkFCdgIjdBo9PQ3qU9LzV7ickHJmOptGTFwBUE2gWi0+t4ftfzhi7ZNk5t+L7v9ySXJvNi+Ito9VoG+w5mXrd5nMo+xfxz87E3tedY5jGC7YJZ0n/JbVv5tTotCpmCQk0hZgozaXwd0vvvUSa1/N1nepUKfXl5o2r5W3F5BRZGFjwT8AyHMw5jqjDldPZpjORGTIiYgEanASDQNpDPe3yOh6WHofVsiN8Qw3HGtRxn+H9i6ET2pu7lo7CPGNdyHJ6WnncVi6uFK8sHLCfALqC2SrxbF2ILY+ng0sGwj1KmpI93nzq3U8gUN42PcTB1YPWg1fe8YPifhTqG0tKxJT/H/Yy6Ro26Rs3kVpPZnbIbZzNn1sevp7iqmM+6f3ZfzieRSP7w2dnP2Hh1I8WaYvLV+VRoKziacZQasQYAjU5DkF0Q53PPU15dbhif+9q+1xgVNIrI3EhiCmOY3GoygiDwQvALmCnNaO7QnNWDVlOjrzGUQOnk2okNQzag1WvZnbyb7h7d7zi84/oqGw6mDg/2gZBIGhGp5e82bmz508TGkvzkU7gvXIBV//4NHFltN2/XdbWzjrcP306/Tf0Y3Ww0b7Z5k+j8aF7e/TJD/IYwvd10LI0sH3pXRYW2gmpddZ3FwB+mP/9y3ZOyhxmHZyATZHR27cyifosM2xZHL+bbC98yo90MXmz24h1n30kePKnloXFKV6VTXFV8U725vMo83jjwBt5W3gTaBlKSVkJAUABzT8+tLXQsU2JjbENJVQn+Nv7EFcUB0NqpNZcLLrNu8DomREwgrzKPSa0mMcBnAGN2j6FIU4SPlQ89PHowvd106b35kEjvv0eX1PJ3n1Vn1k5kaCwtf/HF8ZRra0uozDo+ixp9DWFuYQiCQCunVhwYcQAbY5sG+7A0V5rXqYLf0Pp49cHN3A11jZrZXWbX2fZKi1e4XHiZL859wdXiq8wOm12nlqBEIqk168QsYgpj2Dl8p2FyRoG6gLF7xpJbmUtCcQLhyeHIkWN73hYnMyde838NWxNbPjj+Ae4W7izqt4hndzyLkdyIb/t8S0ZZBgG2AWx/Yjv70/bTz7sfJgoTtgzbgl7USy1yEskDICV/d0n7e/Jn9BCTv0ptJZU1lYYPvyJNEW8ceIPu7t0NyYm3lTdHM49iqjCtMzavoVrcGiuFTMHSAUsREHAyc6qzTSlTsrDXQr6P/p5F0YuIL4rnhWYv8IT/Ew0UrUTy4EXmRhJsH4ypwpQCdQFpqjRU1SoqtBU87vs4gGHiA0B+ZT7nc88jIjL39Fx6e/UmuTSZval7yavMY1HfRXhaepKvzuelnS9RoC7g0y6f0sW9C1qdlqzyLAY2GYidiR1f9PgCmSDDysjKMBTFTGlWZziKnYndw39QJJJ/CCn5u0vazCxk5ubIrB9eeZD3jr3HiawT/ND3B9o6tyU8OZyL+Re5mH8RmSDD09KTJf2WEJUXhbeVN8Zy44cW26PoduMXBUFgUqtJOJg4sPbKWmafnE1X965Sq4Pkb2NPyh6+jfqWdYPXUVpVWx5lROAIHmvyGFMOTqG0qtSwb7BdMPtS97EqdhXT207nVPYpMsszERHp49WHiLQIItIikAtymlg34bs+39HGuQ0AjmaOPGv/LFUOVYS5hQG14+omtppoOH4LxxYP985LJJI6pOTvLlXFxaH08Hho3ajpZekcSDuAXCbnjf1vsOfpPexK3kWAbQAvN3+ZD459QGfXzrhauOJq4fpQYvonGBk0kk5unRiyZQiLohfxfPDzUjkYySOvWlfNl+e+JLsim+OZx1HXqBER2ZywmW3XtuFi7sLHnT9GK2p5+/DbTD88nWsl17AzseOjkx8BICDgb+PPVz2/IqM8A61ei4eFxy2XVmxj3oaeHXs+3DspkUjumpT83QX1xYtUnjuH04zpD+2c66+sRy7Imd9jPlMOTmFB5ILa9STbTGOw72BaObaSukUeEG8rb3p59mJ9/Ho2Xd3E+sHr8bX2NcwKlEgeFTq9jsUXF7M7ZTfZFdkoZAoOpR9CJsiwUFpQravG3cKdZQOWYW9qD8Avcb8QlRdFS8eWfNnjS14Mf5EhfkPo49UHM4UZgiDcdRUAiUTSOEnJ3x2I1dXkffElcmtrbEY9+3DOKYrsS91HV4+u9PLqRUvHlqyPX4+1sTWDfQcD3LKYs+T++TjsY4blDePDEx8yPmI8xZpilg1YRlvntg0dmkRyW7kVuTiZOSEiMuPwDCLSImjn3M6wcsX1McKdXDsxpc0UHEwd6tS4HOgzkKi8KCa1moSLuQu7n9otFTaWSP5mpHf0HWS98y6VZ87g9PYM5BYPdvbq8czjVGorSVWlklWRRTf3bgBMCJ2Al6UXi/suxtnc+YHGIKllY2JDb6/evN3+bYo1xcgFOZuubmrosCQS9KKen+N+5puob0gsSUSr11KkKQLgaMZR+m7qy7r4dSy9tJSItAimt53OioErGNdyHAN8BlBSVUJ2RTbtXNrRxLrJTcXNRwSO4OfHfjaM15MSP4nk70dq+bsNoaoK1a5dOEyahM3TTz/Qc8UXxTM+YjxPNn2SILsgADq7dgagq3tXdj6584GeX3JrQ/2G0t+7P5+d/YwdSTuo0FY0qhI2kr+fhZELAXij9RuGMcapqlSmHZxGS8eW5FXmcSzzGAICyy8vx9nMmSJNEWsGreHjkx8DtbUrS6pKGNRkEC+FvGQ4dk/Pnizqu4iTWSd5vMnjtzy/Qqa4qY6fRCL5e5F+0t2GTKVCZm2N/SsvP/BzHUo/BMCWhC38EvcLHhYeeFpJ42oaAxOFCUP9hqKuUfPWobfIrcht6JAkf1OZ5Zksu7yMJZeW8H3094iiiCiKzDk1h8zyTHYl7SKmIIapbaZyaOQh+nn1w1xpjl7U88KuFyhUF/JK81co1BRia2LL+x3fv2mSWhf3LsxoPwMbE5sGupcSiaShSS1/tyGrVGM7ahQy8wfT0iOKIhqdBlOFKUcyjuBv448gCFwrvsbroa8/kHNK7k2oYygz289kYeRCvo78mnnd5jV0SJJHzI018647knGEFZdXMLn1ZL6N+pay6jIEBPp49WFR9CIiUiPIV+dTWlXKex3fY2TgyDrdsJ/1qF2ScEHkApZeWsq/O/6bpwOepry6nP4+/e+4tJlEIvlnkpK/O7Do2uW+H7O8upxqfTX7Uvbx6elPcTZzJq8yj4mtJjI+dPx9P5/k/ycIAqObjSapNImdSTup1FairlGjqlZJpWAkd6QX9YzeNRqtXst7Hd+jlVMr1l1Zx5zTcwB4effLyAQZOlFHf+/+fNHjC1bFrOJQxiFaObWipUNLhvoN/cvxd5NbTaafdz+C7YIRBIEPOn/wMO+eRCJ5xEjJ3+0IYBIScl8PWVpVyrM7n0Uv6jFXmuNl6UULxxZkl2fXqW4vaZyG+A5h09VNbLm2hY3xGymuKmb/M/tRyKS3kuSvHcs8xsWCi5grzRmzewyd3TpzLPMYPT16MjJoJG8deotpbabR1b0rdiZ2CILAmOZjGNN8zF0dXy6TG1bKkEgkkjuRvrFuQ1QqkZmZ3bfjxRbGMvvkbDLKMhARAXinwzs8H/z8fTuH5MFq7dQafxt//nPmP4brzuacpbNb5waMStIQijXFf7mMYnZ5NssuL2Niq4lYG1mz7NIyXMxd2Dh4I/89+1+i8qIYGTiSme1nYiQ34vio41IdSYlE8tBIyd9tiMb3b7m0suoyxu4Zi7HcmPk957P00lKuFF1hgM+A+3YOyYMnCAIrB65kdexqrI2s+fbCt+xN3Sslf/8wSaVJPLntSWZ3mc1Qv6EAZJVnUamtxN/Wn++jv2frta0kFCdgZ2JHZF4kH3b+EBsTm1uOF5USP4lE8jBJyd9tiEY3L1t0r35L/I1ybTlL+y8lxCGEJtZNSCxJlNaOfQRZG1vzRus3ALhUcIk9KXt4IfgF/Gz8GjgyyYOWXJrMxqsbUcqU6EQdSy4u4bEmj3Gl6AoTIiZQpatiXrd57EjaQYBtAJF5kcgEGVPbTOXpgAdbLkoikUjulpT83YZoYvJ/H0Or17LuyjpWxayipWNLQhxqxxD62fhJycLfwPjQ8ZzNOctLu19i+xPb/7IbUPJoy6vMo0hTxH/P/JdzuecQELBQWpCiSiFsbRjqGjUOpg4YyY2YdnAaSpmSr3t+janSFDOFGWbK+zd8RCKRSP5fUvJ3G6Li3h+exJJEvr/wPaYKU7Yl1i6cPrX11PsYnaQx8LPxY1G/RTyz/Rm2XNvCK81faeiQJPcgqzyLiwUXGeA9AEEQ0It6ll9eTjvndqiqVbx79F1U1SoAHE0dyVfnM7HVRFJKUxAEgQDbAHp49KBCW8Gp7FN0cusk1emUSCSNlpT8PSA7knawN3UvAM8EPMOszrMaOCLJgxJkF0Q753ZsiN/AS81eQi6TN3RIknpILk1m7J6x5KvzcRjgwMWCixSqC1kduxoTuQnV+moCbAMY4T6CzLJMprSZwncXvmOI75BbFkr2tfFtgHshkUgkd09K/h6Q+KJ47EzsmBA6gSf8n2jocCQP2KigUcw4PIMVMSt4tcWrDR2OpB7mnJ6DVq/FVGHKlINTKKsuA2qXVcyvzMfdwp153ebV6bqVinxLJJJHmZT83YZWD3llGpws6z/2L74oni5uXRgVNOoBRCZpbPp792eQzyAWRC5AL+oZ23ys1ALYCF3Kv0Qz+2aG5yamMIbT2ad5q+1bJJcms+XaFh73fZy+Xn3p7NYZM4XZTatySCQSyaNOSv5uI7NcT4c5+5k9LIQXO/vc9e0K1YXkqfMItAt8cMFJGhVBEPik6yeIiHwT9Q2Z5Zl81PkjKXFoRC7kXWB0+GjebPsmY0LGkFGWwacnP8VCacHTAU+Tr86nuKqYme1nYmdi19DhSiSSRk6j1aGUy5DLHr3PeSn5uwN7cyPWnEytV/IXXxQPQLBd8AOKStIYGcuN+az7Z3haerLk0hKa2TVjZNDIhg7rH+9S/iV+vPijoZbe8svL2RC/gczyTEwVpszrOg9LI0ssjSz5pvc3DRytRCJ5FIiiSJ8vD/NcRy8m9fJv6HDq7dYLRf4FQRCMBEFwEgTB5E/XWwiC8KkgCNsFQfhGEIS/xTQ3AXi9hy8JeeUk5Zff1W1+iP6BaYemAUgtf/9AgiAwufVkOrp2ZGHUQsMMUcmDp6pW8f6x9zmbc7bO9d9d+I5DGYfYl7qPYLtgSqtK0Yt63u3wLpuHbKaPd58GilgikTyqsks1ZJaoOZFYcNe3ickq5WhCPlDbarj5fAY1On29z51cUEFaYeUNsaiZ9EskxRXVd32MeiV/wAdANtD6+hWCIMiAI8C7wOPAJOCkIAj29Tx2o2Msh8dbugGwNzaXC+klrD2T9pf7V+mqWBO7Bk9LT6a2mYq1sfXDClXSiMgEGTPazaCsuowVl1c0dDh/a1W6KiJSI4jOj+bVPa/yW+JvfH3+awAK1AVsT9zO8azj+Fj5ADCtzTTWDFrDxiEbeS74Oakci0QiuSO9Xrzpumt5tQ1CFzNKEcWbt9/KpzvieGtDNACLDicyfWM0v0Zm3nLf86lFvL/lkuHcNTo9o5edZmtUJi8sPc2MjdGGfbdHZ7HzYjabIzPu+j7Vt9u3D5ApiuLJG64bDrQCLgELqE0AhwPjgTn1PH6jYiwXcLcxpYW7NXtjcjiWUMDJpEKGhLphYXzzQ3cg7QBl1WXM7zmfTq6dGiBiSWMRZBdED88e/Jb4G2+0fgOZUN/fWZK7sSByAWti1wBgqbSkv3d/9qbuNSSB+ep8lDIlywcsJ0+dR4h9SANHLJH8s2m0Og7F59G/mQuyRj5WrkanZ/xPkai1Nfz8at3v9OvJX5mmhq/2XcXNxpRRHbzq7FOq1mJlokAQBGp0ei6kl6DW6kgtrGD5sWQAfjiciEIu0CfIGWuzP5Z5nLvrCudTi3mqrQdtvGw5kpDP0YQCTiYWUqMXKaqoRqcXkcsETiQWArAl6taJ5K3U9xvJB4j/03XDABF4xE7gRAAAIABJREFUQRTF5cAz1LYODq/nsRsdk9/zu/7NnIlMK+FUUiE6vci5lKJb7r8lYQtu5m50cOnwEKOUNFb9vfuTV5nHpYJLd/3LUPLXRFFkQ/wGjmceRxRFTmadZG3cWgb4DOCDTh+wffh2ZnWehYnchPePvY9O1PFdn+9YN3gdjmaOUuInkTQwURR5e9NFxv8UyeHfuz8ftOoaPfvjcm/Zencnc3bFERGXy/FrhST+aejXtRsuLzxwjU92xKKu1hmuS8wvp/2nEey6lMPkXyJ559dLqLW12+fsjEOlqWF8Dz+SCyp4a0M0s3fEGm4blVbM+dRiAPZczgFg8/lMzI3k1OhFBAHUWh3JBeVodXrOJBdhbaokJuvuhxnVt+XPDsj903VhQKooipcARFHUC4JwGuhaz2M3OiaK2l8l/UNc+HLfVWp+f/GcSiqiZ6BTnX2zyrM4lX2KCaETpFYeCQA9PHugkCl4Y/8bWBtb88vjv2BpZNnQYT2StDot7x9/n/DkcCyUFnRx78KelD04mTrxXsf36szOXdB7AfmV+YS5heFo5tiAUUskkhttOp/B9ugsAE4mFtLrhu/RC+kllGm0dGv61+/Za3nlxGSV0s7HDncb05u232r27ZaoDP61+RKfDAth9F9M3NRodVzMKKW9j62hQsPPp1NZcTyFJ1q5sfVCFrsuZtMtwJGtUZm08rQhPqeMUE8brmSrqKrRU1GtY19cLkNDa4eKrT2dRrVOz49HEonOKK1zvr2xufg5mvOvgYF0aGLLnsu5bDifzmvdfSlVa3lz/QWsTBQEuliyPToLlaaGvbE5PN/RG38nC/SiyKxtMczZGUdGsZrKah2fPBHMsqNJpN7dU1Hv5E8LGAayCYLgBPgCP/1pv0rAop7HbnSuv3wCnC3wtjejpFJLEwdzTicX3rTvtsRtAAzzH/YQI5Q0ZlZGVnR3787J7JOUlpXy5bkv+Sjso4YOq9Hbem0rK3JW0K66HRZGFhzPPM7KmJWcyj7Fi81eZN2VdexJ2cMrzV/h9Zav37RubphbWANFLpE0brFZKiyMFXjZ175nStVafovO4rkOXvetXIlGq8NEeesapz+fTqOpkwX2FkYcv1Y7UaK8qgZTpZwZG6MpKK/i7Pt9UcrrNqCoq3UcvprHm+ujUWt12JgpOTyjFwUVVUxdF8X8Ea1YdDiRHdHZPNvBk4+HNTfc9vi12u/r/4RfoWegE7bmRpgp5chkAlqdnoLyKmZti2FfbC6zh4WQUazmQnoJZ5KL6NbUgS+eCSWzRM23B68xP+IqMkFg5YkUAJ5u60FbL1ucrYxZeSKFr/dd5WpOGRN6+hnG392Y+DlbGaPTQ0F5Fb0CnRAEgd5BzrT2tGXX5WyeX3qaUnU17jamrB7bkYTcMt7edJHt0Vn0CXJmYk8/nKxMqNHpmbMzjoPx+ZgoZViaKBjcwpUXOnohm3l3z1N9k7+rQBdBEExEUdQAT1Hb5XvsT/u5Ann1PHajJQgCHw8NoaJKR0xWKYuPJKGu1mFqVPsCr9JV8WvCr3Rw7YCbhVsDRytpTOZ1m4dWr2XZ5WWsuLwCV3NXXmv5mlT/7y9o9Vq+ifyGvKo8Pjv7GT08ezDt4DTMFGbM6jyLZwKeIcQ+hAJ1AaObjZYeR8k/wppTqVRU1XYT/pVclQaZIOBoaXzL7Tq9yEsrzmBmJGfPtO6YKOUsPZrENweu4WBuxKAWrneMo6SymkELjjKlT1Oe7eBFcUU1q06mkF2iYXgbd0rVWib9HMlTbTz4YEgz4rJVHE0ooJWnNe42ZlxIL+HfjwejrtYxP+IqRRXVDPnmGK7WJoYxdLO2xXAxo4R3BgVxLKGAQS1ceW31OfLKqghwtmB6/0DG/3SexUcSqaiq4XKmimd/PEVhRTVNnSz45Uwa7ram7IvNRSGTkZBXTocmdsRlqXhp+RmySzW08rThpTAfPttzhaT8CgAcLIyYtS0GhUygqbMl7wwK4uUuPijkMt7o3ZSfTqXSwt2al7r4sPpECl/svUqAswWvda99TpRyGYuPJPLtwWtsOJdOcaWWMWE+rDyRQrCrFa29bLAzMyI6o4SjCVX0Cvqj1dPW3IgNr3dm6roomrlZ8c2zrbE2VdLS3ZoWHtb4OVrUSYgVchnBrlZcSC9h1csdaOtti0Jevx7H+iZ/G4G5wBFBEI4BrwLVwNbrOwiCIAfaAOfreexG7Xo3r14U0elFkgsqaOZmBcCa2DXkVOQwp8sjPb9F8gBcb5Wa0noKhepCvr3wLeoaNVPbTJUSlxvU6GsQEPjt2m/kqfPwN/Zny7Ut7E3di5+1HxuGbMBIbgTAY76PNXC0ksYmvaiSvDINbb0fbHHufb931/k63rljK7WwAlMjeb1WiKqq0WGsuLnVbOXxZPJUVbzatQmXMkv5aHssK8a050q2irY+thjJZby47Ax6UWT7G105mlBAYXkVI9t7otbqMFXKOZdSRH5ZFQA/HkliUi9/Np2vbZ1afTK1TvJXqNbz0vIzCAJ8NCSEn06lMrVvU34+nUZ2qYZ5u+Lo38yZ19ac53xqMRbGCtafS0chE3CyNGbj+XROJReSVlSJKIKFsYJOvnYYyWUMb+1OSmEFX+6DlSdSyCxRk1miRiETUMplhooao5edqY31aBLGChnfP9+GnoGOmBkpGBbqxtJjyRjJZVgaKyisqKZHgCPznmxBj88PMnfXFXwdzQ2J3dsDAnDo7surq88R5GLF+dRiTiYV4mRpzHuPBeFkaUKopw2f7IhlQk8/2vvUfR11D3Cke8Af3dGTezelk689IW5/VPR4pWsTXunahC/3xvP9oUTmDm/BkFBXNp3PYHBLV0MtwK8jrhKTpaKdj22dcwS7WrFnWvc63wsymUCQi9UtXysj2nkS4mZFR997K6xS3+TvK6Af0AtoB+iAaaIo3tjK15/aruEj9xRRI+f3+5s+Mb8cXycjxu4dy8X8i/Ty7EUHV2mih+TWFDIFn3T5BBO5CcsuL+NK0RXmdJ2DvekjXxHp/6auUTNi+wgyyzPR6rUE2gYywXICx02Os+nqJqa3m25I/CR/P3q9SEF5FU5W9V9G87o5O+M4cCWPbZO7EOx685elulpHVqkaT1szclUadl/OoWegI5N+ieS759rQ1PnOY3G3RmUybf0FBoa4sGh0W8P1RxPymfxLFDundMXD9vcfe2uj+C06Cw9bU/a92cPQSwS1g/nn7Izj1W5NGNj8j4Rr2bFk/hMex8j2nnwwuBl5qiqcrIzR6UWSCioQRYjOKGHdmXSi00uYui6KowkFvPdYEJ187YnPrV2Tuufnh8hRaQCwMFHw5voLBLlYYW2qxFgho1tTRxbuT0Ct1ZFdqqG1lw0nkwpZcTyZ/iEuuFiZ8OV5DVnlagAmqCKJy1ZxLrWYjOJKgl2tuJpbxvNLT3Mlp4xPhoXwTDtP1pxMZV9cLvNHhJKQV87knyPpHejE1L5NeeK740TE5TGlT1PsLYyxNlViZ27EkiNJALhZ1yZfcpnA7ss5LBjVmpNJBXRsYs+nO2OZ3i+Qx25ITj8cEsLlLBXX8spZ8mI7LmWWMqq9J242pswd3gJNjZ7nO3gx8edIdsfkEObngKedGUdn9sLFyoT0YjUF5VWEuFlhZvRHGrR8TPs7v9h+187n1j80pvcP5PUefoaKIEdm9sLK5I9zTOzpz0udfW6Z5NenQeC5jl533uk2hPrOQhRqo+sKOAORoigm/Wl7L6AlsP3P2x41gYGBYnx83cnN6modzT7czdQ+TenZspLR4aMZGTiSKW2mYGV06wxd8vAdOnSInj17NnQYNxFFkbVX1jL//HxCHUP5sd+P/9g1gDU1GrZe28qF/AvsTNrJMwHP4GvtyxP+T3DuxDl69OhBkaZISpAfQfV5/206n8F7v17i6L964XyPCWCnufvJUWlo5mrFjje61ikhUlBexbBvj5NZoqa5uxVOliYcuJKHnbkRRRXVTOvblGl9AwA4GJ9HjU5EFEWWH0/m3483o7m7NaWVWjrMjaBap8faVEnkv/tx+Go+h6/mE5VeQnR6CXOHt+C5jl7kqTR0mLufrv4OHLtWwKtdm/DuY8HIZQLZpWp6fHaIap0eJ0tjDr3dE2OFnLhsFSMWn8Tewoj0IjUDQpzZF5uLvYUxY8J8+HxP7ffQG739WXMqlZJKreH+tXC3po2XDWvPptPUyYJreeX8a2AQs3fE4mJlQo5Kg4+9GSmFlfRv5sznT4fy+DdHyShW09TJgrWvdWLK2ihDuZAQNytislTMHd6Cj36LoVqnp42XDVdzy5HLBJa+1I4rOWV8sPUyLlYmHJ7Z85aJTGV17Vg+QRD47+4rnE8pZs2rHQz7ztwUzYZzGbham3Bgek9kMiip1JJeVFknsRJF8ZZJUV6ZhuPXChgW6v6XJWNK1Voi04rrTCz5uxME4bwoiu3utF+9l3cTa7PFo7fZfhA4WN/jPipMjeS425iSmF+BWUYcAEGmQ6TET3JXBEHgueDnMFWYMuvELBZGLeTNtm82dFgPXVZ5FtMOTiOuqPY9NNRvKLM6z6qzjyAIUuL3NxSTVYqduRErT6QQlVaCt50Z1To9p5IKGdbKvd7Hy1NpyFFpCPW0ITq9hOOJBYYZo1qdnkk/R1JQXsXrPXxZfDgJUGFpoqCoohqFTOBYQgHT+gYgiiL/3nIZlUaLq7UJV3PLefL7E6x8pT2ZxWqqavSGMVzhl3OYuSmaihtKe5xOLqR7gAMH42tLmPx7cDBLjiSz9Fgy++JymdTTH4VcoFqn55MnmvPB1su8vekiqYUVXM5UYayQ8fPYTvx3zxV2XszGx96MGr3IF3trEz9nK2NWHk+hrKqGJ9u482tk7azTC+klXM0tY0CIC58MC6FMU4OnnRnrzqZxNbecUA9rNo4PY2tUJu2b2GFtpmTN2I7EZqno18wZI4WMn1/tSGRaCftic1l0OBFPSxmj2ntyIrGAnZey+Xpka8MkEYD2PnY4WRrjYGF8y8QPqNOi9q+BQTclcQObu7DhXAYdm9gZWkadreQ3/QD4q9YwJ0sThrf2uO1rw9pU+Y9K/OqjXsmfIAhJwEZRFP91h/3mASNEUfzr0amPMD9HCxLzyrmmO4+oV3IlXQ6hDR2V5FHyhP8TXC64zPLLy/Gw9OCZgGcaOqQHokZfw9g9Y9GJOma0m0GoYygXCy4yef9kdHodX/f6Gg8LD3ysfRo6VMldUGm0aLS6eo1jK9NoWXk8hZe7NkEuCIxafIowf3sScstJKqggtbB2XNbZlCL6BDvz9A8neK6j103rqV9PHq7llTNtfRStPG2Y2ieAi7/Pppw5IJA31kYxe3sscpnAN8+25ufTaZxOLuKrkaE80cqdmEwVZ1OK2DqpC6eTikgtrGDpsWRUGi3ZJbXLddXGXM5b/QLYHp3F62vO42lrhruNKa/38GXliRSmrovC3FjB7GFBnEspprJax/64PLZHZyEIAp52pgQ6W/LZ0y3pE+zEosOJzNx8kWBXK6xMFDzfwYuCsiq+PXgNU6Wc2cNC6OrvgJe9GbMGN0OvF5nSpyknEgv5ZEcsliYK3uwbwH92X8HN2oS5w1vwSpcm2Jkb0eW/B3C3MeWDwcHYmBlhY1Y7RKKrvyNXc8vpG1yb4I1o/8dqNk0czGniYG64LAgCbb1taettS7emDmRevYhMJvDvx5vxTDvPOonfdQNCXO76NXD9HDfq4u9AJ187hre5fQIneTDq2/LnA9xN4SyH3/f9W/JztODw1XxMlUkIMmficu5u3V+J5DpBEHiv43tcK7nGkotLeNL/yUe++1cURQo1hTiYOhiuWxO7hsi8SCyNLBkdPpom1k3Ir8zHzsSO7/t+j7eVdwNG/M+l1emZsjaKcd19aeNle+cb/O79LZeJSivmyNu96nS16fUin+2Jx8vOjFG/JxkarY6YLBVLjyYRfjkHW3MjLIwVlFXVcDShgMrfW81yVbWTEM4kF7E3JocrOWXM3h5Lc3drQ2zrz6bx3cFEvhoZyutrItHq9FzNKSc2S0VnP3tkArT2suGZth4s/n0c2ZgVZ8ksUfNKlyaGFqJvn2tNjkqDn6MFfo4WnEwsZPGRJF5ddQ5r09rVFfwczcksUTOmiw9PtfVg1I8nic1WMa5bE1ytTfF3siC3VMPyMe1o623Hi519WHMyhYi4XOzNjVBptDzewg1BEJAL8FgLV3oEONJ+TgRx2Sp6Bzkhkwm82S+Aoa3cMJLL8LT7I7lytjLhhxfaGv7/b/gVmrlaMaqDF6M6eBmS4ObutZMNNo3vjI+9OfYWdWf5Dmrhws+nU+9qFu+Nuvg7cCijduaoi7UJLtb3PhbzdowVcta91vmBHFtyZ/Xu9r1LpkDNAzp2g/Nzqv3FZGSah6O8JbEpqr8clyCR/BW5TM6zQc/y9pG3+eTUJ3haejK2xdiGDuuebYjfwJzTc3iy6ZPkq/MZ7j+c7y98Ty/PXszrNo+dSTvZn7YfexN75nWbh4t5/VoOJP+fg/F5LNyfwNpxnUjMLyf8cg4ymUCLkdZM+jmSjGI1L3TyxtPO9JaFdvV6kaMJ+ZRUaolKL64zs3bB/gQWHU4E4OPtMXRwlhGpTWTh/gQAFDKBvbG1qywIAobE77rWXjZEpZWw6kQKbr8nG5/siOXXCWGUVdXwn/ArFFdqGbH4FGZKOVsmhRGTpWLqugtcyiylqZMlZkYKpvRpSgsPa/JUVczeEUuYnz3vPRZkOM+NLWMA7XxsebK1O2dTiziTXEQLd2sWPtuaXJUGKxMlViZKNr4exoL9CbwU5gPAspfaIZcJhskdUFsNwtHyGvNHhBLkYoXNDct0AZgbKxjU3JXNkRl1ZpL63WHWsJ25EfOebIHrDQnYn79n/mqGc3sfO2I+HlDvEiCSf4b7nvwJgmANdAFy7vexG4un2nig1Zfz5VUVQfZN2RGrJUelwdX65orjEsnt9PLqhZWRFZsTNiMTZDzZ9ElsTe6+JaYx2ZW8C4VMweaEzShlSo5kHMFMYcZ7Hd/DXGnOiMARjAgc0dBhPhLu949JnV5kzs44ruWVE51eYujePBCXx782XWRvbG5t2YstlxAEOP1eH2KzVHz4WwzzhrcgzN+BuByVYaLB9uhsHCyMKaqo5mB8Pgv3J/BUGw96BTmy/mw6xxIKuFqWRqiHNeO6+3IhrYTlx5PRixjGzSnlQm0rU3w+M/oH8srKs0RnlDKxpx+uNqZ8sPUyc3fFcTq5iOJKrWGc23+fbom/kyX+TpakFVaSWaI2rKpgbqxgcEs3anR6bM2V9A50vm3yo5TLmD+yFdU1epYfT6aFu/VNXaIu1ibMe7KF4bK3vflNx/G0M+Ps+31v+xw819GL7dFZ9Aio36ozT7W9925RKfGT/JU7Jn+/j/O70dOCIPS8zfGcf/+77P8LrfEyUcoJaVIJV6GtazA70BObpZKSP0m9GcuN+SjsI6LzolkVu4ojGUceqVViFkYuxExpxnD/4UTlRTE+dDzPBz9PfmU+E/dPZHzo+L9lC19VjY4v9sQztqvvfe8WG7f6HEq5wHfPtal3AiiKIicSC2nnY4uxQk5VjY6tUZnsj8szFNE9n1ZM6e9JnFqr49eoTKb0acrkXv4cu5bPKyvPsehQEitP1CZry4+noNWL7LqYDUBLD2tWnkgxrHIAMKyVG3OfbI6xQk6ImzW9vjhErqqKKX2aMrilGy5WJiw9lkxrLxvefSyIyLRijBUyJvTww9/Rgi7+DoRP7cbqk6mMCfPBylTJtwcSWHI0mQBnC+YMb85zHbx4Z2BQnZIwb/RpesvHQSGX3XEywI2MFLLbFlC+H9p623L54wEYKaSETNLw7qblz+eG/0Vql227XVv19aLPt50U8qi7UnQFgD5+bZgtnCMqrYQ+wc4NHJXkUdTPux99vfoSnhLOgbQDDPUb2iiHEIiiyLncc7RyaoVSpmRvyl6WXFoCwLWSa4iI9PHqg7WxNdbG1ux5ak+jvB+3kl5USVJBxR1bZQ7F5zFrWwyTe/uz5GgySrmMmQODbnub62KzVMhlAoEuf9SUu14w3t+p9iM1T6UhIi4XUaxd//P6oHqNVseSI0kEuFjSqYk9r/90jooqHa9192VwS1eqavSYKOUcuJLH2FXnmD0shBc6ejN62RnOJBfhaGnMsFZuXMwoJTK1GK1OJPD32nZtfWx5s29TBEGgZ4AT9uZGLD+ejLmRnKGt3NlwLp0DV3LRi+DrYM68J1uw7UIW/o4WOFga4WhhQnN3K8Nz3cTBHH8bGUmlevo3q42/rbctc4e3oH+IM8YKOYteaIsggKu1qaFIra+jBR8NDTE8NpvGh1FVozc8NsD/VQuwMZASP0ljcTfJX5Pf/wpAErAJePsv9q0G8kVR/NuO97surjAOR1NHvKydCfOzZ0tUJm/1C/jLekMSye0IgkAvz16sj1/PwM0D+U/3/5BQnMAAnwFYG1vf+QAPQURaBG8deoswtzDkgpzjWccJtgumSFPEzqSddHbtTIBtgGH/RyXx2xOTw5S1UVTV6Dn+Tm/DgvHZpWocLYwNXWeiKLLsWDJpRZX8J7z2x9/OS9m8PSAQQRDIU2lQa3V425uj0erYG5vL4BauyGQC5VU1jPzxJGWaGsaE+fDR0BAuZpQwZW0UKYWVLH2xHWlFlSQVlCOKtUVvP9kRS+8gJ5RyGb+cTuPLfVeB2gSiRqfH19GCKeuiWHwkkcxiNQdn9DTUgztyNR8zIwVnkov4eGgIL3b2RhAE3t4Yzf4reShkAl39HfhyROhNKwp0berAtgtZDG/jzuhOPqw9k4aPvRkvdPLGz9GCEDfrOisb3MqoICNMXf0NS40JglCnKK2bzZ17SW6cBCGRSO6vOyZ/oiimXv9fEIRVwNEbr/uniiuKI8iu9hf/qPZevLE2iqPXCuo9nkMiuW5iq4l4W3mzKmYVL4a/CMD+tP380PcHZMLDbzHYm7KXnIocRgWNQi/qCU8Ox1RhyomsEziZOTG2+VieC36OQnUh6WXp9PbqfV8SPr1epKqmfsXnryuqqMbKRHHLsU6V1TXM2hbD1D5N6yQW3x9KxNxYQVVNNQeu5FGuqald+3PFGUa082DW4BDeXH+BuGwVyb+XJSmqqMZEKSO1sJJzqcU0dbLgie+Oo9WLHP9Xb1adSGFe+BUUMoHHWriy+XwGZZoa+gY7sfJECsZKGRvPZWCqlONsZczMzRcpqqgGoKmTBe8MCmLsqnNsjcqkV5ATPx5JokMTO17vXltqZEhLN4aEuvHc0lPEZKmortHz2przXMkpw9POlJOJhVxIL6WVpw2jO3kbnpe23rZs/H1Jr0AXy1s+X/2aObPzYjajO/kQ6GLJl8+E0sbbts44uDvxt5HTs6M0k1siaazqNeFDFMWXH1QgjxJNjYbk0mR6e/UGoH+IM/bmRszdGUeoh3Wd2WSSxq+iqgZz4wc18f3u2ZnYMbrZaLq6d2VR9CKczJxYGbOS2Sdn836n91HKlHc+yH2g0+so15Yz68QsKrQVfB35NQqZAp1ex1MBTzG2+VgcTB0MpWkcTB0ItAsEoEan/78HmX8dcZWVxyrp2u3m5+VyZinWpkpD8iaKIhnFajxsTckoVjPw6yNM6OnH5N5/jAVLK6zk59OphHrasOl8BvYWRrw7KBiAjOJKotNL+B979x0eVZX/cfx9Jr2RHkogtEBC70VUCCSWXQsqiIugi3Vta91l/bm6btFVLKiromDDxS6uLrgCQiAKikgTIUDoEEASIKT35P7+uCEQeiDJzCSf1/PMc5mZO5PvMLj57Dn3fM8fL4njzcXbmDRnI/klRyYuPl2x2x5VS9tPUNUWTaP7tWbmyt3cnRDL699s5drXl+Ln5UFRmb2CdW7qPj5ZkQ7AO99tJ6lLc97+zr7e7fXx/bj+zWVM/WYbzZv58N6tg0jekMET/9tAj+hgokP8uKR7c0bER9GtVTMmfvYzhzdhen5ML86PjahxeclHtw8mr7icW6Yv58ftWfSJCeH2Cztw5/urKCit4K3f9q8xG3Fl71Ys33GIRWmZnB97pCXP0S7r0ZJB7cOrR+3OZcGBiLgm5//GczMrM1Yydc1UKqwKuoTZv0B8PD146Td9uPnd5Vz7+lJeub4vIf5efLF6D7dd2EFTwfXEsizuen8VF3drXquLu/fnlbA5I48hsRF8uiKdh/+zluev7cVVfWq3u8BHP+4idW8u/7iqe21LP6X2we2ZNHQSlmXh5fDijbVv8O3ubxnfdTw3dbupTkbXduXuYu2BtXQL71ajwfLBooNc9+V1VFgVFJQVMLrDLXh45fNT5k+kHUrj4raX0DzgSPg43LrDGMOsNXv58+drmXf/0BrTepO/TiOnqIzbhnao0R7jRErKK3hv2S5yS+GLn/Yw7qjRo++3HuC3b/9I7zYhfHrHEMDeGP5vs9fTNyYECygorWBR2v4a4W/69zt4+7vtdKq6dmzuun08fGk8xhi+WmsvYrisR0vW7s5hbuo+OkQEkF9Szpj+bXhl0RYWpe3nb1d24+JuzdlxoJD2EQHkFZdx/aAYRvaO5uv1+9i6P5+EuCie+N96nvzfejJyS+jVOpjlOw5x1/ur2HmwkMev6Iqnh4PpNw1gb3YxbcP98fJwcN2ANqzelc3vE2NrbOI+aVRPvli9hxbBvgxoF0avNiHH/X35eHrgE+jBTee3Z+LMn/nHyO60CfPH29PBVb1bHfcaf29Pnh9z6o70xpjq4CcijVOtw58xphlwN5AItAJOdgWu1dh2+NhfuJ8HUx6ksKyQIO8gekf1rn7ugk4RTJ8wgHs/+ombpy/nyt6teC1lK/3ahp50A+imrKyiEg9jzikYbz9QwJx1+0g/VFgj/BWVVrDuQAWdsovYlJHHmvRsrujVqrqn1gsLNvHBsl3cfH573vm5vUiIAAAgAElEQVR+OwZ4Zu5GhsSGExnoww/bsigoKeeCThFsycwn2M+L+z5azeQxvWl31NTXR8vTWbM7m/uTOh3XYLUuGGO4t++99I7qzQcbP+CFlS+w7sA6Hhn0CKE+oWfdFDolPYU/ffsnCssL8XJ4cVfvu1iwcwFbs7cS4RdBVnEWvp6++Jb24bPkLiQ/lIBP3xJmbVjK+FczePu3BxgSG4FlWYx7cxkRQT68PLYPyRsyyCsuZ9q326ov3F+16xD/WrgFsEfE5t0/9LiRccuyuO3fKwn286Jbq2ZkFZTi5wn//n4no/q25sUFm/H2MLy5xF59unLnIRZv3s/Pu3OY+s1W4lsEkV1Uxrb9BUSH+LEmPZvC0nI8HIbi0kqSN2YAsDkzHy8Pw86Dhdzz4WoqKiySN2bQJyaEdhEBDIkNZ27qPh66OI5f92iBMYZAX08iA32qR78Or+ifeoO9dWZ4INx6YYcan+Xvs9fTLtyfN37bn7veW8WCDRlc3LU5I+Lt0Ozv7VljEUOQrxevjut73PfUPTq4upHv6Yzs3YrELlEE+dqjw3Pvu/C0QVtEmi5jWWd+bY0xpg32vr5tsBeAnIplWZZbb1kQFxdnpaWlVd9/atlTzNw0k0+u+IQOwR1OOALzyYp0Js78mVB/Lw4VlnFXQsczXg3YWDwzdyNhAd41fike7dtN+/nDp2uIDvXjrd8OICzgSBhYlJbJi/M38cRVPXh36Q725RRzx7CO+Pt48FzVxexPXNWdDpGBTP9uO3+dvR6AxROHsye7iEVpmSzblsVP6dk1fublPVvyyvX2L9ihzyxiV1YhAIPah3HHsI7cNH05AMPjIlm2PYtKy2JY50jmpWYwqH0Yy7ZncVdCRx66OA4Ph6G0vJLuf51HaXklL17Xu9ajhrVlWRbvpr7LS6teotwqJ8w3jGkXTauebj0TBWUFPLz4YVLSU2gTEMuAoFtZnj+V9PztdAjuQPeI7szbMY8b4+7k/KgrGPXaUsCTge3CuOXC9qxJz2ZKylZiowKZc9+FJG/I4I73VuHt4WDlY0lc8sK37M0pxtNhCA/05sXr+vDC/E1sO5DPy2P7csNby7ioa3OevLoHizZmUlpRydRvtjKofTgfV02TAnSIDGBoVBnTU0sZ1bc1n62yr1Eb2C6M24d24NZ/r8DTYSivtPB0GL6670I6Nw9if14JqXtzmPDOct6ZMIBXFm0hbV8e+SXlBFXtLHHLBe35YNkuPD0M4QHe9I0J5bHLuxIa4E1RaQVz1v3CVb1PvlF8bZVVVDLrp72MiI8iNKDpXA6SkpJCQkKCs8uQs6Tvz30ZY1ZaltX/tOfVMvzNAMYBq4BJwEYg92Tnu/vCkGPD34S5E6iorGDGr2ec9DX780oY8OSC6vvxLYKYe//Qeq2zIVRUWngc9Qsxv6Sc9KxCurRsRnpWIXe8t5J/XNUdA1w95Xs6RQUy/8FhpGcVMi91Hzee1w5vTwe5xWUMeGIB0SF+7M4uolfrYD753XkYY1iwPoNb/70CgBvPa8uMH3ZisDfnjgyyG8pWVFpYwJ3DOvLt5v2s35vLocIyhsdF8t2Wg5RWVOLj6eC6zp606xBL5+ZBzF6zl/+u2cOKRy8iK7+Uoc8u4sbz2uLn5cG9iZ0I8PHky5/3snpXNm8t2Y6/t8dxOxCAvQKzrNLid0M7MKh9OFe8sgSAXm1C6NPG7l92sk3O60paVhqL9yzmw40fggUvDn+R7hHd2ZW3i4W7FhLuF86v2v2KfYX72HJoCwltEtiQtYHdebt5c+2bbDq0iUtb3cRnKe0oK/fEx6eAP1wF13cdSUm5obislBHPL6bSsoPL74fH8s73O8grLic8wBsLe7FDy2BfcovK8PRwkFNUxp8ujWfS3I38blgHdmcVsWrXIbILyygqq2DSqB5cNyCGad9u5Z9fbaxxfdzhP7cO9WPKuL78klPM4Pbh/LB0CROXlJFTVEbHyADeu3UQUUG+GGDwU8lk5pUwZVxfurRsVmMhQkFJOT3/9jXBfl5kFZQS6ONJfkk5z47uyZ8++5lZ91xAi2Bfmvl6qe1GPVJ4cG/6/tzXmYa/2k77Xoy9c8dwy7LyzqoyN7Y9ZzvDWg875TmRQT70ahPCmvRsftW9BXPW7WNRWibD46IaqMq6V1ZRyfDnUogJ82fymN74eXkw9o0f2Lgvl9m/v4DH/5tK6t5cZv20l7R99j+L7QcKyCkq45Z3l7MpI5/vtx5k7MAYDuSXUFJeyeTrerN2Tw6PfbGOj5anU1hq9zGLr+qB9vmqPViW3cT1X8mbOVRYxnPX9qJ/21D+/MVanqpqtXHD4Lak7ctjUdp+ercJ4Y0b+xPg48GP3y8h4QK7S5Gvl4OPV6Qzf/0+ikorAbjxvHY1pt4u79mKy3u2omfrYCICffj30h0s3nyAexM78fzXaVw/MIZ3l9r/X+aTFen4etkhr1/bUFbuPMSa9GwGtg/j17XcR7O24sLiiAuLY2jrodydfDfXf3U9/p7+FJYXVp/z0qqXKC4vJrc0lwf7PcjklZMBiPSLpJ/v/Xy0IJKerYN5ZnRPfjPtB1770jDp02TKKy06RgZQVmFhsLeHevDiOG4f1pELJy3kYEEpD/8qnpgwf75YvYfwQG8mDGnPuDeXMWWRPbU7slc0XVs1Y8nmA4x/axkXd23OmP72Xq+3D+1IWYXFrJ/28ufLuuDl4SA2KpAHPv6J8YNj6Nk6hJ5Vs/c+HoYx/VvzxuLtjB0YU6OB+j0jYtmXU3zCv+sAH09+N7QD3209yC0XtOeirs1J3ZvD1X1ak9SleZMafRMROZnahr9mwFdNMfhlF2eTVZxFh+ATT2UebXTfaPKKy/jrld3YlJHHTe8s5/Xx/bi0u3vtdFBZaTFrzV4CfDzZfaiIvdlF3PDWMsIDvdmSmY+flwdjXl9KQWkFEYHezF6zl4MFpXSPbsa6PblMnLmGzZn5jB0YU9UoNhMvD0PbcH96tQ4mvkUQLydv5v/+sxYAf28Ppt7Qj09XprOxKkROGNKOn3dnsyUznyt7tcLb08H7tw5m7e4cPlu1mxvOa0u78ABKyivw8/I44VR835hQokP8+O9Pe/F0OGgZ7EvHyBO3rRjZ256+7R4dzMH8EjpEBnL9oBjKKyy+Xp9B+4gAvt96kM9W7SYswJtnR/dk4cZM3li8jc9W7mZwh3Ce+moDmXkljB/clou61k/j786hnfnPlf/hk7RPyCjMoH1we4a2Hsr2nO1MXzednNJcCg4V8MLKF2gZ0JK7uz3Ov+aUkJxZxK0XtOcPl8Th6+XBs6N78eKCTYzu15o9h4r439pfuKZPNLdc2J7QqmvzAn08+d2wjkyau5GkLlHERgXVCF43nteWfyVvplWwb3UD4ws6RTD7ngvo1Dywxndy9/BY7h4eW+OzvHfroBN+xtsu7EB+SQVjBrSp8fiN57U75d/NsZdZdK5qZqzgJyJiq+207wZgs2VZV9ZfSa7j6Gnf1ZmruXHOjbya+CpDW5/5NG5xWQUjX/mOwrJyfD096Nk6pHobJFe1ZPMBXlywifGD23L/xz8R6ONJpWXx0m/6cFvVtOzkMb3IzCvh6Tkb+fOvu2Bh8c+vNuIw8PaEAUx4x76G7vzYcN6/dTC5xWXMWLqTZ+elcX9SJ+5PspsBz133Cylp+7krIZbwQG8CfDyrr5uMCfPn24nDKSwtp6Sssla/vI+dtpg0dyPTvt2GAW46vx1/vqzrWf3dZOQWM/ipZCzLbvnx3LX2ysmn5mzgzcXbiQj05lBhGZGBPuzPK2HGLQOrdzA4LL+knFcWbmFY50jO6xh+oh9TfV7gCVrQbMrIY966fdw+rEP1v6OM3GJeSt7M7kNFXBAbzsqdh1iS+zyOwHV08LiO9Rv6EuLvzeQxvbiw04l7UVZUWny+eg8j4qNqXIcJ9v8R2HbUThTHKquopNKy6uzftaad3Ju+P/em78991de073vARGNMuGVZB8+uNPe0Ldve4rh9cPvTnFmTr5cHEy+N45Z3VxDk48nmzN0sSstkwpB23HuSfSnrw6GCUnKKymqsVj3auj05ZOYVc16HCGav2cuKnYfYst/eCzS/pJxf92jBRV2b88RV3SkqreCavq2xLIvLerSkTZg/qXtzADg/NoLBHcJxGKi0qJ7ububrxd3DY7mwUwRdWh5pZ3Fp95Zc2r3m9F3vqvYUh4/+3p6ca+vEkVWrrwGu6Xv2fcuaN/PlroSOeHk4aoxgjR/Ulp92ZePnbV9H2DEikCtfXcLfZq/nruEdmb1mL1f2iuaHbQdZviOLjfvyeP2brQR4e3DrhR0I9fcidW8uz1aFya378/nVi4v5yxVdGT+4LTsOFLArq5CS8kr+7z9rOZBfQureXJ4f04uN+3K5efoKikor6BAZwD+/sqfEHb5DaRVUypr1cfx2UAy/T+xExClWJXs4DKNP0tPN4TAnDX4AXtpAXkTEbdQ2/E0CEoCvjDE3WZa1vu5Lck3bcrbh4+FDq4BWtX7tiPgonr+2F/3bhbLtQAGTv97EG4u3cc/w2AbrAfjX2aks3nyA7x8eweaMfFoE+3Lz9OUE+HgwYUh7/vTZz+QUldE3JoScInvT9+zCMi7p1pxfcoq5fqDdb2384CN914wx1c12u7Roxpj+rRnVtzW+Xh60iwhg2/4CEo651rFn6+N7lR2rY2Qg53UI57KedXf9XHyLZsS3CMLTw9QIn2fjj5ccv3q7TZg/H//uvBqP3TSkHX+dvZ7/+89a8orLmZeaQYC3BxFBPkwZ15e92UXM/vkX3ly8rXrhxB8vjSMqyJdPV+ymtKKSJ/+3ge0HCpixdCelFfb1iqH+XvxuaAemfruNxU/up7CsgnbhAbx1V3/aRwTwxuJtbMrI57NVsHfDzUQE+PDXK7u5zXZrIiJSv04Z/owxC0/wsBcwAPjZGLML2AVUnuA8y7KsxHMv0fn2Fexj/s75xIbEnlVvNWNMdZ+wtuEBHMgr4Y8zf2bDvlz8vDzoEHnyEZW6YFkW3205SFZBKePfXMaKnYfoER3M+l9yadHMlzveW4mHw95784NluwCICfNnV1YhN57X7qQ7ARzN4TA8M/pI89herUMwcNJr607Fw2H48PbBtX7d6bx788DT9ieqS1f2jubJrzaQV2yvNg0P9GZIx4jqxSJgL6oY+ep3gL369evUDFqH+vH56t30jQlhb3Yxby3ZzkVdm3PLBe3xdBjiWgQR5OvFJd1b8NGPu2gd6s+4QTHVvQZvH2q311y7O4e0jDzOjw1X8BMRkWqnG/lLOMVzDqBd1e1Ezm5zThcza+ssnl/xPKUVpUxOmFwn79m3bSgAd763ij3ZRcyp6lNWWFpeY9HClJQt/Jyew2vj+57TL+9tBwo4kF8CwIqdhwBYuyeHMf1b84eL47jx7R+5qGtzbj6/PZ+uSKeswuKpa3pQaVkMOcU1aafy95HdKC2vdKnQ0bzZyfqR14+wAG8u69GS7QcLGd2v9Qn/Lnq1CaF/21DKKi1+yS7i8VmpVFTa/+n87cruJHWJotLihG1J+saE0jcm9KQ/v1+70Krwd/rwLiIiTcfpwt/wBqnCRZVZZTy65FF6Rvbk0cGPEh9WN82aO0QEEOLvVd1o+Nl5afztym4kPv8NT4/qwcje0WQVlPJy8haKyipYufPQaXcJWbEjizcWb+O5a3tVd/k/bNm2LAD6xoSwalc2L/2mN3PX7eP+pM5ENfNlzn0XVgeT4XFRLErLpG9MKH7eZ3/x/rE1NFXPj+mNZVmnDMHTbx4IwN9mpfLpyt3cn9SJ3m1CGNY58pzC8/C4KD5ftYehJ1ngISIiTdMpw59lWd80VCGuKLsimxbeLXg18VWCfc5sm6UzYYyhT5sQFqXt5+Kuzfl6vb39VFFZBbN+2svI3tFM/247RWUVBHh78PZ3208Y/p6bl0aIvxe3XtiBz1fvYV5qBrlFK/HydPDXK7ryU3o28S2asXBjBhGBPrxyfV9W78rmsp4tq1uaHK7nsMMLDM4l+MkRdmPsUwe4wyt6703sxMD2YScdJayti7o2Z/VfLqoxzSwiIlLrvX3dhTHmeuBOoCfggb0byTvAa5ZlnegaxeMUVRYxoduEOg1+h904pB2dmgdxf1Inhj2bwvyqALhkywEKS8uZuXI3w+MiiY0K5O3vdpBXXIaHw/D4f1O5a3gsbcP8eff7Hfh6e3Dz+e35KT0bb08HS7fZi7AnvLOcXVmFeDgMFZUW9yZ2olWIH61C/E5VFq1D/bUnqJO0CfOvXkBTVxT8RETkWI2yP4Mx5lXgfaA/9l7E84HOwCvATGPMGf9GPN2OHmdreFwUj/y6C/7entUtX67o1YqS8kqmfrONvTnF/KpHSy7sFElFpcVP6dnMXbePT1fu5s+fr2XbgQLySsrZn1fCj1WtQ26/sAMLHhzGo5d1YVfV1mtDOoZz0/nteCCp4drKiIiIiOuq1cjfSVb/nkgpcABYCXxoWda+2hZ2towxo4C7sLehG2pZ1uaqx5sDi4CrgXuAl073Xg4cdAqt/9B0/cAYooJ8GNY5kqVbD/Dyws04DCTGR+Ht6cBhYMWOQ/y8OxsPh+H7rQd5bt6RPYdfWrCZikqLPjEhxEYFEhPmT25xOVf1blXvK4lFRETEvdR22jeh6mhx8guZjn5uLPCkMeYey7Lern15Z+X/qo5/Ohz8ACzLyjDG3AmkAA8bY14+3fSvr8MXh6n/wVEPh+GSbvbWb89e24ub3lnOwHZh1a074lo0I3ljBht/yePm89uRvDGTuan78Pf2IL5FUPVU7+GmyN6eDh68qHO91y0iIiLup7bhbzhwJfAAsAz4ENiJ3eevHXbYGwy8iD3qNwKYAEw1xmywLGtpnVR9EsaY1kA/7JHHT4993rKsb4wxe4Doqjq/P9X7+ZiT74ZQX4bHRTFlXF9ijrr2a0C7UP69dCeeDsO1/dvQpWUzHvxkDT2ig3l6VE9eWbgFLw9THRZFRERETqa24a8C+D1wr2VZr5zg+ZeNMXdhT6mOsCzrFmPMEuAt4D6gXsMf0KfqmGpZVtFJzlmOHf76cJrw5+to2L5wh/26R82dLS7v2YrvthzgH1d1p3PzIDpEBPDBsl1c2r0F7SMCeH5Mr5O8k4iIiEhNtQ1/j2EHqxMFPwAsy5pijLkNeBS4xLKsd4wxjwLnn0OdZ+rwxrs7T3HOrmPOPSkv4xq96ga2DyP5oYTq+54eDmbeOcR5BYmIiIjbqu0FbQOA1DM4L7Xq3MPWAw3Rafbw6oaCU5yTX3UMqudaRERERFxObUf+vIGYMzgvBnsP4MOKgJJa/qyzcXihyVlvLWeMuR24HSAyMpKUlJQ6KEsaWn5+vr47N6bvz73p+3Nv+v4av9qGv5+BIcaYiyzLmn+iE4wxSdhTvD8c9XAbYP/ZlVgreVXHU/U3Ofxc3ometCxrGjANIC4uzkpISKiz4qThpKSkoO/Ofen7c2/6/tybvr/Gr7bTvs9XvWa2MWaqMSbBGNPeGNPOGDPMGPM6MLvq3MkAxphg7MUVy+qs6pPbUXVse4pz2hxzroiIiEiTUauRP8uyPqtavPF34Naq29EMdtuXxy3L+qzqsSjgWeCrc6z1TKyuOnYzxvidZMXvgGPOFREREWkyat3B2LKsfwIDgXeB7dg99UqxR9LeBQZblvXEUedvtizrsfru8Vf1s9KBVdjXJl577PPGmGFAa+zdP+q9HhERERFXc1bbV1iWtcqyrJsty4q1LMuv6tbRsqybLMtaUddF1tJTVcdJxpjYww8aY6KAKVV3nz7d7h4AgfnbYflb9VCiiIiIiHPU/95lDcyyrJnAa0ALYK0xZrYx5j/AZqAr8AVw0j6FNRgHfP0oHNpRT9WKiIiINKxGF/4ALMu6CxiHPQU8DLgE2ALcA4yyLKviTN6n0D8aMPDtc/VVqoiIiEiDOuWCD2PM29g98x6xLCuj6v6ZsizLuuWcqjsHlmV9AHxwLu9RaTwh/jLY+CVc/gJ4uMaOHyIiIiJn63SrfSdgh79JQEbV/TNlAU4Lf3Wm60hY+wnsWAwdRzi7GhEREZFzcrrwd1PV8Zdj7jcdsYngHQjr/6vwJyIiIm7vlOHPsqx3T3W/SfDys0Pf5vlgWWDM6V8jIiIi4qIa5YKPOhebBLl7YP9GZ1ciIiIick7OOvwZY4KNMUnGmLHGmCF1WZTLiU20j1sWOLcOERERkXNU6/BXFfreBjKBecB7HLXNmzHmLmPMXmPM4Lor08mCW0NkPKTNcXYlIiIiIuekVuHPGBMApGCv+j0EzMHez/doc7EbLF917uW5kF5jYed3kL7c2ZWIiIiInLXajvz9AeiFPdrXwbKsy489wbKsbcAmoHEtjR1wK/iHwzdPO7sSERERkbNW2/B3LbAXuM2yrMJTnLcLiD7rqlyRTyD0vRG2LoLSU310EREREddV2/DXAVhuWVbJac47AISfXUkurM0gsCrglzXOrkRERETkrNQ2/JUBvmdwXmsgv/bluLjofvZxz0rn1iEiIiJylmob/tKAPsaYkwZAY0wo9nWBa8+lMJcUGAXBMbBnhbMrERERETkrtQ1/M4Eo4FSrHv4JBAKfnG1RLi26r0b+RERExG3VNvy9AmwAfm+MWWKMebDq8XbGmDuNMQuB27FH/d6qwzpdR3RfyN4FhVnOrkRERESk1k65t++xLMsqNMZcDHwKDAHOq3pqWNXNACuBqyzLKq3LQl1G8272MXM9tLvAubWIiIiI1FKtwh+AZVl7gCHGmEuBX2OvAPYA0rGbPn9hWZZVp1W6kqiu9jFD4U9ERETcT63D32GWZc3F3s2jaQlqCb4h9sifiIiIiJup7fZuB40xn1Zd39epvopyacbYo38KfyIiIuKGarvgoxkwCnvhx0ZjzC5jzDvGmHHGmJZ1X56Lat4VMjdAI57dFhERkcaptuEvDLgS+BeQit3M+bfAv4HdxphUY8xLxpgrjTHN6rZUFxLVBUpy7VW/IiIiIm6ktqt984Avq24YY6KAxKrbCKALEA/cA1QA3nVZrMtoPdA+7vweQts6txYRERGRWqjtyF8NlmVlWpb1oWVZtwIXA88BJdgtXzzqoD7X1Lw7+IfD9m+cXYmIiIhIrZz1al9jTAT2iF9S1S3mqKdXAwvOrTQX5nBAuwth2zf2dX/GOLsiERERkTNSq/BnjLmEI2GvB0dGDrcC04BkYKFlWY1/+4sOw2D9F3BwC0Q0zYXPIiIi4n5qO/I3B7CATOy9excACyzLanorH9oPs4/bv1H4ExEREbdxNtf8GewAWHnUrekJ6wDNWttTvyIiIiJuorYjfyM5srr3emAsgDFmC/Yo4OFp3+y6LNIlGWNP/aZ9BZWV9nWAIiIiIi6uVonFsqzZlmXdb1lWD6AFcAMwHbuly53Ap8B+Y8xyY8w/67pYl9N+GBQdgoy1zq5ERERE5Iyc9XBVVZuXDyzLusWyrPZALDAZKAP6AX+qoxpdV7sL7OOuH5xbh4iIiMgZOutWL3Bck+dE7HYvh/ueNP5rAZu1Ar9Q7fMrIiIibqO2rV4CgASO9PfrdvipqmMa9nV/C4BFdVOiCzMGorrZ+/yKiIiIuIHajvxlVb3mcNjbix32krFbvuytw9rcQ1QX+PljNXsWERERt1Db8FeIPaKXDCRblrWx7ktyM1FdoCQXcnZDSBtnVyMiIiJySrUNf+GWZTX+a/lqo3nVzHfmBoU/ERERcXm1bfWi4HesyHj7mLHOuXWIiIiInAF1Jj5XfiEQ1hF2r3B2JSIiIiKnpfBXF2LOg11L7UUfIiIiIi5M4a8uxAyGoiw4sNnZlYiIiIicksJfXYgZbB93LXVuHSIiIiKnofBXF8JjwT8c0pc5uxIRERGRU1L4qwvGHLnuT0RERMSFKfzVlZjBkLUN8jKcXYmIiIjISSn81ZWY8+xj+g/OrUNERETkFBT+6kqLnuDpB7sU/kRERMR1KfzVFU9vaN0fdix2diUiIiIiJ6XwV5c6Dod9ayE/09mViIiIiJyQwl9d6phoH7cudG4dIiIiIieh8FeXWvQE/wjYssDZlYiIiIickMJfXXI4IDbRHvmrrHR2NSIiIiLHUfirax0TofAg7Fvj7EpEREREjqPwV9c6jrCPmvoVERERF6TwV9cCI+1r/7Zo0YeIiIi4HoW/+tD5Enunj4NbnV2JiIiISA0Kf/VhwG3g4QPfTHJ2JSIiIiI1KPzVh6DmMPBW+PkTyE53djUiIiIi1RT+6kv/mwELUj93diUiIiIi1RT+6ktYB2jVB1L/4+xKRERERKop/NWn7qNg72o4sNnZlYiIiIgACn/1q8cY8PCGH15zdiUiIiIigMJf/QpqDj2vg5/eh4IDzq5GREREROGv3g35PZQXw/I3nV2JiIiIiMJfvYuMg86Xwo/ToLTQ2dWIiIhIE6fw1xCG/B4KD2r0T0RERJxO4a8htD3fHv1b+ARkbnR2NSIiItKEKfw1BGPgypfBJxD+cxuUlzq7IhEREWmiFP4aSmAUXPEv2PczpPzT2dWIiIhIE6Xw15C6XA59b4QlL8LWRc6uRkRERJoghb+GdukkewXw7HuhotzZ1YiIiEgTo/DX0Lz9IfFxyN4F679wdjUiIiLSxCj8OUPnSyGiMyx6EvasdHY1IiIi0oQo/DmDwwG/fg5K8uCti2H3CmdXJCIiIk2Ewp+zdBgGd/8IQa1g5k1QnOvsikRERKQJUPhzJv8wGPUmZKdD8t+cXY2IiIg0AQp/zhYzCAbfaW/99t1LUFnh7IpERESkEfN0dgECjHjUXv07/y9QnAOJf3F2RSIiItJIaeTPFXgHwHXvQZ/xsOQF2Pm9sysSERGRRkrhz1UYA5c+DSFt4dMJkLvX2RWJiIhII6Tw50p8gmDsh1BaAG9fArvVA1BERETqlsKfq412gycAACAASURBVInqAjfOAgs7AC5/y9kViYiISCOi8OeKWveDO76F9kPhqz/C/k3OrkhEREQaCYU/V+UXCldPBS9/WPBXZ1cjIiIijYTCnysLjIQhv4e0/8H+NGdXIyIiIo2Awp+r638zeHjr2j8RERGpEwp/ri4wErpeBWs+hPz9zq5GRERE3JzCnzu44AGoKINPboDyUmdXIyIiIm5M4c8dNO8KI1+BXUsh5Z/OrkZERETcmMKfu+gxGvr+Fpa8CLtXOLsaERERcVMKf+7kkn/au4Asf9PZlYiIiIibUvhzJz6B0P0aSP0CinOdXY2IiIi4IYU/d9PnBigvgtTPnV2JiIiIuCGFP3cT3Q8i4uCn951diYiIiLghhT93Ywz0GQfpy7Tnr4iIiNSawp876vkbMB6w/A1nVyIiIiJuRuHPHQU1h34T7FW/e1Y5uxoRERFxI40q/Blj4owxDxhj5hhjthhjio0xOcaYpcaY+40x3s6usc4kPQ4BUZD8d2dXIiIiIm6kUYU/IBmYDCQAvwCfAyuB3sALwA/GmDCnVVeXfIOh7w2w/Rvt+SsiIiJnrLGFvzTgFiDSsqwLLcsaa1nWCKALkAr0wQ6BjUO3q8GqhA2znF2JiIiIuIlGFf4sy0q0LOtty7Lyj3l8B3BH1d0xjWb6N6orRHRWzz8RERE5Y40q/J3G6qqjLxDuzELqjDHQ7RrYsQTyMpxdjYiIiLiBphT+OlUdS4EsZxZSp7pdBViw/r/OrkRERETcQFMKfw9XHb+0LKvEqZXUpaguENkF1n3m7EpERETEDTSJ8GeMmQBcBxQCjzi3mnrQeyyk/wDbv3V2JSIiIuLijGVZzq4BAGPMM8CVZ/HSRMuy9pzifROBrwAv4EbLst47TR23A7cDREZG9vvkk0/OoqSG5agoYeCP91DuGcCK/pPBNIlMf0r5+fkEBgY6uww5S/r+3Ju+P/em7899DR8+fKVlWf1Pd55nQxRzhloBcWfxOq+TPWGMuQD4L+AN3Hu64AdgWdY0YBpAXFyclZCQcBYlOUHY4/Dfu0mIDYQ2A51djdOlpKTgNt+dHEffn3vT9+fe9P01fi4zRGRZ1njLssxZ3Hac6P2MMUOwR/wCgD9ZlvVyQ36eBtflCvDwhtQvnF2JiIiIuDCXCX91yRgzGJgDBAGPWpb1jJNLqn++wdAx0V71W1np7GpERETERTW68GeMGQjMA5oBf7Us60knl9Rwuo6E3N2QvszZlYiIiIiLalThzxjTD/gaO/j9w7Ksvzm5pIbV5QrwCoCfTntpo4iIiDRRrrTgoy7MB4KBbCDGGDP9JOf9wbKsAw1WVUPxCYTuV8O6z+HSp8EnyNkViYiIiItpbOEvtOoYAvz2FOf9FWh84Q+gzw2w+j3YMBt6X+/sakRERMTFNKpp33NdIdwotBkEITHa8UNEREROqFGFPwGMge6jYOsiKGicg5siIiJy9hT+GqPuo8CqgLUznV2JiIiIuBiFv8aoRQ+I7gc/TlPPPxEREalB4a+xGnQnZG2FLQucXYmIiIi4EIW/xqrrSAhsActed3YlIiIi4kIU/horT28YcCtsTYb9m5xdjYiIiLgIhb/GrP9N4OGj0T8RERGppvDXmAVEQI/RsOZDKDrk7GpERETEBSj8NXaD7oCyQlg1w9mViIiIiAtobNu7OVV5eTlZWVnk5ORQXl7u7HKqeMFls6CiFFLXgqNpfOXBwcFs2LChTt/T09OT4OBgwsLC8PRsGn+PIiLS+Og3WB2prKwkPT0dHx8fYmJi8Pb2xhjj7LJsZe3hQBp4+UFErLOraRB5eXkEBQXV2ftZlkVpaSkHDx4kPT2dtm3b4nBo4FxERNyPfnvVkUOHDuHp6UnLli3x8fFxneAH4OVrt30pzYOyYmdX45aMMfj4+NCyZUs8PT05dEjXUIqIiHtS+Ksj+fn5hISEuFboO5p/mH0synJuHW7OGENISAgFBQXOLkVEROSsKPzVkeLiYvz9/Z1dxsl5eIFPEBRmgaUt386Fv78/RUVFzi5DRETkrCj81ZHKykrXvwYsIBIqy6DggLMrcWsOh4NK7ZksIiJuysXTintx2Snfw3yagXcQ5O2DSldZjex+XP57FhEROQWFv6bEGGjWCqwKKDzo7GpERETECRT+mhpvf/AOhPz9uvZPRESkCVL4a4oCmzf4tX/GmLOaLm3Xrh3GGHbs2FH3RYmIiDRBCn9NkU+Qff1f3i9QXuLsakRERKQBKfw1RcZAcGv7zzm7wbKcW88pJCcns2HDBqKjo51dioiISKOg7d2aKk8fCGoJuXugOAf8Qpxd0Ql17NjR2SWIiIg0Khr5a8oCIsHTF3L3Nujij2nTptGnTx/8/f0JDw/nmmuuYd26dSc892TX/O3cuZOnnnqK4cOH06ZNG3x8fAgLC2P48OF88MEHJ/3ZX3/9NZdddhlRUVF4eXkRFhZGfHw8N998M6tWrarLjykiIuKSFP6assOtXypKGmzxxwMPPMCdd95JcHAwI0eOJCIigs8//5xBgwaxZMmSM36fGTNm8Mgjj5Cenk58fDxXX301Xbt2ZfHixYwbN46JEyce95rp06dzySWXMHfuXGJjYxk9ejTnn38+vr6+TJ8+na+//rouP6qIiIhL0rRvU+fTzF4AkrsXvAPsWz2aNm0aixYtYujQoQBYlsUjjzzC008/zfXXX8+mTZvw9fU97ftccsklXH311XTr1q3G45s3byYxMZHXX3+dCRMmMGjQoOrn/v73vwOwePFihgwZUuN1u3fvJjc391w/noiIiMtT+GsAf5udyvq9rhwsLCgrBOuA3QcQQ9dWzXj8im6nfWVt3XnnndXBD+wWME888QSffPIJ27Zt47PPPmPcuHGnfZ8BAwac8PFOnTrx2GOPcfvttzNz5swa4S8jI4OQkJDjgh9A69atz+LTiIiIuB+FPwEMePrZAbCsGLz86u0njR8//rjHPDw8GDt2LE8++SQpKSlnFP4AiouLmTdvHsuXL2f//v2UlNhta3755RcANm3aVOP8gQMHkpKSwo033sgDDzxA7969tVWbiIg0OQp/DaA+RtDqRf5+yN0N4bH2VHA9aN++/Qkfb9euHWBPv56JpUuXMmbMmFOef+w07pQpU7jsssuYMWMGM2bMIDg4mIEDB3LRRRdxww030KJFizP7ECIiIm5MCz7kCP9wcHhBzh57BNAJzmQkrrCwkKuvvprdu3dzyy23sGLFCrKzs6moqMCyLObNmwfY1xMerUuXLqSlpTF79mweeOAB4uLiWLRoERMnTqRjx47MnTu3Xj6TiIiIK1H4kyMcDgiOtlf/7k+rl90/TrZN2+HHW7Vqddr3+Pbbb8nIyKBfv368+eab9OvXj+DgYBwO+5/zli1bTvpaLy8vLr/8ciZPnsyyZcvIzMzkvvvuo7CwkFtuuaXWn0dERMTdKPxJTX6hEBkPWJC3r87f/v333z/usYqKCj7++GMAEhISTvseWVlZALRp0+aEz5+qz9+xQkNDefbZZ3E4HOzdu5f9+/ef8WtFRETckcKfHM/TBwIioCgL8jPrdPu3KVOm1OjnZ1kWjz/+OFu2bCE6OppRo0ad9j3i4+MBWLhwIRs3bqx+vLKykr///e989913x72msLCQyZMnnzDc/e9//6OyspJmzZoREuKaO52IiIjUFS34kBMLamFP++buAavC3gquDtx2220MGzaMoUOH0rJlS1atWkVaWhp+fn68//77+PmdfqVx3759ueKKK5g9eza9e/dm+PDhBAcHs3z5cnbt2sXEiRN55plnarymtLSUhx56iIkTJ9KjRw86deqEw+Fg69atrFixAoBJkybh5eVVJ59TRETEVWnkT07M4QlhHexp4Lx9UJhVJyOAkydP5uWXXyYrK4svvviCzMxMrrrqKpYtW8awYcPO+H1mzpzJ008/TWxsLCkpKSQnJ9OtWzeWLFnCr371q+PODwwM5LXXXmP06NEUFRUxb948Zs2aRXZ2Ntdffz0//PADd9xxxzl/PhEREVdnjl0RKUfExcVZaWlpZ3Tuhg0b6NKlSz1X5ASVFXBwi90DMLC5vR2cG8jLyyMoqH7a1UAj/r5dREpKyhld/ymuSd+fe9P3576MMSsty+p/uvM08ien5vCAiM52G5j8DCjKdnZFIiIicg4U/uT0jIHg1vbOHznpUFHu7IpERETkLCn8yZkxDghpa08D5+wCq9LZFYmIiMhZUPiTM+flZ1/zV5wDWdvtICgiIiJuReFPaicwCoLbQEmuvRBEU8AiIiJuReFPai8gAkLbQ1kRHNxkH0VERMQtKPzJ2fELgfCO9tTv/jTIy6jTnUBERESkfij8ydnzCbL3AfZtBnl7IXevsysSERGR09D2bnJuPLzsKeCc3VCQCeXF4BMI/hF2j0ARERFxKRr5k3NnDARH242gK0rtEcCDWzQNLCIi4oI08id1wzggJMb+c2EWZO+0G0L7NLOnhzUKKCIi4hIU/qTu+YVCcS4UHrRvDk8I6wDeAc6uTEREpMlT+JO6ZwyEtoXK1lBeBNnpcGALBLWw+wQa4+wKRUREmixd8yf1wxjw8LSnfCM62ce8vXBoB5QVa3s4ERERJ1H4k/rn4QXhHaq2hsuG/Rtg3zp7hXAtt4hLS0vjpZdeYvz48cTHx+NwODDGMHPmzHoqXkREpHHRtK80nMDm4B0I5SX29nAF++19gptF2497nP6f42uvvcZLL73UAMWKiIg0Thr5k4blHQD+YRDaDsJj7ccObYeMdZC13R4NLM45aZuY7t2788c//pGPP/6YLVu2MGzYsIarXUREpBHQyJ84j08QRHaBsgIoyranhK1Ke0TQPwKatQRMjTYxt956q/PqFRERaQQ08if1rqKigtDQULy8vMjLy6vx3Kwvv8T4NsOExjBn9W5o0QMCoqDwALmbl+Ll40toSDCVhYegtECNo0VERM6Rwp/UOw8PDxISEigvLyclJaXGc8nJydV/XrBggd0sulkrCG7NN2t2UF5ezvAh/XFk74ADmyBzPexPg5KaIVJERETOjMKfNIjExESgZtg7fL958+ZERUXZ4Q/sNjEBkSR/v9J+7a9GQngnCG4DXv72CuGDWyBzA5Tm268pL4XKSrWQEREROQ1d89cQ5jwM+9Y6u4raadEDfvV0nb3d4fBXHfCAjIwMUlNTGTt2LJZl8fHHH5OZmUlUVBRwJCgmXXwJ+ATat4AIO/wVHrBH/xxV/4Rz98C+NYABL398LAd4lIJ3kN1qRo2lRUREAI38SQPp0qULrVq1IjU1lX379gFHhbukJJKSkrAsq/qxjIwM1q1bR3R0NHFxcTXfzOFht40JjwVPX/sx/3AIammHQwOe5QWQvQsyU+GXn+yVxOXF9rnlJXZwrCxvkM8uIiLiSjTy1xDqcATNnSUmJjJjxgySk5MZN25cjfBnVS3kWLBgAWPHjmXhwoXVrzkjvs3s7eOqFOTmEuTnCSUFUFFi7zGcmWOPAlaUVp1l7H2IPX3B29+eUj5qZbGIiEhjpPAnDeZE4S82NpaYmBgAOnbsWD0tfHQwPCvGnv7Fy9++H9gc8jPs4BcQAZ5+dmuZokM1rxN0eAGWfQyIAA/vqsBYZvcoVDgUERE3p/AnDeZwkEtOTmbr1q3s3LmTO+64o8bzU6dOZfPmzdXhb8SIEXXzwz28ILh1zcd8m0FIjD39W1oAZUVVU8PGvp+TfsybOMDTC3ya2fsTz7zFbkrdc4wdMuN/Db7BdVOviIhIPVH4kwZz+Pq9tLQ0XnvtNaDmtG5iYiJTp05l2rRp7Nixg/j4eKKjo+u/MIenHdqODm6WZU8XV5TZo4UOL3tLuvISKDgABZmwYbY9ovi/B+3XeAVAz2vtlcnhHaFlL/s6RC02ERERF6LwJw0qMTGRtLQ0Xn31VRwOR42RvREjRmCM4ZVXXgHOYcq3LhhjXwt4eEEJ2COFYAfCgxbcs9zuSZiTDoVZsOJt+OlDOzQe1rwHtLsAsCA2CaL72dvbiYiIOInCnzSopKQkpkyZQnFxMX379iUs7EgQCg8Pp3fv3qxevRo48WKPVatWcdddd1XfX79+PQCPPPIIzz33XPXj8+fPr6+PYE8he/pCaFv7flgH+9a6P1zxLyjNsxtR71kJq/4NK6fbYXLZ64CBtudDzGAIaQNR3aBVH/DQf4oiItIw9BtHGtTw4cNxOBxUVlaecGQvKSmJ1atX43A4SEhIOO753Nxcli1bdtzjmzdvro9ya8/D015BHDPYvp13tz2FXF4M6ctg5/ew8StY8gJYFfZrorpBwp/s3ophHZxbv4iINHoKf9KgQkJCqKioOOnzzzzzDM8888xJn09ISKhuC3Mqx+4h7FTGgJcfdEiwb8Mfsa8dzM+ww+D8v8AnN4LxgMF3QsLD4BPk3JpFRKTRUvgTcQZPH3ulcUgMxF8OB9Jg5buw9BVYOxMuuB9izoMWPcGhXuwiIlJ3FP5EnM0n0F4IEt0P+oy3RwLnPmw/F9kFLngAuo/SdYEiIlInNKQg4kraDISb5sDdy2Hkq/Zjn98Ob18MB7c6tzYREWkUFP5EXI0xENnZHgW883sY9RYc2AIv94MProPNC6Cy8vTvIyIicgKaRxJxZQ4H9Bhtt4dZ8bbdNmbTKLuR9DVT7aliERGRWtDIn4g7aNYSRvwZHki1RwLLiuCti+HrR+2t6ERERM6QRv5E3Imntz0S2HEEzH8Mvn8F0uZA15HQ7Rpo0d3ZFYqIiIvTyJ+IO/IPsxeE/HaW3R9wyYswbRikPA3lpc6uTkREXJjCn4g7az8U7vkR/rjFHvlLeQreGAG7V9g7i4iIiBxD4U+kMfAPg1FvwG8+sHcOeTMRpl6o9jAiInIchT+RxiT+Mnsk8LLnIWcPTB0KH/wGMjc6uzIREXERCn8ijY1fKAy4FW5bCN2vgd0/wrQEeOfXkPqFs6sTEREnU/gTaazC2sOVL9uNontdBwX74dPfwkfjYEuyGkWLiDRRavUi0tgFtYArXrJXAS9+Hpa/ARu/hND2MPhOGHCb3UxaRESaBP0vvriNsrIykpOTeeihhxg8eDAtW7bE29ub6OhoRo8eTUpKirNLdG2e3jD8/+DBDXaj6KCWMGcizBgJWxdpdbCISBOh8Cdu45tvviEpKYnJkyezc+dO+vXrx9VXX01YWBifffYZw4cP5y9/+Yuzy3R9nj52o+ibvoLLX4RffoYZV9ktYjbP13SwiEgjp/AnbsPhcDBq1Ci+/fZbfvnlF7788ks+/vhj1q5dy0cffYSHhwf/+Mc/WLRokbNLdQ/GQP+b4KE0+9rAwgPw/mh4tgMs+CsUZjm7QhERqQcKf+I2RowYwcyZM7nwwguPe+66665jwoQJALz33nsNXJmb8/KFvjfCPSvhmjeg/TBY8gI80x5eOx+2LHB2hSIiUocU/qTeVVRUEBoaipeXF3l5eTWemzVrFsYYjDHMmTOnxnO5ubl4eXkRGhpK5RlMRfbp0weA3bt3113xTYmnN/QcA2PehVsWQNLfoLQA3hsF71+rkUARkUZC4U/qnYeHBwkJCZSXlx+3KCM5Obn6zwsW1Bxh+uabbygvL2f48OE4zmA16ubNmwFo2bLluRfd1LUZABfcD3f/CBc/CdtS7L2D5z6iXUNERNycwp80iMTERKBm2Dt8v3nz5kRFRR0X/g6fe/i1p7Jv3z6mT58OwKhRo+qgYgHs0cAh98CNs6BZa1j+JrwywN45ZOGTsHWhRgRFRNyM+vw1gEk/TmJjlnttrxUfFs+fBv6pzt7vcIA7OuBlZGSQmprK2LFjsSyLjz/+mMzMTKKiooAj4S8pKemU711eXs748ePJyckhMTGRK6644rjpZTlHbc+Dm+dA3j748Q1IXwbfPgtY4B8OV0+DTqf+nkRExDVo5E8aRJcuXWjVqhWpqans27cPqBnukpKSsCyr+rGMjAzWrVtHdHQ0cXFxp3zvO+64g+TkZNq0aaPFHvUtqAUkPgYTvrT7Bd7wOQREwfuj4OV+9m3df+yG0iIi4pI08tcA6nIEzZ0lJiYyY8YMkpOTGTduXI3wZ1U1GF6wYAFjx45l4cKF1a85lfvuu4+33nqLFi1akJycTIsWLer3Q8gRzVrat9tTYNlrsOsHyNkNM28CT1/odjXEJkHHEeAf5uxqRUSkisKfNJgThb/Y2FhiYmIA6NixY/W08JlM+T700EP861//IjIykuTkZDp16lT/H0KO5+ULFzxg/7miDDbNtfcO/vkTWPOhHQRb9YHIeBj0O4jq4tx6RUSaOE37SoM5HOSSk5PZunUrO3furBHukpKS2LVrF5s3b64OfyNGjDjhe02cOJHJkycTHh7O/Pnz6dq1a/1/ADk9Dy/ocgVc8SL8aQfcthB6Xw/Gww6CUwbDjKvtcCgiIk6hkT9pMIev30tLS+O1114Dak7rJiYmMnXqVKZNm8aOHTuIj48nOjr6uPd5+OGHefbZZwkNDWX+/Pn06tWrwT6D1IKnN0T3s28ABQdh5dv2gpH3rrGng70DodNF9qKR0PbQXCFeRKS+NfrwZ4zpDqwEvIFUy7K6O7mkJi0xMZG0tDReffVVHA5HjZG9ESNGYIzhlVdeAU485fvYY48xadIkQkJCmD9/fnVjZ3EDAeEw9I8w5F74YQosfRUcXrBh1pFzWvWByC7EHsiDvp2hWSvn1Ssi0kg16vBnjPEEpgNeTi5FqiQlJTFlyhSKi4vp27cvYWFHFgKEh4fTu3dvVq9eDRy/2GPWrFk88cQTAMTGxvLyyy+f8GfEx8dz991319MnkHPm6WNfI3jBA2BZsGspODzt9jEbZsP2b2mVtw9enAsRnSFrK7TsbU8p+4VAp4uhxxj7WkMREam1Rh3+gEeAfsCrgNKACzi8W0dlZeUJR/aSkpJYvXo1DoeDhISEGs9lZR1pJrxixQpWrFhxwp8xbNgwhT93YQy0HWL/uc1AGPJ7AH6c8zGDPVPhl58hZhDsXQ1Y9v0Ns2HW7+3A6OkH/qHQ5Up7MUlJPoS0AZ8g530mEREX12jDnzGmJ/Ao8B9gJgp/LiEkJISKioqTPv/MM8/wzDPPnPC5CRMmMGHChDP6OWry7N6K/ZpDwnXHP2FZ9q4ie1ZCWRGUF0PWdlj2Oiy1LxfAp5m96KR1f2jRE1r1hYoS8PJr2A8hIuKiGmX4M8Z4Ae8C+cBdgHpLiDQGxkBson07WvYu+OlDuwn1zu9g4//gp/ft5xxeYFXaI4x5+yBmsB0KIzvD/7d35/FVlfe+xz+/nZAEEkiYkkgYZFBA7BVwHipgaI/aOlXsOSg91WtnbXtPS9vr8bSXq6e2UntOvXW+ttaj9jgXaksno0GK2gMtToCozCgQZAhhSCDJc/74rW12dnZCiJn39/16rdfae631rL2yH/fi5/Os5/fkFcOWZbD9DcgfDqd9wbulRUR6sV4Z/OEtfpOBz4YQtpuZgj+R3qxgJEyPkqmf/Fmor4eq92DdYqhYBfV1sH4xDBzlM5CseKhx+aw8OLQPXn0Miib584VZeXDip2D4qX6MWef+TSIiHaTXBX9mNgV/1u/3IYT/6OrrEZEuEIt5S96Uq5ruq6uFAzu9ta96Dww81ruGVy2AxT/yASh1h33fX+7x5wdrqjwYzM6D3CEeEB7a7y2NEy/2LmYRkR6iVwV/ZpaFd/ceBL7QxZcjIt1RRib0L/Il0aTLfImr2QdLb4eDu6DvQH9/aJ93Mb/2hI883rfdjxlQ4s8a5hV6ayHA7g1wyv/0VkkRkW7E4nOqdjUzmw9c3IaipSGEd6Nz/CtwI/DlEMI9CeeeDjxPK/L8mdkXiALHoUOHnvz444+36iLy8/MZN25cGy5fOkJdXR0ZGRkddv533nmHysrKDjt/utu3bx95eXldfRlHlFF7gKLti8mvXE2svob+VevIqan4YH9dLIu9A8ZjoY6sQ3sIlsmBfiXUZA8hs7aK2sxcKvNPYOfgU6mP9QGLkVG7n1h9LYez8rvwL/twekr9SWqqv55rxowZfw0hHLEroju1/A0DxrehXB8AMzsZ+A5QDtzb1osIIdwH3Acwfvz4kJxupDmrV6+mf3+ll+guqqqqOrQ+cnJylGC6A5WXlzdJ9dN9Xdjwsr4O9mz0Zw4zs8hYejsD33vF5zfOPR7qa8nd9jpUvurdx7t3Mfzd30KfflBb488kVr7ro5MLJ8HZX/OUNluWezd1n34wZrq3OtZWQ16RtziGOhg9rds8l9iz6k+Sqf56v24T/IUQ5gBzPsQpLsL/niLgeWt8EyyI1qPNrDx6/bkQwjsf4vNERBqLZcCgMQ3vP/Hjlo+vq4VNL8KqhZCVCzvW+LR3A4+FZT+DX33Rj8vMgaITYV8F/OGG1OcaNsXnUH7/bSicCGOmwaaXYdc6H8CSke3T6E261IPIVQuhZKoHoVXb/PnFoRPg0AEYNxMOVXlg2U0CShFpP90m+GtHE2k+tUs/YFr0Wm3aItK1MjJh9Lm+JDvti/D+Gn89dIIHcAA71/q6Tz+o3OyDUXauhVce9sEpJ14GW1+FxfOh/zEeBNYdhrpD8P5bsGiul88rgrf/EH2YAQmPAPUb7INisvPhtM/7M4+hHiq3QO1BGHkW1Nf6OXOHegC59z1/5jF/OLG6GjiwC7a+4ml19r8PQ8crkBTpJnpN8BdCmAfMS7XvaJ75ExHpFjKzoPgjTbcPHtvwesAxvh5XCqcnjXGrrvQAMSNhdssQvCXw0H5PabNnk3crDyiBipXe5VxdCW/+xoO2ba/BktsSrikHMrLgby0nUjgzMw9W5MG+bQ0bR53jrY4b/uyfPfJM2L8DcvL9cyZf5cGjiHS4XhP8iYhIgpwUA0bMGgePg0Y3vC7+SEOweVLC7Co71nj3b5++UQJs86CxT44n0N6/A/ZXeMLsqm2wbzt7ObAyQgAAGKZJREFUl9zP4IyD8Hff99ZJi8GffwIb/+ytiasWNL22F26DM6/3APDALhhxKhSe4M9RhjpvdRxxurdAVldCzV7/zD45cHCPty4OHqvWRZFWUPAnIiLNG5piHN7Q4xtex1sfAYq9Y+X1ypKmAwbO/KoHgv2PgXee9TyKBaM8Xc7Q8fD8LbD4h0e4lomwa613N4O3Wg6dCLvXexqe7HzIL/G8i8Ometd1TZUfX3fIu7MHj/Nt2f2h7yA49hwPIEXSiII/ERHpeLGYj2YGmHBh0/3/8Ajs3ujd1NkD4I2nPEizGBw+4N3NK38Fp1zr58nK9VyK762AohO8VbBitY+2XrWwoWs6I6thqd7jLYeJ+g32QTrxY/KKvMt95zofwDP+Aph8pXeJry2Dwcf5oJyKVR5wjjjDWyH7DerQr0+kPaVF8BdCKMefaBYRke4qHhyCT9OX7Oyvte489fWwZ4MHclm5DdurK2HvVu8SP7TfWwxffdRbCOsOebC5401PozN0AuzfDb//3/DHf/EBLqlkZHnZ48/3cpnx7vEA/YbAMSd593qfXB9dDd4CmlekeaSly6RF8CciImkkFmuccicuJ7/xs5BDxsFxH2v5XO+t8ABx6AQ/dsNSb10siALVd5d7APjaYzBgGNS/H3VLmz8DufxnDecaWwrbV/pAmOwBMOos73rOyPTg8P01ns5n1FlQtdW3jTgVdrzlrYvjL4DcQh+0M+FCH4Ut0gYK/qRH+elPf8qSJUt4/fXXqaioYO/evRQUFHDSSSdx9dVXc9VVV2F64FtE2suwKb7EJQ6GSXz/d99vWra+3lsXKzf7KOcX7/C0PuO+Cdtfh83/Bdve8BbDQ/v9Wcq+A2H5zyF/hG9/7VEPLvv0g1f/s+Hcz2T66OvxF/hzi5te9i7yokl+rpKpHmzqfigpKPiTHuXWW2+loqKCE088kbPOOovc3Fw2btzIc889R1lZGU8++SRPP/10V1+miIi3QA4e68uY6TDjxtYFY/X1XjYEz82YU+BB4XsrfIBM/2Pgrd/5SOs3nobXn/AWzRDglUcazlM4ybcf3u+5GfOG+jOP/YZ4fsaavd7NffLVntx70OjG3eTSayn4kx7l0UcfZcqUKeTmNr5BrVy5ktLSUhYuXMiDDz7IrFmzuugKRUSa0dpWuFis4fjE0dYjT294PeJUX194m3cv5xUC5oNQ+vT1oHDFQz5oJacAlt0P9YdTf97S232dkQ2jz+Uju3bD8i96gHj216Fyk3dz54/w4HPgKJ9xJtZx86dLx1LwJz3KOeeck3L7pEmTuO666/je977Hn/70JwV/IpIeMrMbD5SJp62Z+hlf4qr3erBmGT7AZf8ODy77DoRX/hMKRsC21+HtP5FTXQPjpsG6cnj6c6k/N3uAtyrWVnu+xbEzvKt513pvXRw22VPxWIZ3Rfcb5C2T8TQ76o7uUgr+pMPV1dUxZMgQ9u3bx65du+jfv/8H+379619zySWXALBo0SIuuOCCD/bt3buXwYMHk5eXx86dO4nF/2+4GZmZ/p9zTo5ydomINJIzoOF1fokvcdO/0/D6/B+wrLzc8zTu3wk7Vnvy78p3Pbl33lCfTnDTS3D4oAefu9bBy3c337KYmePn2PEW1FRCVn8fzX3WVz1Bd+5QyB3cIX+2pKbgTzpcRkYG06dPZ8GCBZSXl3PRRRd9sK+srOyD188++2yj4G/x4sXU1tYyY8aMIwZ+69ev55577gFodH4REWmj3MGQG/W25OR7PkWAkpPhf3y68bE1Vf584pDjAYPNf/GBKvW1sPJpDxg/MgsKRnoL48t3w0t3AsFniima5ANXpt8AO9+B2hovm5XrrZSxTM/JmDvE10qT86Eo+JNOUVpayoIFCygrK2sS/BUVFRFC4Nlnn21UJh4YlpaWNjnfAw88wOLFizl8+DBbtmzhxRdfpL6+nhtuuIHLLruMqqqqjv2DRESkQXZ/DwrjxiXct8fOaHr8eTd6Iu78Ed5yuO01eOkO+Mu9zbcgJsodCkPGe2A44UKfCrBglHc3KzA8IgV/nWDbLbdQs/rNrr6Mo5I9cQLF//zP7Xa+eACXGOBt376dlStXMnv2bEIIPPbYY1RUVFBY6JO7x4O/mTNnNjnf0qVLefDBBz94n5mZyc0338w3vvGNdrtmERHpIIPGwMx5jbe9+hisex6O+7i3NMYyvEUxNxqlfGCnz+F8YKe3Dr7/FvQv9nmjCX6O/sfAwGN9VphhU73chiUwZQ6Mv9BHTMcyYeQZ3gqZphT8SaeYOHEiw4YNY+XKlWzbto3i4uJGwV0IgUcffZSysjJmz57N9u3beeONNygpKWH8+KZzi95///3cf//9HDx4kPXr1/PAAw8wb948Hn/8cRYtWtTouUIREekBTvr7pnkUW+Pgbg8KK1Z7jsSaKh/h/MbTHgQecxKU3eRLosJJPjd1CJDVD0ZP83PlFED+cD9PbbXPWZ3YqtkLKPjrBO3ZgtaTlZaW8tBDD1FWVsZVV13VJPgDbxmcPXs2zz333AdlWtK3b19OOOEEfvSjH1FcXMzcuXO5/vrrG7UKiohIL9Z3oC9DjoMTLm7YXl8PdTWe+qZiNWxZ7gNPMvrAmkWweVnDqOcda2D1M81/xrEf9ZlX6g5Fs7183J9rLDrRR0r3MAr+pNOkCv7GjRvHyJHe9D527NgPuoVb6vJtzjXXXMPcuXN55plnOHy4Fc+MiIhI7xWLQayvvy6c6Etc0aTGx8ZnYxkwzFv8KjdDVl6UM/Ep+NtDsPhWT10T6hrK5eTDyDN9IMoZX/HnDrNyPR/i+29513NmTpRmp/ukt1HwJ50mHsiVlZWxdu1aNm7cyJe+9KVG+++9917efvvtD4K/8847r9XnLygoIDMzk9raWnbv3s2gQYPa9w8QEZHeKT4bC3jAl1fYsO+cf/Kl9pAHce+9AqsXegvgK7/0ASvrymHFw358YoCYPcBT4hSfGOVFrIGPf9/ncbYMmPhJn7qvkwNDBX/SaeLP761Zs4a7774baNytW1payr333st9993Hhg0bmDBhAiUlJc2drokXXniB2tpaCgoKGDxYOaNERKQdZWb5evjJvgBMvtLXle/C+hdg3zZPqJ1X5M8NvvlbbwlctQD2bPZnEO9PaNRYlA+1B6HkFJj6jx5c7tvu+zKy4JRrIaP9QzUFf9KpSktLWbNmDXfeeSexWKxRy955552HmXHHHXcATbt8lyxZwqZNm5g1axbZ2Y2H8i9dupRrr70WgGuvvZaMDE07JCIinSS/BCbPbrp94id9ff4PgWiu5o0vwuhz/XnDFQ97mpx3ymDBl5qWX/2Mj0o+sNMTYo86E/oO8sBy4sX+DGJGFuze0NBy2QoK/qRTzZw5k7vuuovq6mqmTp3aqGt28ODBTJ48mRUrVgBNB3usXbuWa665huuvv56pU6dSXFxMVVUVa9euZdWqVQB84hOf4Oabb6a2trbz/igREZGWxFvviiY1PG84dLwntgYfcbxlmbf8DRrrKWreeAqev8WnzOs3yLujl97u+8CDvlDvSa/3bYdhU1p9OQr+pFPFZ+uor69POZhj5syZrFixglgs5tMLJZg2bRrf/e53WbJkCW+99RYvvvgiIQSKi4u5/PLLmTNnDpdeeimAkjyLiEjPYQYjTmu87bTP+5KoahtYDN76A2xf6UHlrvWeiuavD7T64xT8SacqKCigrq6u2f3z589n/vz5KfeNHj2am266KeU+ERGRXq9/sa+nfqbpvrO+Bv/Up1WnaXnCVBERERHp/o5iYIiCPxEREZE0ouBPREREJI0o+BMRERFJIwr+RERERNKIgj8RERGRNKLgT0RERCSNKPhrRyGErr4E6QSqZxER6ckU/LWT+KwV0vvV19cTi+mnIyIiPZP+BWsnOTk5HDhwoKsvQzrBgQMH6Nu3b1dfhoiISJso+GsneXl57NmzR12CvVwIgT179pCbm9vVlyIiItImCv7aycCBA6mtrWXr1q3U1NQoCOxlQgjU1NSwdetWamtrGThwYFdfkoiISJu0fiI4aVEsFmPEiBHs2rWLTZs2UVtb29WXlNaqq6vJyclp13NmZmaSn59PYWGhnvkTEZEeS8FfO8rMzKSwsJDCwsKuvpS0V15ezpQpU7r6MkRERLodNV+IiIiIpBEFfyIiIiJpRMGfiIiISBpR8CciIiKSRhT8iYiIiKQRBX8iIiIiaUTBn4iIiEgaUfAnIiIikkYU/ImIiIikEdMctM0zsypgTVdfh7TJEOD9rr4IaTPVX8+m+uvZVH8916gQwtAjHaTp3Vq2JoRwSldfhBw9M1uuuuu5VH89m+qvZ1P99X7q9hURERFJIwr+RERERNKIgr+W3dfVFyBtprrr2VR/PZvqr2dT/fVyGvAhIiIikkbU8iciIiKSRhT8JTGzK81siZlVmtk+M1tuZteZmb6rTmBm483s62b2sJm9aWb1ZhbMbFYryrap7szsfDP7o5ntMrMDZvaGmd1oZtnt95f1fmbWx8xKzezHZvaymW01s0Nm9q6ZPWlm049QXvXXxczsq2b2uJmtNrOdZnbYzHaY2bNmNsfMrJlysaiulkd1VxnV5exWfKbuuR3EzG6J7p/BzOa2cJx+e+kmhKAlWoA7gQAcBH4D/ArYG217Gsjo6mvs7Qvwk+j7Tl5mdUTdAd+OjqkFngWeACqibS8B/br6O+kpCzAzob62RvXwGPB6wvabVH/ddwG2AIeAvwHPAI9G32N99J0uAGJJZTKAhdH+yqi+fgtUR9v+Xwufp3tux9XlqdHvIl53c9uzDvTb69lLl19Ad1mAyxP+0TouYXsRsCra9/Wuvs7evgCfA+YDnwbGAuVHCv7aWnfAKdGNcT9wesL2PGBxVO7fu/o76SkLcB7wJPDRFPv+PvpHIgAzVH/dcwHOAXJTbJ8EbIu+02uS9n0z2r4SKErYflxCmUtSnFP33I6rx+yoPt6NgrmUwZ9+e+m7dPkFdJcFWB79B/uPKfZNS/iBxDr72tJ5aWXw16a6iwKVAHwvRbkxQB1QAxR09ffQGxbg/uj7/pnqr+ctwHej7/uXCdsygO3R9nNTlPlstO+/UuzTPbfj6urW6Pu7CPhFC8GffntpuuiZCsDMhgMn490dTyTvDyEsxv8Pqhg4o3OvTlrS1rozsyzggujtIynKrcO7LrKAC9v9wtPTimg9PL5B9dej1Ebr6oRtZwKFwJYQwgspyjwBHAZONbOS+EbdczuOmZ2Ot8b+MoTwTAvH6beXxhT8uSnRemUI4WAzxyxLOla6h7bW3XigH7ArhLD2KMpJ2x0XrbcmbFP99QBmNhr4UvQ2MaCIf7fLSCGEcADvfgSYnKKc7rntyMxygAeBXcDXj3C4fntpTHP7utHRemMLx2xKOla6h7bW3eikfa0tJ21gZsXA1dHbpxJ2qf66ITO7Bu/264O31J6FNxb8IITwq4RDW1t/k0ldf7rntq/v48HZP4QQ3j/CsfrtpTEFfy4vWu9v4Zh90bp/B1+LHJ221p3qvJOYWSbwMJAPlCV1Ran+uqez8ef14mrxZ/7+Lek41V83YWZnAf8LWBBCeKwVRVR3aUzdvi6euyp06VVIW7S17lTnneceoBTYDMxJ2qf664ZCCJ8LIRjevTcJT8E0D3jZzIYlHKr66wbMrC/wAJ6i5SutLRatVXdpSMGfq4rWeS0cE99X1cIx0vnaWneq805gZrcD1+IpP0pDCNuSDlH9dWMhhIMhhFUhhG8BNwAnAXckHKL66x5uAY4HvhFC2HqkgyOquzSmbl+3IVqPauGYEUnHSvewIVofbd3FX488ynLSSmb2Y+BrwA488Hs7xWEborXqr/t7ALgNuMjM+oQQDvPh60/33PZxGZ5377Nm9tmkfROi9ZfN7JPAOyGEz6HfXlpT8OfiKSgmmVnfZkY+nZp0rHQPba27N/GM9oPMbGwzo9ZOS1FOWsHM5gPfAHYCHwshrGrmUNVfz7EHf/YvExiE5/f7W7Tv1FQFzKwfcGL0NrEedM9tfzF8kE5zxkRLQfRev700pm5fIISwGb+JZQFXJO83s2n4iLdteP4i6SbaWnchhEPA76K3V6UoNwbPYXYIn6pKWsnMfgh8C9iNB36vNnes6q9HORcP/PYA8ZGkL+FTeg03s3NTlLkCHzG8LITwbnyj7rntK4RwbAjBUi146heAb0XbJkdl9NtLZ12dZbq7LMAsGrKZj0vYXojnqdJUQ11TL+UceYaPNtUd/n+18SmKTkvYnpfwuZqi6Ojq6+boe9sNnNzKMqq/brAAH8X/Mc9Ose9sYG30nd6WtG8uDdO7FSZsPy6q0+amd9M9t3Pq9Rc0P8OHfntpulhUYQKY2V3Al/EM9s/imelLgQH4hOazQgh1XXeFvZ+ZTQXuSth0Ap4u4G08cSkAIYQzksq1qe7M7Nv4VEh1wHN4q8Y0/Ob3F+C84Ilq5QjM7GJgYfR2OQ3JfZO9GUL4YVJZ1V8XM7Or8ef69uAtQtvw395Y/HcI3pJzRUjoIjSzDHz+2Ivw0aZleGvfTCAH+GkI4WvNfKbuuR3MzH6Bp+35VgjhthT79dtLR10dfXa3BbgSWIrfxPYDfwWuQ/NLdtb3Px3/v8YWl/asO+B84E94a9VBPGi5kRQtIFpa/B6vbk3dAeWqv+634Al5bwKex9PyHMQDgg34XK6XtlA2Blwf1dn+qA7/DFzZis/VPbdj6/UXNNPy92HrQL+9nruo5U9EREQkjWjAh4iIiEgaUfAnIiIikkYU/ImIiIikEQV/IiIiImlEwZ+IiIhIGlHwJyIiIpJGFPyJiIiIpBEFfyIiPZyZbTCzYGbHdvW1iEj3p+BPREREJI0o+BMRERFJIwr+RERERNKIgj8RSUtmlmtm3zazZWa218wOmtlKM5tnZnlJx86LnqmbZ2ajzexhM9tuZtVRmW+aWWYzn2Nm9hkzKzez3VGZtWZ2p5mNOML1zTWzl8xsT3R968zsCTO7sIVyHzOzMjOrNLMDZvaymV3c9m9KRHobCyF09TWIiHQqMxsO/AE4AdgBrACqgVOBY4DXgOkhhN3R8fOA/wP8B/DJ6Ng/AwOAGUA2sAC4PIRQn/A5BjwMXAkcBsqBXcBpwOjo9fkhhGVJ1zcqur7xwL7osyqBEcBJwPIQwvSE4zcAo4B/BW4ElgHrovJTgAB8OoTwZJu/NBHpNRT8iUhaiQKypcCZwB3Ad0IIB6J9fYH7gDnAgyGEq6Pt8/DgD+ApYE4IoTradxzwPFACXBdCuCvhs74C3AlsB0pDCCuj7RnAvwNfBTYC40MINdG+GLAcD9oWAtfEg9Bof3/gtBBCWcK2DXjwdwi4JITw+4R9/wLcDLwTQjjuQ3x1ItJLKPgTkbRiZhcAi4CXgbMTW+qi/bl4q9kgoDCEsDsh+DsIHBtCqEgqcw3wc5ICLDNbC4wBvhBC+P9JZbKAd/DWvDkhhEei7ZcCvwI2ACeEEA624m/agAd/Pw4hzE3xORVAPjAqhLDpSOcTkd5Nz/yJSLqJPy/3VHLgBxBC2I+3vGXi3cCJ/pgc+EUeAeqBcWZWAh90LY+Jtj+U4nMOReUApifsOj9+ztYEfkl+08znrIveDjvK84lIL6TgT0TSzZho/aNoEEeThYYAcWhS2fWpThgFWFujt8OjdUm03hrvIk5hbdKx4C14AG8e6Q9JoblWvb3ROqcN5xSRXibl6DQRkV4sI1ovxrtWW7KxDeePP0tjSe9TsRb2tUWTlkwRkWQK/kQk3WyO1k+EEO48yrLHptoYPVd3TPT2vWi9JVoPM7Ps+ICOJKOj9bsJ2+IB5/ijvDYRkVZRt6+IpJvfResr2lD242aW3BUMMBu/n64NIWwBiNbrou1zkguYWR88BQx4Cpi4P0TrOWambloRaXcK/kQk3SwA/gpMM7N7zGxQ8gFmNsbMrktRth9wh5llJxw7Fk+lAnB70vH/Fq1vNrMJCWUygPn4830bgcT8ewuBV/BWxkfMLD/p2vqbWekR/0oRkWao21dE0koIoT5Kp7II+CJwpZm9infTDgFGAsfjufmSu4UfAj4BrDWzpUAecB4+kOKZFMffBZyNtwy+ambPA7vxJM9jotdXJHYJR9f3KeCPwKeAj5lZYpLnyfho5DJERNpAwZ+IpJ0QwhYzOw24Fvg08BHgdGAn/vzdbXiuvWTr8PQvt+BBX3607efAT5JTx4QQgpldhXc1fx44A+iLPxd4N/CDEMJmkoQQ1pvZVDwJ9OXAR/GBKtvwdC4PfJi/X0TSm5I8i4gcQUKS5/8bQpjXtVcjIvLh6Jk/ERERkTSi4E9EREQkjSj4ExEREUkjeuZPREREJI2o5U9EREQkjSj4ExEREUkjCv5ERERE0oiCPxEREZE0ouBPREREJI0o+BMRERFJI/8Nlnlx4yRcIp8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CYT_w.plot(figsize=(10,10), grid=True)\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.title('Weights change')\n",
    "plt.ylabel('weights')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.plot(history.cyt_tr_hist)\n",
    "plt.plot(history.cyt_te_hist)\n",
    "#plt.ylim((1,1.20))\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dummy variable for \"class\"\n",
    "protein['y'] = LE.fit_transform(protein['class'])\n",
    "# X = protein.as_matrix(columns=protein.columns[1:-1])\n",
    "X = protein.iloc[:,1:-2].values\n",
    "y = protein.iloc[:,-1].values\n",
    "y_class = onehotencoder.fit_transform(np.array([y]).T).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all = Sequential()\n",
    "model_all.add(Dense(3, input_dim= X_tr.shape[1], kernel_initializer='random_uniform',\n",
    "                bias_initializer='random_uniform',activation='sigmoid'))\n",
    "model_all.add(Dense(3, activation = \"sigmoid\"))\n",
    "model_all.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 126/1484 [=>............................] - ETA: 1s - loss: 1.0488 - acc: 0.6270     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1484/1484 [==============================] - 1s 793us/step - loss: 1.1007 - acc: 0.5620 0s - loss: 1.1120 - acc: 0\n",
      "Epoch 2/200\n",
      "1484/1484 [==============================] - 1s 754us/step - loss: 1.0990 - acc: 0.5687\n",
      "Epoch 3/200\n",
      "1484/1484 [==============================] - 1s 702us/step - loss: 1.0996 - acc: 0.5708\n",
      "Epoch 4/200\n",
      "1484/1484 [==============================] - 1s 708us/step - loss: 1.1009 - acc: 0.5627\n",
      "Epoch 5/200\n",
      "1484/1484 [==============================] - 1s 717us/step - loss: 1.0969 - acc: 0.5606\n",
      "Epoch 6/200\n",
      "1484/1484 [==============================] - 1s 705us/step - loss: 1.0982 - acc: 0.5620 0s - loss: 1.0860\n",
      "Epoch 7/200\n",
      "1484/1484 [==============================] - 1s 703us/step - loss: 1.1003 - acc: 0.5694 0s - loss: 1.1098 - acc\n",
      "Epoch 8/200\n",
      "1484/1484 [==============================] - 1s 706us/step - loss: 1.1009 - acc: 0.5600 0s - loss: 1.1398 - - ETA: 0s - loss: 1.1141 - acc: 0.\n",
      "Epoch 9/200\n",
      "1484/1484 [==============================] - 1s 706us/step - loss: 1.0987 - acc: 0.5728\n",
      "Epoch 10/200\n",
      "1484/1484 [==============================] - 1s 704us/step - loss: 1.0959 - acc: 0.5620\n",
      "Epoch 11/200\n",
      "1484/1484 [==============================] - 1s 715us/step - loss: 1.0996 - acc: 0.5748\n",
      "Epoch 12/200\n",
      "1484/1484 [==============================] - 1s 704us/step - loss: 1.0976 - acc: 0.5586\n",
      "Epoch 13/200\n",
      "1484/1484 [==============================] - 1s 696us/step - loss: 1.0982 - acc: 0.5620\n",
      "Epoch 14/200\n",
      "1484/1484 [==============================] - 1s 713us/step - loss: 1.0980 - acc: 0.5627 0s - loss: 1.1501 - a\n",
      "Epoch 15/200\n",
      "1484/1484 [==============================] - 1s 697us/step - loss: 1.0952 - acc: 0.5721\n",
      "Epoch 16/200\n",
      "1484/1484 [==============================] - 1s 702us/step - loss: 1.0961 - acc: 0.5714\n",
      "Epoch 17/200\n",
      "1484/1484 [==============================] - 1s 696us/step - loss: 1.0981 - acc: 0.5667\n",
      "Epoch 18/200\n",
      "1484/1484 [==============================] - 1s 698us/step - loss: 1.0983 - acc: 0.5681\n",
      "Epoch 19/200\n",
      "1484/1484 [==============================] - 1s 698us/step - loss: 1.0993 - acc: 0.5613\n",
      "Epoch 20/200\n",
      "1484/1484 [==============================] - 1s 692us/step - loss: 1.0968 - acc: 0.5761\n",
      "Epoch 21/200\n",
      "1484/1484 [==============================] - 1s 694us/step - loss: 1.0958 - acc: 0.5660\n",
      "Epoch 22/200\n",
      "1484/1484 [==============================] - 1s 699us/step - loss: 1.0944 - acc: 0.5728\n",
      "Epoch 23/200\n",
      "1484/1484 [==============================] - 1s 700us/step - loss: 1.0914 - acc: 0.5741\n",
      "Epoch 24/200\n",
      "1484/1484 [==============================] - 1s 704us/step - loss: 1.0939 - acc: 0.5701 0s - loss: 1.0978 - acc: 0.56\n",
      "Epoch 25/200\n",
      "1484/1484 [==============================] - 1s 723us/step - loss: 1.0962 - acc: 0.5741 0s - loss: 1.1026 - acc: 0.57\n",
      "Epoch 26/200\n",
      "1484/1484 [==============================] - 1s 715us/step - loss: 1.0982 - acc: 0.5687\n",
      "Epoch 27/200\n",
      "1484/1484 [==============================] - 1s 742us/step - loss: 1.0971 - acc: 0.5856 0s - loss: 1.0947 - acc: 0.5\n",
      "Epoch 28/200\n",
      "1484/1484 [==============================] - 1s 735us/step - loss: 1.0970 - acc: 0.5640\n",
      "Epoch 29/200\n",
      "1484/1484 [==============================] - 1s 742us/step - loss: 1.0957 - acc: 0.5761\n",
      "Epoch 30/200\n",
      "1484/1484 [==============================] - 1s 700us/step - loss: 1.0987 - acc: 0.5674\n",
      "Epoch 31/200\n",
      "1484/1484 [==============================] - 1s 700us/step - loss: 1.0944 - acc: 0.5708\n",
      "Epoch 32/200\n",
      "1484/1484 [==============================] - 1s 705us/step - loss: 1.0949 - acc: 0.5681\n",
      "Epoch 33/200\n",
      "1484/1484 [==============================] - 1s 809us/step - loss: 1.0954 - acc: 0.5694\n",
      "Epoch 34/200\n",
      "1484/1484 [==============================] - 1s 783us/step - loss: 1.0954 - acc: 0.5701\n",
      "Epoch 35/200\n",
      "1484/1484 [==============================] - 1s 986us/step - loss: 1.0936 - acc: 0.5768\n",
      "Epoch 36/200\n",
      "1484/1484 [==============================] - 1s 949us/step - loss: 1.0958 - acc: 0.5627 1s - loss: 1.095 - ETA: 0s - loss: 1.0854 - acc: 0.56\n",
      "Epoch 37/200\n",
      "1484/1484 [==============================] - 1s 870us/step - loss: 1.0956 - acc: 0.5761\n",
      "Epoch 38/200\n",
      "1484/1484 [==============================] - 1s 733us/step - loss: 1.0981 - acc: 0.5627\n",
      "Epoch 39/200\n",
      "1484/1484 [==============================] - 1s 719us/step - loss: 1.0956 - acc: 0.5580 0s - loss: 1.08\n",
      "Epoch 40/200\n",
      "1484/1484 [==============================] - 1s 776us/step - loss: 1.0962 - acc: 0.5660\n",
      "Epoch 41/200\n",
      "1484/1484 [==============================] - 1s 756us/step - loss: 1.0984 - acc: 0.5701\n",
      "Epoch 42/200\n",
      "1484/1484 [==============================] - 1s 720us/step - loss: 1.0944 - acc: 0.5782\n",
      "Epoch 43/200\n",
      "1484/1484 [==============================] - 1s 722us/step - loss: 1.0946 - acc: 0.5714\n",
      "Epoch 44/200\n",
      "1484/1484 [==============================] - 1s 705us/step - loss: 1.0955 - acc: 0.5714\n",
      "Epoch 45/200\n",
      "1484/1484 [==============================] - 1s 714us/step - loss: 1.0942 - acc: 0.5606\n",
      "Epoch 46/200\n",
      "1484/1484 [==============================] - 1s 758us/step - loss: 1.0955 - acc: 0.5654\n",
      "Epoch 47/200\n",
      "1484/1484 [==============================] - 1s 776us/step - loss: 1.0953 - acc: 0.5694\n",
      "Epoch 48/200\n",
      "1484/1484 [==============================] - 1s 683us/step - loss: 1.0975 - acc: 0.5586\n",
      "Epoch 49/200\n",
      "1484/1484 [==============================] - 1s 684us/step - loss: 1.0923 - acc: 0.5755\n",
      "Epoch 50/200\n",
      "1484/1484 [==============================] - 1s 778us/step - loss: 1.0945 - acc: 0.5728\n",
      "Epoch 51/200\n",
      "1484/1484 [==============================] - 1s 722us/step - loss: 1.0964 - acc: 0.5654\n",
      "Epoch 52/200\n",
      "1484/1484 [==============================] - 1s 699us/step - loss: 1.0942 - acc: 0.5849 0s - loss: 1.1220 \n",
      "Epoch 53/200\n",
      "1484/1484 [==============================] - 1s 676us/step - loss: 1.0990 - acc: 0.5708\n",
      "Epoch 54/200\n",
      "1484/1484 [==============================] - 1s 675us/step - loss: 1.0933 - acc: 0.5708 0s - loss: 1.1018 - acc:\n",
      "Epoch 55/200\n",
      "1484/1484 [==============================] - 1s 710us/step - loss: 1.0932 - acc: 0.5721\n",
      "Epoch 56/200\n",
      "1484/1484 [==============================] - 1s 690us/step - loss: 1.0972 - acc: 0.5721 0s - loss: 1.09\n",
      "Epoch 57/200\n",
      "1484/1484 [==============================] - 1s 674us/step - loss: 1.0942 - acc: 0.5566\n",
      "Epoch 58/200\n",
      "1484/1484 [==============================] - 1s 773us/step - loss: 1.0891 - acc: 0.5849\n",
      "Epoch 59/200\n",
      "1484/1484 [==============================] - 2s 1ms/step - loss: 1.0944 - acc: 0.5573\n",
      "Epoch 60/200\n",
      "1484/1484 [==============================] - 2s 1ms/step - loss: 1.0948 - acc: 0.5586A: 0s - loss: 1.117\n",
      "Epoch 61/200\n",
      "1484/1484 [==============================] - 2s 1ms/step - loss: 1.0937 - acc: 0.5694\n",
      "Epoch 62/200\n",
      "1484/1484 [==============================] - 2s 2ms/step - loss: 1.0930 - acc: 0.5647A: 0s - loss: 1.0883 - acc\n",
      "Epoch 63/200\n",
      "1484/1484 [==============================] - 1s 815us/step - loss: 1.0922 - acc: 0.5681\n",
      "Epoch 64/200\n",
      "1484/1484 [==============================] - 1s 870us/step - loss: 1.0926 - acc: 0.5633 1s - loss: \n",
      "Epoch 65/200\n",
      "1484/1484 [==============================] - 1s 778us/step - loss: 1.0933 - acc: 0.5667\n",
      "Epoch 66/200\n",
      "1484/1484 [==============================] - 1s 688us/step - loss: 1.0918 - acc: 0.5694\n",
      "Epoch 67/200\n",
      "1484/1484 [==============================] - 1s 708us/step - loss: 1.0922 - acc: 0.5721\n",
      "Epoch 68/200\n",
      "1484/1484 [==============================] - 1s 689us/step - loss: 1.0943 - acc: 0.5681\n",
      "Epoch 69/200\n",
      "1484/1484 [==============================] - 1s 724us/step - loss: 1.0954 - acc: 0.5647 0s - loss: 1.0926 - acc: 0.5\n",
      "Epoch 70/200\n",
      "1484/1484 [==============================] - 1s 675us/step - loss: 1.0940 - acc: 0.5647 0s - loss: 1.1056 - acc: 0.56\n",
      "Epoch 71/200\n",
      "1484/1484 [==============================] - 1s 676us/step - loss: 1.0896 - acc: 0.5728\n",
      "Epoch 72/200\n",
      "1484/1484 [==============================] - 1s 668us/step - loss: 1.0902 - acc: 0.5613\n",
      "Epoch 73/200\n",
      "1484/1484 [==============================] - 1s 696us/step - loss: 1.0935 - acc: 0.5674 0s - loss: 1.145\n",
      "Epoch 74/200\n",
      "1484/1484 [==============================] - 1s 687us/step - loss: 1.0922 - acc: 0.5573\n",
      "Epoch 75/200\n",
      "1484/1484 [==============================] - 1s 696us/step - loss: 1.0929 - acc: 0.5613 0s - loss: 1.0714 - \n",
      "Epoch 76/200\n",
      "1484/1484 [==============================] - 1s 663us/step - loss: 1.0946 - acc: 0.5654\n",
      "Epoch 77/200\n",
      "1484/1484 [==============================] - 1s 680us/step - loss: 1.0943 - acc: 0.5728\n",
      "Epoch 78/200\n",
      "1484/1484 [==============================] - 1s 680us/step - loss: 1.0944 - acc: 0.5714\n",
      "Epoch 79/200\n",
      "1484/1484 [==============================] - 1s 671us/step - loss: 1.0918 - acc: 0.5728\n",
      "Epoch 80/200\n",
      "1484/1484 [==============================] - 1s 729us/step - loss: 1.0918 - acc: 0.5694\n",
      "Epoch 81/200\n",
      "1484/1484 [==============================] - 1s 819us/step - loss: 1.0931 - acc: 0.5654\n",
      "Epoch 82/200\n",
      "1484/1484 [==============================] - 2s 1ms/step - loss: 1.0918 - acc: 0.5701\n",
      "Epoch 83/200\n",
      "1484/1484 [==============================] - 1s 991us/step - loss: 1.0939 - acc: 0.5755 0s - loss: 1.0929 - acc: - ETA: 0s - loss: 1.0930 - acc: 0.578 - ETA: 0s - loss: 1.0935 - acc: 0.575\n",
      "Epoch 84/200\n",
      "1484/1484 [==============================] - 2s 1ms/step - loss: 1.0947 - acc: 0.5654\n",
      "Epoch 85/200\n",
      "1484/1484 [==============================] - 2s 1ms/step - loss: 1.0941 - acc: 0.5701A: 0s - loss: 1.0991 - acc: 0. - ETA: 0s - loss: 1.0940 - acc: 0.571\n",
      "Epoch 86/200\n",
      "1484/1484 [==============================] - 1s 845us/step - loss: 1.0930 - acc: 0.5546 0s - loss: 1.0685 - acc: 0.581 - ETA: 0s - loss: 1.0892 - \n",
      "Epoch 87/200\n",
      "1484/1484 [==============================] - 1s 705us/step - loss: 1.0925 - acc: 0.5741 0s - loss: 1.1426 -\n",
      "Epoch 88/200\n",
      "1484/1484 [==============================] - 1s 681us/step - loss: 1.0925 - acc: 0.5681\n",
      "Epoch 89/200\n",
      "1484/1484 [==============================] - 1s 712us/step - loss: 1.0936 - acc: 0.5681\n",
      "Epoch 90/200\n",
      "1484/1484 [==============================] - 1s 700us/step - loss: 1.0909 - acc: 0.5735\n",
      "Epoch 91/200\n",
      "1484/1484 [==============================] - 1s 675us/step - loss: 1.0912 - acc: 0.5721\n",
      "Epoch 92/200\n",
      "1484/1484 [==============================] - 1s 675us/step - loss: 1.0965 - acc: 0.5741\n",
      "Epoch 93/200\n",
      "1484/1484 [==============================] - 1s 680us/step - loss: 1.0910 - acc: 0.5593\n",
      "Epoch 94/200\n",
      "1484/1484 [==============================] - 1s 688us/step - loss: 1.0890 - acc: 0.5613\n",
      "Epoch 95/200\n",
      "1484/1484 [==============================] - 1s 669us/step - loss: 1.0932 - acc: 0.5654 0s - loss: 1.1014 - acc: 0.56\n",
      "Epoch 96/200\n",
      "1484/1484 [==============================] - 1s 678us/step - loss: 1.0943 - acc: 0.5748 0s - loss: 1.1019 - acc: 0.57\n",
      "Epoch 97/200\n",
      "1484/1484 [==============================] - 1s 671us/step - loss: 1.0885 - acc: 0.5735\n",
      "Epoch 98/200\n",
      "1484/1484 [==============================] - 1s 712us/step - loss: 1.0890 - acc: 0.5755\n",
      "Epoch 99/200\n",
      "1484/1484 [==============================] - 1s 676us/step - loss: 1.0941 - acc: 0.5633\n",
      "Epoch 100/200\n",
      "1484/1484 [==============================] - 1s 660us/step - loss: 1.0916 - acc: 0.5667 0s - loss: 1.0736 - acc:\n",
      "Epoch 101/200\n",
      "1484/1484 [==============================] - 1s 663us/step - loss: 1.0886 - acc: 0.5708\n",
      "Epoch 102/200\n",
      "1484/1484 [==============================] - 1s 667us/step - loss: 1.0916 - acc: 0.5654\n",
      "Epoch 103/200\n",
      "1484/1484 [==============================] - 1s 687us/step - loss: 1.0913 - acc: 0.5620 0s - loss: 1.0830\n",
      "Epoch 104/200\n",
      "1484/1484 [==============================] - 1s 676us/step - loss: 1.0895 - acc: 0.5654\n",
      "Epoch 105/200\n",
      "1484/1484 [==============================] - 1s 679us/step - loss: 1.0883 - acc: 0.5593\n",
      "Epoch 106/200\n",
      "1484/1484 [==============================] - 1s 690us/step - loss: 1.0904 - acc: 0.5620\n",
      "Epoch 107/200\n",
      "1484/1484 [==============================] - 1s 693us/step - loss: 1.0870 - acc: 0.5674\n",
      "Epoch 108/200\n",
      "1484/1484 [==============================] - 1s 803us/step - loss: 1.0897 - acc: 0.5708\n",
      "Epoch 109/200\n",
      "1484/1484 [==============================] - 1s 723us/step - loss: 1.0885 - acc: 0.5728\n",
      "Epoch 110/200\n",
      "1484/1484 [==============================] - 1s 680us/step - loss: 1.0907 - acc: 0.5735\n",
      "Epoch 111/200\n",
      "1484/1484 [==============================] - 1s 674us/step - loss: 1.0900 - acc: 0.5708\n",
      "Epoch 112/200\n",
      "1484/1484 [==============================] - 1s 710us/step - loss: 1.0877 - acc: 0.5741 0s - loss: 1.0919 - acc: 0.570\n",
      "Epoch 113/200\n",
      "1484/1484 [==============================] - 1s 732us/step - loss: 1.0903 - acc: 0.5687\n",
      "Epoch 114/200\n",
      "1484/1484 [==============================] - 1s 667us/step - loss: 1.0902 - acc: 0.5728\n",
      "Epoch 115/200\n",
      "1484/1484 [==============================] - 1s 670us/step - loss: 1.0864 - acc: 0.5714 0s - loss: 1.0661 - \n",
      "Epoch 116/200\n",
      "1484/1484 [==============================] - 1s 677us/step - loss: 1.0923 - acc: 0.5586\n",
      "Epoch 117/200\n",
      "1484/1484 [==============================] - 1s 670us/step - loss: 1.0868 - acc: 0.5714\n",
      "Epoch 118/200\n",
      "1484/1484 [==============================] - 1s 671us/step - loss: 1.0878 - acc: 0.5667\n",
      "Epoch 119/200\n",
      "1484/1484 [==============================] - 1s 669us/step - loss: 1.0897 - acc: 0.5660\n",
      "Epoch 120/200\n",
      "1484/1484 [==============================] - 1s 672us/step - loss: 1.0914 - acc: 0.5708\n",
      "Epoch 121/200\n",
      "1484/1484 [==============================] - 1s 721us/step - loss: 1.0920 - acc: 0.5573\n",
      "Epoch 122/200\n",
      "1484/1484 [==============================] - 1s 673us/step - loss: 1.0893 - acc: 0.5674\n",
      "Epoch 123/200\n",
      "1484/1484 [==============================] - 1s 669us/step - loss: 1.0922 - acc: 0.5633\n",
      "Epoch 124/200\n",
      "1484/1484 [==============================] - 1s 667us/step - loss: 1.0897 - acc: 0.5721\n",
      "Epoch 125/200\n",
      "1484/1484 [==============================] - 1s 663us/step - loss: 1.0921 - acc: 0.5694\n",
      "Epoch 126/200\n",
      "1484/1484 [==============================] - 1s 668us/step - loss: 1.0903 - acc: 0.5694\n",
      "Epoch 127/200\n",
      "1484/1484 [==============================] - 1s 674us/step - loss: 1.0876 - acc: 0.5748\n",
      "Epoch 128/200\n",
      "1484/1484 [==============================] - 1s 669us/step - loss: 1.0874 - acc: 0.5735 0s - loss: 1.0866 - acc: 0.5\n",
      "Epoch 129/200\n",
      "1484/1484 [==============================] - 1s 667us/step - loss: 1.0875 - acc: 0.5620\n",
      "Epoch 130/200\n",
      "1484/1484 [==============================] - 1s 673us/step - loss: 1.0912 - acc: 0.5761\n",
      "Epoch 131/200\n",
      "1484/1484 [==============================] - 1s 692us/step - loss: 1.0894 - acc: 0.5633 0s - loss: 1.1020 - acc: 0.5\n",
      "Epoch 132/200\n",
      "1484/1484 [==============================] - 1s 680us/step - loss: 1.0925 - acc: 0.5667\n",
      "Epoch 133/200\n",
      "1484/1484 [==============================] - 1s 666us/step - loss: 1.0882 - acc: 0.5674\n",
      "Epoch 134/200\n",
      "1484/1484 [==============================] - 1s 669us/step - loss: 1.0870 - acc: 0.5633\n",
      "Epoch 135/200\n",
      "1484/1484 [==============================] - 1s 670us/step - loss: 1.0886 - acc: 0.5836\n",
      "Epoch 136/200\n",
      "1484/1484 [==============================] - 1s 657us/step - loss: 1.0876 - acc: 0.5755\n",
      "Epoch 137/200\n",
      "1484/1484 [==============================] - 1s 665us/step - loss: 1.0869 - acc: 0.5674\n",
      "Epoch 138/200\n",
      "1484/1484 [==============================] - 1s 711us/step - loss: 1.0907 - acc: 0.5735 0s - loss: 1.1199 - acc: \n",
      "Epoch 139/200\n",
      "1484/1484 [==============================] - 1s 968us/step - loss: 1.0881 - acc: 0.5667\n",
      "Epoch 140/200\n",
      "1484/1484 [==============================] - 1s 836us/step - loss: 1.0877 - acc: 0.5741\n",
      "Epoch 141/200\n",
      "1484/1484 [==============================] - 1s 771us/step - loss: 1.0887 - acc: 0.5613\n",
      "Epoch 142/200\n",
      "1484/1484 [==============================] - 1s 800us/step - loss: 1.0911 - acc: 0.5647\n",
      "Epoch 143/200\n",
      "1484/1484 [==============================] - 1s 877us/step - loss: 1.0898 - acc: 0.5701 0s - loss: \n",
      "Epoch 144/200\n",
      "1484/1484 [==============================] - 1s 731us/step - loss: 1.0853 - acc: 0.5735 0s - loss: 1.0741 -  - ETA: 0s - loss: 1.0521 - acc: 0.5\n",
      "Epoch 145/200\n",
      "1484/1484 [==============================] - 1s 734us/step - loss: 1.0878 - acc: 0.5654\n",
      "Epoch 146/200\n",
      "1484/1484 [==============================] - 1s 789us/step - loss: 1.0889 - acc: 0.5721\n",
      "Epoch 147/200\n",
      "1484/1484 [==============================] - 1s 889us/step - loss: 1.0859 - acc: 0.5708\n",
      "Epoch 148/200\n",
      "1484/1484 [==============================] - 1s 797us/step - loss: 1.0904 - acc: 0.5735\n",
      "Epoch 149/200\n",
      "1484/1484 [==============================] - 1s 680us/step - loss: 1.0887 - acc: 0.5761\n",
      "Epoch 150/200\n",
      "1484/1484 [==============================] - 1s 702us/step - loss: 1.0851 - acc: 0.5573\n",
      "Epoch 151/200\n",
      "1484/1484 [==============================] - 1s 722us/step - loss: 1.0907 - acc: 0.5606\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1484/1484 [==============================] - 1s 790us/step - loss: 1.0871 - acc: 0.5741\n",
      "Epoch 153/200\n",
      "1484/1484 [==============================] - 1s 763us/step - loss: 1.0885 - acc: 0.5694\n",
      "Epoch 154/200\n",
      "1484/1484 [==============================] - 1s 891us/step - loss: 1.0882 - acc: 0.5566\n",
      "Epoch 155/200\n",
      "1484/1484 [==============================] - 1s 933us/step - loss: 1.0878 - acc: 0.5566\n",
      "Epoch 156/200\n",
      "1484/1484 [==============================] - 1s 692us/step - loss: 1.0856 - acc: 0.5721\n",
      "Epoch 157/200\n",
      "1484/1484 [==============================] - 1s 734us/step - loss: 1.0858 - acc: 0.5708\n",
      "Epoch 158/200\n",
      "1484/1484 [==============================] - 1s 947us/step - loss: 1.0857 - acc: 0.5681\n",
      "Epoch 159/200\n",
      "1484/1484 [==============================] - 1s 912us/step - loss: 1.0912 - acc: 0.5694 0s - loss: 1.0910 - acc:\n",
      "Epoch 160/200\n",
      "1484/1484 [==============================] - 1s 809us/step - loss: 1.0909 - acc: 0.5613 0s - loss: 1.1163 -\n",
      "Epoch 161/200\n",
      "1484/1484 [==============================] - 1s 827us/step - loss: 1.0895 - acc: 0.5627\n",
      "Epoch 162/200\n",
      "1484/1484 [==============================] - 1s 865us/step - loss: 1.0868 - acc: 0.5721 1s - loss: 1.0841 - - ETA: 0s - loss: 1.0892 - acc: \n",
      "Epoch 163/200\n",
      "1484/1484 [==============================] - 1s 778us/step - loss: 1.0863 - acc: 0.5647A: 0s - loss: 1\n",
      "Epoch 164/200\n",
      "1484/1484 [==============================] - 1s 783us/step - loss: 1.0830 - acc: 0.5714\n",
      "Epoch 165/200\n",
      "1484/1484 [==============================] - 1s 731us/step - loss: 1.0894 - acc: 0.5728 0s - loss: 1.0872 - acc: 0.\n",
      "Epoch 166/200\n",
      "1484/1484 [==============================] - 1s 792us/step - loss: 1.0836 - acc: 0.5620\n",
      "Epoch 167/200\n",
      "1484/1484 [==============================] - 1s 713us/step - loss: 1.0853 - acc: 0.5748\n",
      "Epoch 168/200\n",
      "1484/1484 [==============================] - 1s 782us/step - loss: 1.0888 - acc: 0.5694\n",
      "Epoch 169/200\n",
      "1484/1484 [==============================] - 1s 802us/step - loss: 1.0868 - acc: 0.5681\n",
      "Epoch 170/200\n",
      "1484/1484 [==============================] - 1s 943us/step - loss: 1.0889 - acc: 0.5681\n",
      "Epoch 171/200\n",
      "1484/1484 [==============================] - 1s 771us/step - loss: 1.0853 - acc: 0.5647\n",
      "Epoch 172/200\n",
      "1484/1484 [==============================] - 1s 717us/step - loss: 1.0872 - acc: 0.5660\n",
      "Epoch 173/200\n",
      "1484/1484 [==============================] - 1s 780us/step - loss: 1.0899 - acc: 0.5701\n",
      "Epoch 174/200\n",
      "1484/1484 [==============================] - 1s 906us/step - loss: 1.0887 - acc: 0.5633\n",
      "Epoch 175/200\n",
      "1484/1484 [==============================] - 1s 936us/step - loss: 1.0859 - acc: 0.5741\n",
      "Epoch 176/200\n",
      "1484/1484 [==============================] - 1s 714us/step - loss: 1.0858 - acc: 0.5708\n",
      "Epoch 177/200\n",
      "1484/1484 [==============================] - 1s 690us/step - loss: 1.0851 - acc: 0.5728\n",
      "Epoch 178/200\n",
      "1484/1484 [==============================] - 1s 721us/step - loss: 1.0872 - acc: 0.5708 0s - loss: 1.0971 - acc: 0.5\n",
      "Epoch 179/200\n",
      "1484/1484 [==============================] - 1s 807us/step - loss: 1.0847 - acc: 0.5687\n",
      "Epoch 180/200\n",
      "1484/1484 [==============================] - 1s 730us/step - loss: 1.0850 - acc: 0.5714 0s - loss: 1.0716 - ETA: 0s - loss: 1.0880 - acc: 0.571\n",
      "Epoch 181/200\n",
      "1484/1484 [==============================] - 1s 741us/step - loss: 1.0859 - acc: 0.5694\n",
      "Epoch 182/200\n",
      "1484/1484 [==============================] - 1s 766us/step - loss: 1.0910 - acc: 0.5687\n",
      "Epoch 183/200\n",
      "1484/1484 [==============================] - 1s 815us/step - loss: 1.0852 - acc: 0.5775\n",
      "Epoch 184/200\n",
      "1484/1484 [==============================] - 1s 860us/step - loss: 1.0841 - acc: 0.5687\n",
      "Epoch 185/200\n",
      "1484/1484 [==============================] - 1s 856us/step - loss: 1.0818 - acc: 0.5687\n",
      "Epoch 186/200\n",
      "1484/1484 [==============================] - 1s 963us/step - loss: 1.0872 - acc: 0.5714\n",
      "Epoch 187/200\n",
      "1484/1484 [==============================] - 1s 779us/step - loss: 1.0855 - acc: 0.5633 0s - loss: 1.0716 - a - ETA: 0s - loss: 1.0766 - acc: 0.5\n",
      "Epoch 188/200\n",
      "1484/1484 [==============================] - 1s 864us/step - loss: 1.0863 - acc: 0.5674 0s - loss: 1.1057\n",
      "Epoch 189/200\n",
      "1484/1484 [==============================] - 1s 683us/step - loss: 1.0873 - acc: 0.5708\n",
      "Epoch 190/200\n",
      "1484/1484 [==============================] - 1s 671us/step - loss: 1.0856 - acc: 0.5741\n",
      "Epoch 191/200\n",
      "1484/1484 [==============================] - 1s 670us/step - loss: 1.0878 - acc: 0.5735\n",
      "Epoch 192/200\n",
      "1484/1484 [==============================] - 1s 673us/step - loss: 1.0864 - acc: 0.5593\n",
      "Epoch 193/200\n",
      "1484/1484 [==============================] - 1s 673us/step - loss: 1.0852 - acc: 0.5741 0s - loss: 1.1063 - acc: 0\n",
      "Epoch 194/200\n",
      "1484/1484 [==============================] - 1s 669us/step - loss: 1.0835 - acc: 0.5681\n",
      "Epoch 195/200\n",
      "1484/1484 [==============================] - 1s 672us/step - loss: 1.0826 - acc: 0.5714\n",
      "Epoch 196/200\n",
      "1484/1484 [==============================] - 1s 670us/step - loss: 1.0857 - acc: 0.5856\n",
      "Epoch 197/200\n",
      "1484/1484 [==============================] - 1s 668us/step - loss: 1.0842 - acc: 0.5721\n",
      "Epoch 198/200\n",
      "1484/1484 [==============================] - 1s 673us/step - loss: 1.0896 - acc: 0.5687\n",
      "Epoch 199/200\n",
      "1484/1484 [==============================] - 1s 683us/step - loss: 1.0866 - acc: 0.5681\n",
      "Epoch 200/200\n",
      "1484/1484 [==============================] - 1s 672us/step - loss: 1.0816 - acc: 0.5687\n"
     ]
    }
   ],
   "source": [
    "class LossHistoryAll(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.weights = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.weights.append(model.layers[2].get_weights())\n",
    "\n",
    "model_all.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "history_all = LossHistoryAll()\n",
    "\n",
    "model_all_hist = model.fit(X, y_class,\n",
    "                  batch_size = 1, nb_epoch = 200,callbacks = [history_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-3.7326841 ,  0.09865446, -1.8912619 ,  4.9887342 ,  2.2132063 ,\n",
       "          6.1130376 ,  0.26344743, -2.1218789 , -4.9977746 , -0.15751955],\n",
       "        [ 3.407947  , -5.19185   , -2.7179418 , -5.1634603 , -3.4933512 ,\n",
       "          3.5918317 ,  5.8061066 ,  6.784805  , -4.459845  ,  0.37288824],\n",
       "        [ 2.606588  , -2.8314116 , -4.518216  , -7.0092187 , -1.1313876 ,\n",
       "          4.957545  , -3.6512523 ,  3.509569  ,  3.2745762 ,  2.0949626 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.54809093,  1.3047516 ,  3.279837  ,  2.0467224 ,  1.9639628 ,\n",
       "        -7.1271996 ,  0.4208262 , -3.1162412 ,  1.4535168 , -0.77121794],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_all.weights[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43126684636118595"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-model_all_hist.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hand calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = np.array([X[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = np.array([y_class[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 3)                 27        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                40        \n",
      "=================================================================\n",
      "Total params: 79\n",
      "Trainable params: 79\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hand_1 = Sequential()\n",
    "hand_1.add(Dense(3, input_dim= 8, weights=[np.ones((8,3)),np.zeros(3)],activation='sigmoid'))\n",
    "hand_1.add(Dense(3, weights=[np.ones((3,3)),np.zeros(3)], activation = \"sigmoid\"))\n",
    "hand_1.add(Dense(10, weights=[np.ones((3,10)),np.zeros(10)], activation = \"softmax\"))\n",
    "hand_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 2.3026 - acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.5)\n",
    "hand_1.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "hand_1_hist = hand_1.fit(X_1, y_1, batch_size = 1, nb_epoch = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=float32),\n",
       " array([5.2373456e-11, 5.2373456e-11, 5.2373456e-11], dtype=float32),\n",
       " array([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=float32),\n",
       " array([3.829537e-10, 3.829537e-10, 3.829537e-10], dtype=float32),\n",
       " array([[0.95271766, 0.95271766, 0.95271766, 0.95271766, 0.95271766,\n",
       "         0.95271766, 1.4255409 , 0.95271766, 0.95271766, 0.95271766],\n",
       "        [0.95271766, 0.95271766, 0.95271766, 0.95271766, 0.95271766,\n",
       "         0.95271766, 1.4255409 , 0.95271766, 0.95271766, 0.95271766],\n",
       "        [0.95271766, 0.95271766, 0.95271766, 0.95271766, 0.95271766,\n",
       "         0.95271766, 1.4255409 , 0.95271766, 0.95271766, 0.95271766]],\n",
       "       dtype=float32),\n",
       " array([-0.05      , -0.05      , -0.05      , -0.05      , -0.05      ,\n",
       "        -0.05      ,  0.45000002, -0.05      , -0.05      , -0.05      ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand_1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=float32),\n",
       " array([3.829537e-10, 3.829537e-10, 3.829537e-10], dtype=float32)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand_1.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.8643827112918754], 'acc': [0.29110512129380056]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand_1_hist.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = []\n",
    "for i in range(1,4):\n",
    "    for j in range(3,13,3):\n",
    "        grid.append([i,j])\n",
    "grid = np.array(grid)\n",
    "grid = np.reshape(np.reshape(grid, grid.shape + (1,)),(3,4,2))\n",
    "grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  3],\n",
       "        [ 1,  6],\n",
       "        [ 1,  9],\n",
       "        [ 1, 12]],\n",
       "\n",
       "       [[ 2,  3],\n",
       "        [ 2,  6],\n",
       "        [ 2,  9],\n",
       "        [ 2, 12]],\n",
       "\n",
       "       [[ 3,  3],\n",
       "        [ 3,  6],\n",
       "        [ 3,  9],\n",
       "        [ 3, 12]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(hidden_layer,nodes,X_tr,y_tr,X_te,y_te,epoch):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes,activation = \"sigmoid\", input_dim=8))\n",
    "    for l in range(hidden_layer-1):\n",
    "        model.add(Dense(nodes, activation = \"sigmoid\"))\n",
    "    model.add(Dense(10, activation = \"softmax\"))\n",
    "    \n",
    "    model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "    model_hist = model.fit(X_tr, y_tr_class,validation_data=(X_te,y_te_class),\n",
    "                           batch_size = 1, nb_epoch = epoch)\n",
    "    fnl_loss = model_hist.history['val_loss'][-1]\n",
    "    \n",
    "    return fnl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 401 samples\n",
      "Epoch 1/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.9111 - acc: 0.2537 - val_loss: 1.7317 - val_acc: 0.3292\n",
      "Epoch 2/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7158 - acc: 0.3051 - val_loss: 1.6581 - val_acc: 0.3317\n",
      "Epoch 3/100\n",
      "934/934 [==============================] - 1s 961us/step - loss: 1.6549 - acc: 0.3244 - val_loss: 1.6030 - val_acc: 0.3117\n",
      "Epoch 4/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6000 - acc: 0.3394 - val_loss: 1.5387 - val_acc: 0.3990\n",
      "Epoch 5/100\n",
      "934/934 [==============================] - 1s 979us/step - loss: 1.5418 - acc: 0.4036 - val_loss: 1.4827 - val_acc: 0.4065\n",
      "Epoch 6/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4841 - acc: 0.4486 - val_loss: 1.4244 - val_acc: 0.4838\n",
      "Epoch 7/100\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.4297 - acc: 0.4700 - val_loss: 1.3808 - val_acc: 0.4489\n",
      "Epoch 8/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.3917 - acc: 0.4904 - val_loss: 1.3399 - val_acc: 0.4888\n",
      "Epoch 9/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3593 - acc: 0.4754 - val_loss: 1.3164 - val_acc: 0.4913\n",
      "Epoch 10/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3326 - acc: 0.4732 - val_loss: 1.2927 - val_acc: 0.4738\n",
      "Epoch 11/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3133 - acc: 0.5054 - val_loss: 1.2762 - val_acc: 0.4638\n",
      "Epoch 12/100\n",
      "934/934 [==============================] - 1s 985us/step - loss: 1.2958 - acc: 0.4754 - val_loss: 1.2611 - val_acc: 0.4863\n",
      "Epoch 13/100\n",
      "934/934 [==============================] - 1s 947us/step - loss: 1.2752 - acc: 0.4818 - val_loss: 1.2557 - val_acc: 0.5012\n",
      "Epoch 14/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2672 - acc: 0.4829 - val_loss: 1.2383 - val_acc: 0.4788\n",
      "Epoch 15/100\n",
      "934/934 [==============================] - 1s 974us/step - loss: 1.2536 - acc: 0.4722 - val_loss: 1.2324 - val_acc: 0.4464\n",
      "Epoch 16/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2442 - acc: 0.4636 - val_loss: 1.2229 - val_acc: 0.4613\n",
      "Epoch 17/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2343 - acc: 0.4657 - val_loss: 1.2084 - val_acc: 0.5187\n",
      "Epoch 18/100\n",
      "934/934 [==============================] - 1s 936us/step - loss: 1.2253 - acc: 0.4829 - val_loss: 1.2035 - val_acc: 0.5187\n",
      "Epoch 19/100\n",
      "934/934 [==============================] - 1s 948us/step - loss: 1.2174 - acc: 0.4989 - val_loss: 1.1973 - val_acc: 0.4813\n",
      "Epoch 20/100\n",
      "934/934 [==============================] - 1s 937us/step - loss: 1.2101 - acc: 0.4979 - val_loss: 1.1906 - val_acc: 0.5212\n",
      "Epoch 21/100\n",
      "934/934 [==============================] - 1s 937us/step - loss: 1.2026 - acc: 0.5096 - val_loss: 1.1839 - val_acc: 0.5511\n",
      "Epoch 22/100\n",
      "934/934 [==============================] - 1s 949us/step - loss: 1.1955 - acc: 0.5118 - val_loss: 1.1846 - val_acc: 0.4863\n",
      "Epoch 23/100\n",
      "934/934 [==============================] - 1s 931us/step - loss: 1.1899 - acc: 0.5161 - val_loss: 1.1775 - val_acc: 0.5087\n",
      "Epoch 24/100\n",
      "934/934 [==============================] - 1s 928us/step - loss: 1.1853 - acc: 0.4925 - val_loss: 1.1767 - val_acc: 0.5162\n",
      "Epoch 25/100\n",
      "934/934 [==============================] - 1s 931us/step - loss: 1.1807 - acc: 0.5203 - val_loss: 1.1704 - val_acc: 0.5237\n",
      "Epoch 26/100\n",
      "934/934 [==============================] - 1s 917us/step - loss: 1.1761 - acc: 0.5182 - val_loss: 1.1723 - val_acc: 0.5387\n",
      "Epoch 27/100\n",
      "934/934 [==============================] - 1s 925us/step - loss: 1.1690 - acc: 0.5418 - val_loss: 1.1865 - val_acc: 0.4713\n",
      "Epoch 28/100\n",
      "934/934 [==============================] - 1s 941us/step - loss: 1.1708 - acc: 0.5246 - val_loss: 1.1643 - val_acc: 0.5237\n",
      "Epoch 29/100\n",
      "934/934 [==============================] - 1s 928us/step - loss: 1.1659 - acc: 0.5214 - val_loss: 1.1620 - val_acc: 0.5312\n",
      "Epoch 30/100\n",
      "934/934 [==============================] - 1s 929us/step - loss: 1.1625 - acc: 0.5268 - val_loss: 1.1639 - val_acc: 0.5312\n",
      "Epoch 31/100\n",
      "934/934 [==============================] - 1s 929us/step - loss: 1.1607 - acc: 0.5278 - val_loss: 1.1612 - val_acc: 0.5137\n",
      "Epoch 32/100\n",
      "934/934 [==============================] - 1s 939us/step - loss: 1.1587 - acc: 0.5289 - val_loss: 1.1586 - val_acc: 0.5237\n",
      "Epoch 33/100\n",
      "934/934 [==============================] - 1s 944us/step - loss: 1.1557 - acc: 0.5278 - val_loss: 1.1567 - val_acc: 0.5212\n",
      "Epoch 34/100\n",
      "934/934 [==============================] - 1s 913us/step - loss: 1.1542 - acc: 0.5385 - val_loss: 1.1610 - val_acc: 0.5087\n",
      "Epoch 35/100\n",
      "934/934 [==============================] - 1s 934us/step - loss: 1.1510 - acc: 0.5268 - val_loss: 1.1570 - val_acc: 0.5461\n",
      "Epoch 36/100\n",
      "934/934 [==============================] - 1s 929us/step - loss: 1.1506 - acc: 0.5289 - val_loss: 1.1583 - val_acc: 0.5162\n",
      "Epoch 37/100\n",
      "934/934 [==============================] - 1s 922us/step - loss: 1.1482 - acc: 0.5450 - val_loss: 1.1596 - val_acc: 0.5162\n",
      "Epoch 38/100\n",
      "934/934 [==============================] - 1s 932us/step - loss: 1.1456 - acc: 0.5321 - val_loss: 1.1584 - val_acc: 0.5187\n",
      "Epoch 39/100\n",
      "934/934 [==============================] - 1s 932us/step - loss: 1.1433 - acc: 0.5278 - val_loss: 1.1588 - val_acc: 0.5137\n",
      "Epoch 40/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1432 - acc: 0.5257 - val_loss: 1.1547 - val_acc: 0.5187\n",
      "Epoch 41/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1402 - acc: 0.5450 - val_loss: 1.1589 - val_acc: 0.5187\n",
      "Epoch 42/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1405 - acc: 0.5385 - val_loss: 1.1538 - val_acc: 0.5262\n",
      "Epoch 43/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1379 - acc: 0.5343 - val_loss: 1.1590 - val_acc: 0.5237\n",
      "Epoch 44/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1382 - acc: 0.5289 - val_loss: 1.1525 - val_acc: 0.5287\n",
      "Epoch 45/100\n",
      "934/934 [==============================] - 1s 986us/step - loss: 1.1360 - acc: 0.5300 - val_loss: 1.1519 - val_acc: 0.5212\n",
      "Epoch 46/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1350 - acc: 0.5225 - val_loss: 1.1505 - val_acc: 0.5337\n",
      "Epoch 47/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1333 - acc: 0.5278 - val_loss: 1.1506 - val_acc: 0.5187\n",
      "Epoch 48/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1308 - acc: 0.5332 - val_loss: 1.1500 - val_acc: 0.5162\n",
      "Epoch 49/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1297 - acc: 0.5375 - val_loss: 1.1525 - val_acc: 0.5411\n",
      "Epoch 50/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1293 - acc: 0.5343 - val_loss: 1.1472 - val_acc: 0.5287\n",
      "Epoch 51/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1293 - acc: 0.5353 - val_loss: 1.1500 - val_acc: 0.5162\n",
      "Epoch 52/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1280 - acc: 0.5364 - val_loss: 1.1501 - val_acc: 0.5262\n",
      "Epoch 53/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1261 - acc: 0.5407 - val_loss: 1.1514 - val_acc: 0.5212\n",
      "Epoch 54/100\n",
      "934/934 [==============================] - 1s 919us/step - loss: 1.1251 - acc: 0.5396 - val_loss: 1.1452 - val_acc: 0.5287loss: 1.1220 - acc: 0.54\n",
      "Epoch 55/100\n",
      "934/934 [==============================] - 1s 936us/step - loss: 1.1243 - acc: 0.5396 - val_loss: 1.1515 - val_acc: 0.5262\n",
      "Epoch 56/100\n",
      "934/934 [==============================] - 1s 934us/step - loss: 1.1224 - acc: 0.5364 - val_loss: 1.1474 - val_acc: 0.5486\n",
      "Epoch 57/100\n",
      "934/934 [==============================] - 1s 938us/step - loss: 1.1234 - acc: 0.5557 - val_loss: 1.1458 - val_acc: 0.5337\n",
      "Epoch 58/100\n",
      "934/934 [==============================] - 1s 934us/step - loss: 1.1210 - acc: 0.5418 - val_loss: 1.1499 - val_acc: 0.5262\n",
      "Epoch 59/100\n",
      "934/934 [==============================] - 1s 931us/step - loss: 1.1217 - acc: 0.5375 - val_loss: 1.1462 - val_acc: 0.5312\n",
      "Epoch 60/100\n",
      "934/934 [==============================] - 1s 936us/step - loss: 1.1208 - acc: 0.5418 - val_loss: 1.1426 - val_acc: 0.5237\n",
      "Epoch 61/100\n",
      "934/934 [==============================] - 1s 911us/step - loss: 1.1199 - acc: 0.5450 - val_loss: 1.1427 - val_acc: 0.5362\n",
      "Epoch 62/100\n",
      "934/934 [==============================] - 1s 892us/step - loss: 1.1189 - acc: 0.5418 - val_loss: 1.1427 - val_acc: 0.5212\n",
      "Epoch 63/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1180 - acc: 0.5450 - val_loss: 1.1421 - val_acc: 0.5387\n",
      "Epoch 64/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1164 - acc: 0.5418 - val_loss: 1.1426 - val_acc: 0.5362\n",
      "Epoch 65/100\n",
      "934/934 [==============================] - 1s 900us/step - loss: 1.1159 - acc: 0.5471 - val_loss: 1.1426 - val_acc: 0.5287\n",
      "Epoch 66/100\n",
      "934/934 [==============================] - 1s 924us/step - loss: 1.1142 - acc: 0.5460 - val_loss: 1.1447 - val_acc: 0.5237\n",
      "Epoch 67/100\n",
      "934/934 [==============================] - 1s 933us/step - loss: 1.1138 - acc: 0.5514 - val_loss: 1.1423 - val_acc: 0.5312\n",
      "Epoch 68/100\n",
      "934/934 [==============================] - 1s 894us/step - loss: 1.1149 - acc: 0.5460 - val_loss: 1.1395 - val_acc: 0.5337\n",
      "Epoch 69/100\n",
      "934/934 [==============================] - 1s 892us/step - loss: 1.1134 - acc: 0.5439 - val_loss: 1.1375 - val_acc: 0.5287\n",
      "Epoch 70/100\n",
      "934/934 [==============================] - 1s 896us/step - loss: 1.1139 - acc: 0.5503 - val_loss: 1.1376 - val_acc: 0.5411\n",
      "Epoch 71/100\n",
      "934/934 [==============================] - 1s 897us/step - loss: 1.1128 - acc: 0.5439 - val_loss: 1.1404 - val_acc: 0.5362\n",
      "Epoch 72/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1114 - acc: 0.5471 - val_loss: 1.1369 - val_acc: 0.5387\n",
      "Epoch 73/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1117 - acc: 0.5482 - val_loss: 1.1334 - val_acc: 0.5486\n",
      "Epoch 74/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1109 - acc: 0.5396 - val_loss: 1.1351 - val_acc: 0.5387\n",
      "Epoch 75/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1101 - acc: 0.5557 - val_loss: 1.1357 - val_acc: 0.5511\n",
      "Epoch 76/100\n",
      "934/934 [==============================] - 1s 944us/step - loss: 1.1093 - acc: 0.5546 - val_loss: 1.1359 - val_acc: 0.5337\n",
      "Epoch 77/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1099 - acc: 0.5428 - val_loss: 1.1350 - val_acc: 0.5387\n",
      "Epoch 78/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1068 - acc: 0.5460 - val_loss: 1.1348 - val_acc: 0.5611\n",
      "Epoch 79/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1085 - acc: 0.5557 - val_loss: 1.1339 - val_acc: 0.5362\n",
      "Epoch 80/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1049 - acc: 0.5514 - val_loss: 1.1347 - val_acc: 0.5611\n",
      "Epoch 81/100\n",
      "934/934 [==============================] - 1s 974us/step - loss: 1.1074 - acc: 0.5460 - val_loss: 1.1296 - val_acc: 0.5536\n",
      "Epoch 82/100\n",
      "934/934 [==============================] - 1s 945us/step - loss: 1.1048 - acc: 0.5503 - val_loss: 1.1344 - val_acc: 0.5312\n",
      "Epoch 83/100\n",
      "934/934 [==============================] - 1s 903us/step - loss: 1.1054 - acc: 0.5578 - val_loss: 1.1321 - val_acc: 0.5312\n",
      "Epoch 84/100\n",
      "934/934 [==============================] - 1s 978us/step - loss: 1.1037 - acc: 0.5493 - val_loss: 1.1258 - val_acc: 0.5586\n",
      "Epoch 85/100\n",
      "934/934 [==============================] - 1s 935us/step - loss: 1.1039 - acc: 0.5493 - val_loss: 1.1260 - val_acc: 0.5511\n",
      "Epoch 86/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1037 - acc: 0.5535 - val_loss: 1.1231 - val_acc: 0.5611\n",
      "Epoch 87/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1025 - acc: 0.5653 - val_loss: 1.1262 - val_acc: 0.5387\n",
      "Epoch 88/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1027 - acc: 0.5578 - val_loss: 1.1270 - val_acc: 0.5387\n",
      "Epoch 89/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1009 - acc: 0.5525 - val_loss: 1.1243 - val_acc: 0.5736\n",
      "Epoch 90/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1007 - acc: 0.5589 - val_loss: 1.1195 - val_acc: 0.5711\n",
      "Epoch 91/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1005 - acc: 0.5525 - val_loss: 1.1234 - val_acc: 0.5536\n",
      "Epoch 92/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.0989 - acc: 0.5589 - val_loss: 1.1198 - val_acc: 0.5711\n",
      "Epoch 93/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.0977 - acc: 0.5621 - val_loss: 1.1306 - val_acc: 0.5337\n",
      "Epoch 94/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.0988 - acc: 0.5503 - val_loss: 1.1186 - val_acc: 0.5511\n",
      "Epoch 95/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0979 - acc: 0.5653 - val_loss: 1.1147 - val_acc: 0.5661\n",
      "Epoch 96/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0979 - acc: 0.5696 - val_loss: 1.1132 - val_acc: 0.5736\n",
      "Epoch 97/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0958 - acc: 0.5589 - val_loss: 1.1201 - val_acc: 0.5387\n",
      "Epoch 98/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0972 - acc: 0.5621 - val_loss: 1.1137 - val_acc: 0.5461\n",
      "Epoch 99/100\n",
      "934/934 [==============================] - 1s 2ms/step - loss: 1.0957 - acc: 0.5685 - val_loss: 1.1142 - val_acc: 0.5511\n",
      "Epoch 100/100\n",
      "934/934 [==============================] - 2s 3ms/step - loss: 1.0955 - acc: 0.5760 - val_loss: 1.1129 - val_acc: 0.5486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 401 samples\n",
      "Epoch 1/100\n",
      "934/934 [==============================] - 3s 3ms/step - loss: 1.8791 - acc: 0.3255 - val_loss: 1.6653 - val_acc: 0.3142\n",
      "Epoch 2/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6186 - acc: 0.3480 - val_loss: 1.5419 - val_acc: 0.3566\n",
      "Epoch 3/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.5111 - acc: 0.3919 - val_loss: 1.4452 - val_acc: 0.4813\n",
      "Epoch 4/100\n",
      "934/934 [==============================] - 1s 2ms/step - loss: 1.4271 - acc: 0.4839 - val_loss: 1.3660 - val_acc: 0.4763\n",
      "Epoch 5/100\n",
      "934/934 [==============================] - 1s 970us/step - loss: 1.3601 - acc: 0.5011 - val_loss: 1.3108 - val_acc: 0.4938\n",
      "Epoch 6/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3108 - acc: 0.5128 - val_loss: 1.2697 - val_acc: 0.5212\n",
      "Epoch 7/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2722 - acc: 0.5439 - val_loss: 1.2418 - val_acc: 0.5212\n",
      "Epoch 8/100\n",
      "934/934 [==============================] - 1s 982us/step - loss: 1.2443 - acc: 0.5375 - val_loss: 1.2161 - val_acc: 0.5187\n",
      "Epoch 9/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2185 - acc: 0.5503 - val_loss: 1.2037 - val_acc: 0.5112\n",
      "Epoch 10/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2001 - acc: 0.5353 - val_loss: 1.1834 - val_acc: 0.5237\n",
      "Epoch 11/100\n",
      "934/934 [==============================] - 1s 966us/step - loss: 1.1831 - acc: 0.5525 - val_loss: 1.1685 - val_acc: 0.5312\n",
      "Epoch 12/100\n",
      "934/934 [==============================] - 1s 979us/step - loss: 1.1678 - acc: 0.5567 - val_loss: 1.1563 - val_acc: 0.5461\n",
      "Epoch 13/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1563 - acc: 0.5546 - val_loss: 1.1496 - val_acc: 0.5337\n",
      "Epoch 14/100\n",
      "934/934 [==============================] - 1s 997us/step - loss: 1.1444 - acc: 0.5546 - val_loss: 1.1516 - val_acc: 0.5387\n",
      "Epoch 15/100\n",
      "934/934 [==============================] - 1s 926us/step - loss: 1.1391 - acc: 0.5589 - val_loss: 1.1326 - val_acc: 0.5486\n",
      "Epoch 16/100\n",
      "934/934 [==============================] - 1s 941us/step - loss: 1.1305 - acc: 0.5632 - val_loss: 1.1280 - val_acc: 0.5337\n",
      "Epoch 17/100\n",
      "934/934 [==============================] - 1s 939us/step - loss: 1.1214 - acc: 0.5717 - val_loss: 1.1236 - val_acc: 0.5511\n",
      "Epoch 18/100\n",
      "934/934 [==============================] - 1s 984us/step - loss: 1.1170 - acc: 0.5653 - val_loss: 1.1174 - val_acc: 0.5486\n",
      "Epoch 19/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1104 - acc: 0.5632 - val_loss: 1.1157 - val_acc: 0.5411\n",
      "Epoch 20/100\n",
      "934/934 [==============================] - 1s 979us/step - loss: 1.1057 - acc: 0.5653 - val_loss: 1.1099 - val_acc: 0.5536\n",
      "Epoch 21/100\n",
      "934/934 [==============================] - 1s 929us/step - loss: 1.1009 - acc: 0.5717 - val_loss: 1.1211 - val_acc: 0.5461\n",
      "Epoch 22/100\n",
      "934/934 [==============================] - 1s 966us/step - loss: 1.0971 - acc: 0.5771 - val_loss: 1.1054 - val_acc: 0.5586\n",
      "Epoch 23/100\n",
      "934/934 [==============================] - 1s 896us/step - loss: 1.0932 - acc: 0.5824 - val_loss: 1.1056 - val_acc: 0.5561\n",
      "Epoch 24/100\n",
      "934/934 [==============================] - 1s 910us/step - loss: 1.0878 - acc: 0.5782 - val_loss: 1.1056 - val_acc: 0.5611\n",
      "Epoch 25/100\n",
      "934/934 [==============================] - 1s 981us/step - loss: 1.0858 - acc: 0.5835 - val_loss: 1.1015 - val_acc: 0.5611\n",
      "Epoch 26/100\n",
      "934/934 [==============================] - 1s 905us/step - loss: 1.0835 - acc: 0.5824 - val_loss: 1.1020 - val_acc: 0.5536\n",
      "Epoch 27/100\n",
      "934/934 [==============================] - 1s 942us/step - loss: 1.0792 - acc: 0.5921 - val_loss: 1.1074 - val_acc: 0.5536\n",
      "Epoch 28/100\n",
      "934/934 [==============================] - 1s 990us/step - loss: 1.0757 - acc: 0.6017 - val_loss: 1.1028 - val_acc: 0.5362\n",
      "Epoch 29/100\n",
      "934/934 [==============================] - 1s 891us/step - loss: 1.0741 - acc: 0.5931 - val_loss: 1.0967 - val_acc: 0.5561\n",
      "Epoch 30/100\n",
      "934/934 [==============================] - 1s 894us/step - loss: 1.0725 - acc: 0.5867 - val_loss: 1.0961 - val_acc: 0.5611\n",
      "Epoch 31/100\n",
      "934/934 [==============================] - 1s 940us/step - loss: 1.0706 - acc: 0.5910 - val_loss: 1.0953 - val_acc: 0.5611\n",
      "Epoch 32/100\n",
      "934/934 [==============================] - 1s 931us/step - loss: 1.0693 - acc: 0.5942 - val_loss: 1.1016 - val_acc: 0.5511\n",
      "Epoch 33/100\n",
      "934/934 [==============================] - 1s 921us/step - loss: 1.0656 - acc: 0.5953 - val_loss: 1.0932 - val_acc: 0.5636\n",
      "Epoch 34/100\n",
      "934/934 [==============================] - 1s 894us/step - loss: 1.0619 - acc: 0.6006 - val_loss: 1.1030 - val_acc: 0.5536\n",
      "Epoch 35/100\n",
      "934/934 [==============================] - 1s 893us/step - loss: 1.0633 - acc: 0.5974 - val_loss: 1.0917 - val_acc: 0.5586\n",
      "Epoch 36/100\n",
      "934/934 [==============================] - 1s 895us/step - loss: 1.0610 - acc: 0.5985 - val_loss: 1.0964 - val_acc: 0.5611\n",
      "Epoch 37/100\n",
      "934/934 [==============================] - 1s 882us/step - loss: 1.0600 - acc: 0.5942 - val_loss: 1.0914 - val_acc: 0.5486\n",
      "Epoch 38/100\n",
      "934/934 [==============================] - 1s 890us/step - loss: 1.0546 - acc: 0.5931 - val_loss: 1.0902 - val_acc: 0.5636\n",
      "Epoch 39/100\n",
      "934/934 [==============================] - 1s 906us/step - loss: 1.0579 - acc: 0.6049 - val_loss: 1.0888 - val_acc: 0.5661\n",
      "Epoch 40/100\n",
      "934/934 [==============================] - 1s 890us/step - loss: 1.0543 - acc: 0.6039 - val_loss: 1.0982 - val_acc: 0.5486\n",
      "Epoch 41/100\n",
      "934/934 [==============================] - 1s 889us/step - loss: 1.0544 - acc: 0.5899 - val_loss: 1.0884 - val_acc: 0.5686\n",
      "Epoch 42/100\n",
      "934/934 [==============================] - 1s 887us/step - loss: 1.0532 - acc: 0.6028 - val_loss: 1.0908 - val_acc: 0.5511\n",
      "Epoch 43/100\n",
      "934/934 [==============================] - 1s 891us/step - loss: 1.0515 - acc: 0.6135 - val_loss: 1.0894 - val_acc: 0.5636\n",
      "Epoch 44/100\n",
      "934/934 [==============================] - 1s 888us/step - loss: 1.0515 - acc: 0.6039 - val_loss: 1.0883 - val_acc: 0.5586\n",
      "Epoch 45/100\n",
      "934/934 [==============================] - 1s 895us/step - loss: 1.0489 - acc: 0.6081 - val_loss: 1.1008 - val_acc: 0.5636\n",
      "Epoch 46/100\n",
      "934/934 [==============================] - 1s 890us/step - loss: 1.0461 - acc: 0.6081 - val_loss: 1.0901 - val_acc: 0.5761\n",
      "Epoch 47/100\n",
      "934/934 [==============================] - 1s 893us/step - loss: 1.0488 - acc: 0.6028 - val_loss: 1.0874 - val_acc: 0.5611\n",
      "Epoch 48/100\n",
      "934/934 [==============================] - 1s 891us/step - loss: 1.0461 - acc: 0.6113 - val_loss: 1.0878 - val_acc: 0.5661\n",
      "Epoch 49/100\n",
      "934/934 [==============================] - 1s 892us/step - loss: 1.0456 - acc: 0.6006 - val_loss: 1.0838 - val_acc: 0.5686\n",
      "Epoch 50/100\n",
      "934/934 [==============================] - 1s 891us/step - loss: 1.0446 - acc: 0.5985 - val_loss: 1.0869 - val_acc: 0.5636\n",
      "Epoch 51/100\n",
      "934/934 [==============================] - 1s 887us/step - loss: 1.0436 - acc: 0.6103 - val_loss: 1.0856 - val_acc: 0.5736\n",
      "Epoch 52/100\n",
      "934/934 [==============================] - 1s 894us/step - loss: 1.0440 - acc: 0.6028 - val_loss: 1.0852 - val_acc: 0.5661\n",
      "Epoch 53/100\n",
      "934/934 [==============================] - 1s 888us/step - loss: 1.0421 - acc: 0.6017 - val_loss: 1.0831 - val_acc: 0.5661\n",
      "Epoch 54/100\n",
      "934/934 [==============================] - 1s 894us/step - loss: 1.0422 - acc: 0.6039 - val_loss: 1.0898 - val_acc: 0.5686\n",
      "Epoch 55/100\n",
      "934/934 [==============================] - 1s 888us/step - loss: 1.0397 - acc: 0.6049 - val_loss: 1.0815 - val_acc: 0.5711\n",
      "Epoch 56/100\n",
      "934/934 [==============================] - 1s 890us/step - loss: 1.0393 - acc: 0.5974 - val_loss: 1.0852 - val_acc: 0.5661\n",
      "Epoch 57/100\n",
      "934/934 [==============================] - 1s 894us/step - loss: 1.0401 - acc: 0.6146 - val_loss: 1.0832 - val_acc: 0.5661\n",
      "Epoch 58/100\n",
      "934/934 [==============================] - 1s 901us/step - loss: 1.0392 - acc: 0.5942 - val_loss: 1.0835 - val_acc: 0.5636\n",
      "Epoch 59/100\n",
      "934/934 [==============================] - 1s 895us/step - loss: 1.0388 - acc: 0.6028 - val_loss: 1.0848 - val_acc: 0.5611\n",
      "Epoch 60/100\n",
      "934/934 [==============================] - 1s 888us/step - loss: 1.0385 - acc: 0.6028 - val_loss: 1.0805 - val_acc: 0.5711\n",
      "Epoch 61/100\n",
      "934/934 [==============================] - 1s 887us/step - loss: 1.0374 - acc: 0.5931 - val_loss: 1.0865 - val_acc: 0.5686\n",
      "Epoch 62/100\n",
      "934/934 [==============================] - 1s 889us/step - loss: 1.0358 - acc: 0.6039 - val_loss: 1.0839 - val_acc: 0.5661\n",
      "Epoch 63/100\n",
      "934/934 [==============================] - 1s 881us/step - loss: 1.0338 - acc: 0.6017 - val_loss: 1.0889 - val_acc: 0.5711\n",
      "Epoch 64/100\n",
      "934/934 [==============================] - 1s 901us/step - loss: 1.0351 - acc: 0.6039 - val_loss: 1.0884 - val_acc: 0.5736\n",
      "Epoch 65/100\n",
      "934/934 [==============================] - 1s 876us/step - loss: 1.0349 - acc: 0.6049 - val_loss: 1.0845 - val_acc: 0.5736\n",
      "Epoch 66/100\n",
      "934/934 [==============================] - 1s 890us/step - loss: 1.0337 - acc: 0.5996 - val_loss: 1.0821 - val_acc: 0.5761\n",
      "Epoch 67/100\n",
      "934/934 [==============================] - 1s 883us/step - loss: 1.0342 - acc: 0.6017 - val_loss: 1.0860 - val_acc: 0.5761\n",
      "Epoch 68/100\n",
      "934/934 [==============================] - 1s 892us/step - loss: 1.0324 - acc: 0.6113 - val_loss: 1.0791 - val_acc: 0.5835\n",
      "Epoch 69/100\n",
      "934/934 [==============================] - 1s 893us/step - loss: 1.0310 - acc: 0.6081 - val_loss: 1.0867 - val_acc: 0.5786\n",
      "Epoch 70/100\n",
      "934/934 [==============================] - 1s 923us/step - loss: 1.0311 - acc: 0.6006 - val_loss: 1.0814 - val_acc: 0.5711\n",
      "Epoch 71/100\n",
      "934/934 [==============================] - 1s 917us/step - loss: 1.0310 - acc: 0.6028 - val_loss: 1.0834 - val_acc: 0.5761\n",
      "Epoch 72/100\n",
      "934/934 [==============================] - 1s 896us/step - loss: 1.0293 - acc: 0.6049 - val_loss: 1.0857 - val_acc: 0.5611\n",
      "Epoch 73/100\n",
      "934/934 [==============================] - 1s 894us/step - loss: 1.0267 - acc: 0.6060 - val_loss: 1.0928 - val_acc: 0.5586\n",
      "Epoch 74/100\n",
      "934/934 [==============================] - 1s 885us/step - loss: 1.0306 - acc: 0.5996 - val_loss: 1.0845 - val_acc: 0.5761\n",
      "Epoch 75/100\n",
      "934/934 [==============================] - 1s 887us/step - loss: 1.0274 - acc: 0.6006 - val_loss: 1.0935 - val_acc: 0.5736\n",
      "Epoch 76/100\n",
      "934/934 [==============================] - 1s 884us/step - loss: 1.0284 - acc: 0.6081 - val_loss: 1.0877 - val_acc: 0.5711\n",
      "Epoch 77/100\n",
      "934/934 [==============================] - 1s 892us/step - loss: 1.0283 - acc: 0.5974 - val_loss: 1.0911 - val_acc: 0.5736\n",
      "Epoch 78/100\n",
      "934/934 [==============================] - 1s 879us/step - loss: 1.0282 - acc: 0.6006 - val_loss: 1.0803 - val_acc: 0.5835\n",
      "Epoch 79/100\n",
      "934/934 [==============================] - 1s 902us/step - loss: 1.0266 - acc: 0.5985 - val_loss: 1.0835 - val_acc: 0.5761\n",
      "Epoch 80/100\n",
      "934/934 [==============================] - 1s 899us/step - loss: 1.0268 - acc: 0.6017 - val_loss: 1.0803 - val_acc: 0.5786\n",
      "Epoch 81/100\n",
      "934/934 [==============================] - 1s 913us/step - loss: 1.0258 - acc: 0.6049 - val_loss: 1.0858 - val_acc: 0.5661\n",
      "Epoch 82/100\n",
      "934/934 [==============================] - 1s 937us/step - loss: 1.0233 - acc: 0.5953 - val_loss: 1.0853 - val_acc: 0.5786\n",
      "Epoch 83/100\n",
      "934/934 [==============================] - 1s 922us/step - loss: 1.0239 - acc: 0.6017 - val_loss: 1.0791 - val_acc: 0.5885\n",
      "Epoch 84/100\n",
      "934/934 [==============================] - 1s 923us/step - loss: 1.0230 - acc: 0.6049 - val_loss: 1.0796 - val_acc: 0.5736\n",
      "Epoch 85/100\n",
      "934/934 [==============================] - 1s 958us/step - loss: 1.0226 - acc: 0.6060 - val_loss: 1.0830 - val_acc: 0.5810\n",
      "Epoch 86/100\n",
      "934/934 [==============================] - 1s 945us/step - loss: 1.0230 - acc: 0.6071 - val_loss: 1.0787 - val_acc: 0.5711\n",
      "Epoch 87/100\n",
      "934/934 [==============================] - 1s 945us/step - loss: 1.0224 - acc: 0.5996 - val_loss: 1.0925 - val_acc: 0.5686\n",
      "Epoch 88/100\n",
      "934/934 [==============================] - 1s 896us/step - loss: 1.0231 - acc: 0.6081 - val_loss: 1.0851 - val_acc: 0.5736\n",
      "Epoch 89/100\n",
      "934/934 [==============================] - 1s 899us/step - loss: 1.0213 - acc: 0.5931 - val_loss: 1.0784 - val_acc: 0.5736\n",
      "Epoch 90/100\n",
      "934/934 [==============================] - 1s 902us/step - loss: 1.0212 - acc: 0.6071 - val_loss: 1.0772 - val_acc: 0.5786\n",
      "Epoch 91/100\n",
      "934/934 [==============================] - 1s 891us/step - loss: 1.0203 - acc: 0.6071 - val_loss: 1.0789 - val_acc: 0.5786\n",
      "Epoch 92/100\n",
      "934/934 [==============================] - 1s 887us/step - loss: 1.0200 - acc: 0.6124 - val_loss: 1.0806 - val_acc: 0.5910\n",
      "Epoch 93/100\n",
      "934/934 [==============================] - 1s 887us/step - loss: 1.0201 - acc: 0.5996 - val_loss: 1.0836 - val_acc: 0.5761\n",
      "Epoch 94/100\n",
      "934/934 [==============================] - 1s 886us/step - loss: 1.0185 - acc: 0.6060 - val_loss: 1.0816 - val_acc: 0.5835\n",
      "Epoch 95/100\n",
      "934/934 [==============================] - 1s 888us/step - loss: 1.0188 - acc: 0.6124 - val_loss: 1.0797 - val_acc: 0.5761\n",
      "Epoch 96/100\n",
      "934/934 [==============================] - 1s 887us/step - loss: 1.0197 - acc: 0.6103 - val_loss: 1.0826 - val_acc: 0.5835\n",
      "Epoch 97/100\n",
      "934/934 [==============================] - 1s 888us/step - loss: 1.0159 - acc: 0.6146 - val_loss: 1.0814 - val_acc: 0.5810\n",
      "Epoch 98/100\n",
      "934/934 [==============================] - 1s 898us/step - loss: 1.0180 - acc: 0.6049 - val_loss: 1.0838 - val_acc: 0.5736 loss: 1.0219 - acc: 0.604\n",
      "Epoch 99/100\n",
      "934/934 [==============================] - 1s 920us/step - loss: 1.0148 - acc: 0.6146 - val_loss: 1.0882 - val_acc: 0.5786\n",
      "Epoch 100/100\n",
      "934/934 [==============================] - 1s 919us/step - loss: 1.0166 - acc: 0.6178 - val_loss: 1.0778 - val_acc: 0.5810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 401 samples\n",
      "Epoch 1/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.8255 - acc: 0.3330 - val_loss: 1.6403 - val_acc: 0.3666\n",
      "Epoch 2/100\n",
      "934/934 [==============================] - 1s 900us/step - loss: 1.5868 - acc: 0.3876 - val_loss: 1.4970 - val_acc: 0.4439\n",
      "Epoch 3/100\n",
      "934/934 [==============================] - 1s 919us/step - loss: 1.4557 - acc: 0.4540 - val_loss: 1.3850 - val_acc: 0.5162\n",
      "Epoch 4/100\n",
      "934/934 [==============================] - 1s 900us/step - loss: 1.3587 - acc: 0.5075 - val_loss: 1.3060 - val_acc: 0.5636\n",
      "Epoch 5/100\n",
      "934/934 [==============================] - 1s 992us/step - loss: 1.2952 - acc: 0.5343 - val_loss: 1.2578 - val_acc: 0.5337\n",
      "Epoch 6/100\n",
      "934/934 [==============================] - 1s 872us/step - loss: 1.2483 - acc: 0.5535 - val_loss: 1.2251 - val_acc: 0.5411\n",
      "Epoch 7/100\n",
      "934/934 [==============================] - 1s 900us/step - loss: 1.2148 - acc: 0.5675 - val_loss: 1.1914 - val_acc: 0.5611\n",
      "Epoch 8/100\n",
      "934/934 [==============================] - 1s 916us/step - loss: 1.1927 - acc: 0.5567 - val_loss: 1.1744 - val_acc: 0.5511\n",
      "Epoch 9/100\n",
      "934/934 [==============================] - 1s 895us/step - loss: 1.1731 - acc: 0.5621 - val_loss: 1.1603 - val_acc: 0.5561\n",
      "Epoch 10/100\n",
      "934/934 [==============================] - 1s 896us/step - loss: 1.1559 - acc: 0.5600 - val_loss: 1.1468 - val_acc: 0.5561\n",
      "Epoch 11/100\n",
      "934/934 [==============================] - 1s 898us/step - loss: 1.1447 - acc: 0.5664 - val_loss: 1.1433 - val_acc: 0.5461\n",
      "Epoch 12/100\n",
      "934/934 [==============================] - 1s 893us/step - loss: 1.1340 - acc: 0.5696 - val_loss: 1.1322 - val_acc: 0.5536\n",
      "Epoch 13/100\n",
      "934/934 [==============================] - 1s 895us/step - loss: 1.1265 - acc: 0.5675 - val_loss: 1.1247 - val_acc: 0.5636\n",
      "Epoch 14/100\n",
      "934/934 [==============================] - 1s 897us/step - loss: 1.1180 - acc: 0.5803 - val_loss: 1.1179 - val_acc: 0.5711\n",
      "Epoch 15/100\n",
      "934/934 [==============================] - 1s 890us/step - loss: 1.1103 - acc: 0.5664 - val_loss: 1.1143 - val_acc: 0.5686\n",
      "Epoch 16/100\n",
      "934/934 [==============================] - 1s 894us/step - loss: 1.1042 - acc: 0.5846 - val_loss: 1.1150 - val_acc: 0.5586\n",
      "Epoch 17/100\n",
      "934/934 [==============================] - 1s 897us/step - loss: 1.0997 - acc: 0.5857 - val_loss: 1.1160 - val_acc: 0.5686\n",
      "Epoch 18/100\n",
      "934/934 [==============================] - 1s 892us/step - loss: 1.0934 - acc: 0.5846 - val_loss: 1.1043 - val_acc: 0.5761\n",
      "Epoch 19/100\n",
      "934/934 [==============================] - 1s 929us/step - loss: 1.0897 - acc: 0.5824 - val_loss: 1.1005 - val_acc: 0.5910\n",
      "Epoch 20/100\n",
      "934/934 [==============================] - 1s 937us/step - loss: 1.0868 - acc: 0.5910 - val_loss: 1.0969 - val_acc: 0.5786\n",
      "Epoch 21/100\n",
      "934/934 [==============================] - 1s 899us/step - loss: 1.0800 - acc: 0.5910 - val_loss: 1.0950 - val_acc: 0.5860\n",
      "Epoch 22/100\n",
      "934/934 [==============================] - 1s 916us/step - loss: 1.0769 - acc: 0.5910 - val_loss: 1.0975 - val_acc: 0.5835\n",
      "Epoch 23/100\n",
      "934/934 [==============================] - 1s 931us/step - loss: 1.0727 - acc: 0.5910 - val_loss: 1.0928 - val_acc: 0.5985\n",
      "Epoch 24/100\n",
      "934/934 [==============================] - 1s 905us/step - loss: 1.0711 - acc: 0.6049 - val_loss: 1.0862 - val_acc: 0.5910\n",
      "Epoch 25/100\n",
      "934/934 [==============================] - 1s 917us/step - loss: 1.0670 - acc: 0.6028 - val_loss: 1.0851 - val_acc: 0.5810\n",
      "Epoch 26/100\n",
      "934/934 [==============================] - 1s 912us/step - loss: 1.0651 - acc: 0.6060 - val_loss: 1.0842 - val_acc: 0.5835\n",
      "Epoch 27/100\n",
      "934/934 [==============================] - 1s 906us/step - loss: 1.0594 - acc: 0.6006 - val_loss: 1.0944 - val_acc: 0.5711\n",
      "Epoch 28/100\n",
      "934/934 [==============================] - 1s 909us/step - loss: 1.0575 - acc: 0.6006 - val_loss: 1.0823 - val_acc: 0.5960\n",
      "Epoch 29/100\n",
      "934/934 [==============================] - 1s 899us/step - loss: 1.0555 - acc: 0.6039 - val_loss: 1.0779 - val_acc: 0.5835\n",
      "Epoch 30/100\n",
      "934/934 [==============================] - 1s 906us/step - loss: 1.0508 - acc: 0.6017 - val_loss: 1.0818 - val_acc: 0.5835\n",
      "Epoch 31/100\n",
      "934/934 [==============================] - 1s 892us/step - loss: 1.0496 - acc: 0.6028 - val_loss: 1.0757 - val_acc: 0.5835\n",
      "Epoch 32/100\n",
      "934/934 [==============================] - 1s 898us/step - loss: 1.0487 - acc: 0.6060 - val_loss: 1.0742 - val_acc: 0.5910\n",
      "Epoch 33/100\n",
      "934/934 [==============================] - 1s 895us/step - loss: 1.0443 - acc: 0.6135 - val_loss: 1.0780 - val_acc: 0.5860\n",
      "Epoch 34/100\n",
      "934/934 [==============================] - 1s 913us/step - loss: 1.0417 - acc: 0.6113 - val_loss: 1.0973 - val_acc: 0.5387\n",
      "Epoch 35/100\n",
      "934/934 [==============================] - 1s 893us/step - loss: 1.0401 - acc: 0.6039 - val_loss: 1.0758 - val_acc: 0.5835\n",
      "Epoch 36/100\n",
      "934/934 [==============================] - 1s 902us/step - loss: 1.0375 - acc: 0.6103 - val_loss: 1.0817 - val_acc: 0.5835\n",
      "Epoch 37/100\n",
      "934/934 [==============================] - 1s 895us/step - loss: 1.0322 - acc: 0.6017 - val_loss: 1.0685 - val_acc: 0.5985\n",
      "Epoch 38/100\n",
      "934/934 [==============================] - 1s 932us/step - loss: 1.0337 - acc: 0.6039 - val_loss: 1.0709 - val_acc: 0.5810\n",
      "Epoch 39/100\n",
      "934/934 [==============================] - 1s 937us/step - loss: 1.0313 - acc: 0.6210 - val_loss: 1.0745 - val_acc: 0.5910\n",
      "Epoch 40/100\n",
      "934/934 [==============================] - 1s 907us/step - loss: 1.0303 - acc: 0.6060 - val_loss: 1.0632 - val_acc: 0.5985\n",
      "Epoch 41/100\n",
      "934/934 [==============================] - 1s 915us/step - loss: 1.0297 - acc: 0.6049 - val_loss: 1.0651 - val_acc: 0.6010\n",
      "Epoch 42/100\n",
      "934/934 [==============================] - 1s 943us/step - loss: 1.0238 - acc: 0.6188 - val_loss: 1.0734 - val_acc: 0.5910\n",
      "Epoch 43/100\n",
      "934/934 [==============================] - 1s 897us/step - loss: 1.0247 - acc: 0.6103 - val_loss: 1.0722 - val_acc: 0.5810\n",
      "Epoch 44/100\n",
      "934/934 [==============================] - 1s 895us/step - loss: 1.0239 - acc: 0.6124 - val_loss: 1.0681 - val_acc: 0.5910\n",
      "Epoch 45/100\n",
      "934/934 [==============================] - 1s 892us/step - loss: 1.0199 - acc: 0.6146 - val_loss: 1.0608 - val_acc: 0.5960\n",
      "Epoch 46/100\n",
      "934/934 [==============================] - 1s 892us/step - loss: 1.0198 - acc: 0.6156 - val_loss: 1.0618 - val_acc: 0.6010\n",
      "Epoch 47/100\n",
      "934/934 [==============================] - 1s 897us/step - loss: 1.0183 - acc: 0.6135 - val_loss: 1.0576 - val_acc: 0.6010\n",
      "Epoch 48/100\n",
      "934/934 [==============================] - 1s 907us/step - loss: 1.0159 - acc: 0.6210 - val_loss: 1.0727 - val_acc: 0.5636\n",
      "Epoch 49/100\n",
      "934/934 [==============================] - 1s 901us/step - loss: 1.0129 - acc: 0.6199 - val_loss: 1.0562 - val_acc: 0.6085\n",
      "Epoch 50/100\n",
      "934/934 [==============================] - 1s 916us/step - loss: 1.0145 - acc: 0.6188 - val_loss: 1.0561 - val_acc: 0.6035\n",
      "Epoch 51/100\n",
      "934/934 [==============================] - 1s 893us/step - loss: 1.0121 - acc: 0.6178 - val_loss: 1.0624 - val_acc: 0.5960\n",
      "Epoch 52/100\n",
      "934/934 [==============================] - 1s 896us/step - loss: 1.0110 - acc: 0.6156 - val_loss: 1.0519 - val_acc: 0.5985\n",
      "Epoch 53/100\n",
      "934/934 [==============================] - 1s 901us/step - loss: 1.0086 - acc: 0.6188 - val_loss: 1.0569 - val_acc: 0.5960\n",
      "Epoch 54/100\n",
      "934/934 [==============================] - 1s 917us/step - loss: 1.0065 - acc: 0.6167 - val_loss: 1.0587 - val_acc: 0.6035\n",
      "Epoch 55/100\n",
      "934/934 [==============================] - 1s 918us/step - loss: 1.0065 - acc: 0.6263 - val_loss: 1.0530 - val_acc: 0.6035\n",
      "Epoch 56/100\n",
      "934/934 [==============================] - 1s 895us/step - loss: 1.0045 - acc: 0.6231 - val_loss: 1.0525 - val_acc: 0.6035\n",
      "Epoch 57/100\n",
      "934/934 [==============================] - 1s 906us/step - loss: 1.0034 - acc: 0.6263 - val_loss: 1.0564 - val_acc: 0.5985\n",
      "Epoch 58/100\n",
      "934/934 [==============================] - 1s 903us/step - loss: 1.0012 - acc: 0.6221 - val_loss: 1.0494 - val_acc: 0.6060\n",
      "Epoch 59/100\n",
      "934/934 [==============================] - 1s 919us/step - loss: 1.0003 - acc: 0.6210 - val_loss: 1.0531 - val_acc: 0.5985\n",
      "Epoch 60/100\n",
      "934/934 [==============================] - 1s 931us/step - loss: 0.9983 - acc: 0.6092 - val_loss: 1.0473 - val_acc: 0.6035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "934/934 [==============================] - 1s 895us/step - loss: 0.9982 - acc: 0.6221 - val_loss: 1.0587 - val_acc: 0.5910\n",
      "Epoch 62/100\n",
      "934/934 [==============================] - 1s 939us/step - loss: 0.9960 - acc: 0.6221 - val_loss: 1.0518 - val_acc: 0.5860\n",
      "Epoch 63/100\n",
      "934/934 [==============================] - 1s 894us/step - loss: 0.9968 - acc: 0.6146 - val_loss: 1.0512 - val_acc: 0.6110\n",
      "Epoch 64/100\n",
      "934/934 [==============================] - 1s 897us/step - loss: 0.9949 - acc: 0.6146 - val_loss: 1.0441 - val_acc: 0.6035\n",
      "Epoch 65/100\n",
      "934/934 [==============================] - 1s 893us/step - loss: 0.9910 - acc: 0.6253 - val_loss: 1.0475 - val_acc: 0.5960\n",
      "Epoch 66/100\n",
      "934/934 [==============================] - 1s 947us/step - loss: 0.9926 - acc: 0.6253 - val_loss: 1.0515 - val_acc: 0.6010\n",
      "Epoch 67/100\n",
      "934/934 [==============================] - 1s 878us/step - loss: 0.9922 - acc: 0.6317 - val_loss: 1.0484 - val_acc: 0.6085\n",
      "Epoch 68/100\n",
      "934/934 [==============================] - 1s 897us/step - loss: 0.9906 - acc: 0.6274 - val_loss: 1.0549 - val_acc: 0.5910\n",
      "Epoch 69/100\n",
      "934/934 [==============================] - 1s 904us/step - loss: 0.9890 - acc: 0.6274 - val_loss: 1.0504 - val_acc: 0.5935\n",
      "Epoch 70/100\n",
      "934/934 [==============================] - 1s 905us/step - loss: 0.9867 - acc: 0.6221 - val_loss: 1.0514 - val_acc: 0.5910\n",
      "Epoch 71/100\n",
      "934/934 [==============================] - 1s 896us/step - loss: 0.9851 - acc: 0.6210 - val_loss: 1.0628 - val_acc: 0.5736\n",
      "Epoch 72/100\n",
      "934/934 [==============================] - 1s 896us/step - loss: 0.9860 - acc: 0.6188 - val_loss: 1.0458 - val_acc: 0.5885\n",
      "Epoch 73/100\n",
      "934/934 [==============================] - 1s 894us/step - loss: 0.9858 - acc: 0.6242 - val_loss: 1.0457 - val_acc: 0.6035\n",
      "Epoch 74/100\n",
      "934/934 [==============================] - 1s 941us/step - loss: 0.9837 - acc: 0.6221 - val_loss: 1.0436 - val_acc: 0.5985\n",
      "Epoch 75/100\n",
      "934/934 [==============================] - 1s 903us/step - loss: 0.9847 - acc: 0.6285 - val_loss: 1.0404 - val_acc: 0.5985\n",
      "Epoch 76/100\n",
      "934/934 [==============================] - 1s 897us/step - loss: 0.9844 - acc: 0.6306 - val_loss: 1.0399 - val_acc: 0.5935: 0s - loss: 0.9829 - acc: 0.633\n",
      "Epoch 77/100\n",
      "934/934 [==============================] - 1s 896us/step - loss: 0.9828 - acc: 0.6296 - val_loss: 1.0411 - val_acc: 0.5960\n",
      "Epoch 78/100\n",
      "934/934 [==============================] - 1s 894us/step - loss: 0.9800 - acc: 0.6424 - val_loss: 1.0473 - val_acc: 0.5985\n",
      "Epoch 79/100\n",
      "934/934 [==============================] - 1s 895us/step - loss: 0.9799 - acc: 0.6296 - val_loss: 1.0489 - val_acc: 0.5860\n",
      "Epoch 80/100\n",
      "934/934 [==============================] - 1s 891us/step - loss: 0.9809 - acc: 0.6210 - val_loss: 1.0444 - val_acc: 0.6160\n",
      "Epoch 81/100\n",
      "934/934 [==============================] - 1s 896us/step - loss: 0.9794 - acc: 0.6221 - val_loss: 1.0471 - val_acc: 0.5885\n",
      "Epoch 82/100\n",
      "934/934 [==============================] - 1s 895us/step - loss: 0.9728 - acc: 0.6263 - val_loss: 1.0439 - val_acc: 0.6035\n",
      "Epoch 83/100\n",
      "934/934 [==============================] - 1s 896us/step - loss: 0.9771 - acc: 0.6285 - val_loss: 1.0450 - val_acc: 0.5935\n",
      "Epoch 84/100\n",
      "934/934 [==============================] - 1s 890us/step - loss: 0.9779 - acc: 0.6274 - val_loss: 1.0441 - val_acc: 0.6110\n",
      "Epoch 85/100\n",
      "934/934 [==============================] - 1s 893us/step - loss: 0.9751 - acc: 0.6328 - val_loss: 1.0392 - val_acc: 0.6110\n",
      "Epoch 86/100\n",
      "934/934 [==============================] - 1s 904us/step - loss: 0.9750 - acc: 0.6221 - val_loss: 1.0426 - val_acc: 0.5985\n",
      "Epoch 87/100\n",
      "934/934 [==============================] - 1s 922us/step - loss: 0.9747 - acc: 0.6349 - val_loss: 1.0421 - val_acc: 0.5960\n",
      "Epoch 88/100\n",
      "934/934 [==============================] - 1s 895us/step - loss: 0.9748 - acc: 0.6370 - val_loss: 1.0409 - val_acc: 0.6060\n",
      "Epoch 89/100\n",
      "934/934 [==============================] - 1s 896us/step - loss: 0.9743 - acc: 0.6210 - val_loss: 1.0372 - val_acc: 0.5910\n",
      "Epoch 90/100\n",
      "934/934 [==============================] - 1s 928us/step - loss: 0.9728 - acc: 0.6285 - val_loss: 1.0365 - val_acc: 0.6035\n",
      "Epoch 91/100\n",
      "934/934 [==============================] - 1s 897us/step - loss: 0.9737 - acc: 0.6231 - val_loss: 1.0365 - val_acc: 0.5935\n",
      "Epoch 92/100\n",
      "934/934 [==============================] - 1s 897us/step - loss: 0.9710 - acc: 0.6381 - val_loss: 1.0494 - val_acc: 0.5860\n",
      "Epoch 93/100\n",
      "934/934 [==============================] - 1s 899us/step - loss: 0.9686 - acc: 0.6424 - val_loss: 1.0495 - val_acc: 0.6060\n",
      "Epoch 94/100\n",
      "934/934 [==============================] - 1s 904us/step - loss: 0.9693 - acc: 0.6392 - val_loss: 1.0637 - val_acc: 0.5636\n",
      "Epoch 95/100\n",
      "934/934 [==============================] - 1s 899us/step - loss: 0.9663 - acc: 0.6274 - val_loss: 1.0444 - val_acc: 0.5960\n",
      "Epoch 96/100\n",
      "934/934 [==============================] - 1s 896us/step - loss: 0.9695 - acc: 0.6285 - val_loss: 1.0359 - val_acc: 0.6010\n",
      "Epoch 97/100\n",
      "934/934 [==============================] - 1s 893us/step - loss: 0.9697 - acc: 0.6338 - val_loss: 1.0398 - val_acc: 0.6010\n",
      "Epoch 98/100\n",
      "934/934 [==============================] - 1s 893us/step - loss: 0.9672 - acc: 0.6231 - val_loss: 1.0525 - val_acc: 0.5810\n",
      "Epoch 99/100\n",
      "934/934 [==============================] - 1s 921us/step - loss: 0.9676 - acc: 0.6328 - val_loss: 1.0378 - val_acc: 0.5960\n",
      "Epoch 100/100\n",
      "934/934 [==============================] - 1s 874us/step - loss: 0.9667 - acc: 0.6360 - val_loss: 1.0363 - val_acc: 0.6110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 401 samples\n",
      "Epoch 1/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.7958 - acc: 0.3158 - val_loss: 1.5787 - val_acc: 0.3491\n",
      "Epoch 2/100\n",
      "934/934 [==============================] - 1s 982us/step - loss: 1.5190 - acc: 0.4368 - val_loss: 1.4223 - val_acc: 0.4763\n",
      "Epoch 3/100\n",
      "934/934 [==============================] - 1s 985us/step - loss: 1.3977 - acc: 0.4936 - val_loss: 1.3210 - val_acc: 0.5387\n",
      "Epoch 4/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3110 - acc: 0.5225 - val_loss: 1.2682 - val_acc: 0.5162\n",
      "Epoch 5/100\n",
      "934/934 [==============================] - 1s 958us/step - loss: 1.2558 - acc: 0.5353 - val_loss: 1.2162 - val_acc: 0.5362\n",
      "Epoch 6/100\n",
      "934/934 [==============================] - 1s 931us/step - loss: 1.2141 - acc: 0.5460 - val_loss: 1.1921 - val_acc: 0.5387\n",
      "Epoch 7/100\n",
      "934/934 [==============================] - 1s 899us/step - loss: 1.1865 - acc: 0.5578 - val_loss: 1.1672 - val_acc: 0.5436\n",
      "Epoch 8/100\n",
      "934/934 [==============================] - 1s 888us/step - loss: 1.1597 - acc: 0.5653 - val_loss: 1.1593 - val_acc: 0.5436\n",
      "Epoch 9/100\n",
      "934/934 [==============================] - 1s 908us/step - loss: 1.1472 - acc: 0.5749 - val_loss: 1.1450 - val_acc: 0.5312\n",
      "Epoch 10/100\n",
      "934/934 [==============================] - 1s 924us/step - loss: 1.1318 - acc: 0.5782 - val_loss: 1.1321 - val_acc: 0.5536\n",
      "Epoch 11/100\n",
      "934/934 [==============================] - 1s 938us/step - loss: 1.1202 - acc: 0.5760 - val_loss: 1.1248 - val_acc: 0.5536\n",
      "Epoch 12/100\n",
      "934/934 [==============================] - 1s 920us/step - loss: 1.1114 - acc: 0.5846 - val_loss: 1.1150 - val_acc: 0.5686\n",
      "Epoch 13/100\n",
      "934/934 [==============================] - 1s 919us/step - loss: 1.1025 - acc: 0.5867 - val_loss: 1.1114 - val_acc: 0.5636\n",
      "Epoch 14/100\n",
      "934/934 [==============================] - 1s 920us/step - loss: 1.0949 - acc: 0.5889 - val_loss: 1.1075 - val_acc: 0.5711\n",
      "Epoch 15/100\n",
      "934/934 [==============================] - 1s 920us/step - loss: 1.0873 - acc: 0.5942 - val_loss: 1.1108 - val_acc: 0.5561\n",
      "Epoch 16/100\n",
      "934/934 [==============================] - 1s 926us/step - loss: 1.0804 - acc: 0.5985 - val_loss: 1.1143 - val_acc: 0.5536\n",
      "Epoch 17/100\n",
      "934/934 [==============================] - 1s 909us/step - loss: 1.0741 - acc: 0.6017 - val_loss: 1.1073 - val_acc: 0.5337\n",
      "Epoch 18/100\n",
      "934/934 [==============================] - 1s 915us/step - loss: 1.0709 - acc: 0.5964 - val_loss: 1.0922 - val_acc: 0.5736\n",
      "Epoch 19/100\n",
      "934/934 [==============================] - 1s 916us/step - loss: 1.0679 - acc: 0.5996 - val_loss: 1.0905 - val_acc: 0.5686\n",
      "Epoch 20/100\n",
      "934/934 [==============================] - 1s 910us/step - loss: 1.0601 - acc: 0.5921 - val_loss: 1.0839 - val_acc: 0.5860\n",
      "Epoch 21/100\n",
      "934/934 [==============================] - 1s 909us/step - loss: 1.0562 - acc: 0.6060 - val_loss: 1.0889 - val_acc: 0.5661\n",
      "Epoch 22/100\n",
      "934/934 [==============================] - 1s 914us/step - loss: 1.0528 - acc: 0.6006 - val_loss: 1.0804 - val_acc: 0.5810\n",
      "Epoch 23/100\n",
      "934/934 [==============================] - 1s 919us/step - loss: 1.0488 - acc: 0.5974 - val_loss: 1.0784 - val_acc: 0.5810\n",
      "Epoch 24/100\n",
      "934/934 [==============================] - 1s 921us/step - loss: 1.0472 - acc: 0.5942 - val_loss: 1.0801 - val_acc: 0.5786\n",
      "Epoch 25/100\n",
      "934/934 [==============================] - 1s 908us/step - loss: 1.0448 - acc: 0.5953 - val_loss: 1.0797 - val_acc: 0.5736\n",
      "Epoch 26/100\n",
      "934/934 [==============================] - 1s 914us/step - loss: 1.0415 - acc: 0.5985 - val_loss: 1.0834 - val_acc: 0.5661\n",
      "Epoch 27/100\n",
      "934/934 [==============================] - 1s 906us/step - loss: 1.0387 - acc: 0.6103 - val_loss: 1.0691 - val_acc: 0.5910\n",
      "Epoch 28/100\n",
      "934/934 [==============================] - 1s 912us/step - loss: 1.0372 - acc: 0.5974 - val_loss: 1.0675 - val_acc: 0.5786\n",
      "Epoch 29/100\n",
      "934/934 [==============================] - 1s 922us/step - loss: 1.0348 - acc: 0.6006 - val_loss: 1.0666 - val_acc: 0.5860\n",
      "Epoch 30/100\n",
      "934/934 [==============================] - 1s 919us/step - loss: 1.0318 - acc: 0.6039 - val_loss: 1.0613 - val_acc: 0.5860\n",
      "Epoch 31/100\n",
      "934/934 [==============================] - 1s 916us/step - loss: 1.0313 - acc: 0.6006 - val_loss: 1.0614 - val_acc: 0.5786\n",
      "Epoch 32/100\n",
      "934/934 [==============================] - 1s 919us/step - loss: 1.0275 - acc: 0.6081 - val_loss: 1.0615 - val_acc: 0.5835\n",
      "Epoch 33/100\n",
      "934/934 [==============================] - 1s 908us/step - loss: 1.0216 - acc: 0.6039 - val_loss: 1.0861 - val_acc: 0.5636\n",
      "Epoch 34/100\n",
      "934/934 [==============================] - 1s 918us/step - loss: 1.0250 - acc: 0.6071 - val_loss: 1.0656 - val_acc: 0.5786\n",
      "Epoch 35/100\n",
      "934/934 [==============================] - 1s 922us/step - loss: 1.0227 - acc: 0.5996 - val_loss: 1.0539 - val_acc: 0.5910\n",
      "Epoch 36/100\n",
      "934/934 [==============================] - 1s 914us/step - loss: 1.0184 - acc: 0.6103 - val_loss: 1.0686 - val_acc: 0.5586\n",
      "Epoch 37/100\n",
      "934/934 [==============================] - 1s 914us/step - loss: 1.0190 - acc: 0.6188 - val_loss: 1.0608 - val_acc: 0.5711\n",
      "Epoch 38/100\n",
      "934/934 [==============================] - 1s 911us/step - loss: 1.0168 - acc: 0.6092 - val_loss: 1.0592 - val_acc: 0.5835\n",
      "Epoch 39/100\n",
      "934/934 [==============================] - 1s 906us/step - loss: 1.0138 - acc: 0.6188 - val_loss: 1.0495 - val_acc: 0.5786\n",
      "Epoch 40/100\n",
      "934/934 [==============================] - 1s 916us/step - loss: 1.0135 - acc: 0.6124 - val_loss: 1.0551 - val_acc: 0.5761\n",
      "Epoch 41/100\n",
      "934/934 [==============================] - 1s 910us/step - loss: 1.0118 - acc: 0.6135 - val_loss: 1.0536 - val_acc: 0.5686\n",
      "Epoch 42/100\n",
      "934/934 [==============================] - 1s 904us/step - loss: 1.0064 - acc: 0.6146 - val_loss: 1.0659 - val_acc: 0.5586\n",
      "Epoch 43/100\n",
      "934/934 [==============================] - 1s 903us/step - loss: 1.0102 - acc: 0.6221 - val_loss: 1.0541 - val_acc: 0.5636\n",
      "Epoch 44/100\n",
      "934/934 [==============================] - 1s 907us/step - loss: 1.0071 - acc: 0.6242 - val_loss: 1.0469 - val_acc: 0.5935\n",
      "Epoch 45/100\n",
      "934/934 [==============================] - 1s 908us/step - loss: 1.0050 - acc: 0.6156 - val_loss: 1.0462 - val_acc: 0.5910: 0s - loss: 1.0040 - acc: 0. - ETA: 0s - loss: 1.0157 - acc: 0.61\n",
      "Epoch 46/100\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.0032 - acc: 0.6092 - val_loss: 1.0522 - val_acc: 0.5736\n",
      "Epoch 47/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.0046 - acc: 0.6263 - val_loss: 1.0410 - val_acc: 0.5686\n",
      "Epoch 48/100\n",
      "934/934 [==============================] - 1s 958us/step - loss: 1.0018 - acc: 0.6242 - val_loss: 1.0513 - val_acc: 0.5636\n",
      "Epoch 49/100\n",
      "934/934 [==============================] - 1s 941us/step - loss: 1.0020 - acc: 0.6306 - val_loss: 1.0462 - val_acc: 0.5711\n",
      "Epoch 50/100\n",
      "934/934 [==============================] - 1s 922us/step - loss: 0.9997 - acc: 0.6146 - val_loss: 1.0394 - val_acc: 0.5885\n",
      "Epoch 51/100\n",
      "934/934 [==============================] - 1s 906us/step - loss: 0.9989 - acc: 0.6146 - val_loss: 1.0389 - val_acc: 0.5711\n",
      "Epoch 52/100\n",
      "934/934 [==============================] - 1s 913us/step - loss: 0.9955 - acc: 0.6135 - val_loss: 1.0375 - val_acc: 0.5736\n",
      "Epoch 53/100\n",
      "934/934 [==============================] - 1s 918us/step - loss: 0.9974 - acc: 0.6103 - val_loss: 1.0376 - val_acc: 0.5711\n",
      "Epoch 54/100\n",
      "934/934 [==============================] - 1s 906us/step - loss: 0.9944 - acc: 0.6296 - val_loss: 1.0388 - val_acc: 0.5736\n",
      "Epoch 55/100\n",
      "934/934 [==============================] - 1s 927us/step - loss: 0.9920 - acc: 0.6242 - val_loss: 1.0423 - val_acc: 0.5661\n",
      "Epoch 56/100\n",
      "934/934 [==============================] - 1s 930us/step - loss: 0.9919 - acc: 0.6210 - val_loss: 1.0337 - val_acc: 0.5835\n",
      "Epoch 57/100\n",
      "934/934 [==============================] - 1s 914us/step - loss: 0.9907 - acc: 0.6242 - val_loss: 1.0353 - val_acc: 0.5661\n",
      "Epoch 58/100\n",
      "934/934 [==============================] - 1s 914us/step - loss: 0.9908 - acc: 0.6221 - val_loss: 1.0382 - val_acc: 0.5711\n",
      "Epoch 59/100\n",
      "934/934 [==============================] - 1s 913us/step - loss: 0.9833 - acc: 0.6317 - val_loss: 1.0360 - val_acc: 0.5736\n",
      "Epoch 60/100\n",
      "934/934 [==============================] - 1s 912us/step - loss: 0.9864 - acc: 0.6317 - val_loss: 1.0325 - val_acc: 0.5761\n",
      "Epoch 61/100\n",
      "934/934 [==============================] - 1s 906us/step - loss: 0.9861 - acc: 0.6221 - val_loss: 1.0352 - val_acc: 0.5761\n",
      "Epoch 62/100\n",
      "934/934 [==============================] - 1s 950us/step - loss: 0.9833 - acc: 0.6178 - val_loss: 1.0385 - val_acc: 0.5810\n",
      "Epoch 63/100\n",
      "934/934 [==============================] - 1s 909us/step - loss: 0.9851 - acc: 0.6253 - val_loss: 1.0345 - val_acc: 0.5736\n",
      "Epoch 64/100\n",
      "934/934 [==============================] - 1s 909us/step - loss: 0.9825 - acc: 0.6253 - val_loss: 1.0301 - val_acc: 0.5885\n",
      "Epoch 65/100\n",
      "934/934 [==============================] - 1s 931us/step - loss: 0.9821 - acc: 0.6317 - val_loss: 1.0368 - val_acc: 0.5960\n",
      "Epoch 66/100\n",
      "934/934 [==============================] - 1s 915us/step - loss: 0.9818 - acc: 0.6360 - val_loss: 1.0304 - val_acc: 0.5686\n",
      "Epoch 67/100\n",
      "934/934 [==============================] - 1s 922us/step - loss: 0.9787 - acc: 0.6296 - val_loss: 1.0258 - val_acc: 0.5885\n",
      "Epoch 68/100\n",
      "934/934 [==============================] - 1s 912us/step - loss: 0.9793 - acc: 0.6221 - val_loss: 1.0256 - val_acc: 0.5885\n",
      "Epoch 69/100\n",
      "934/934 [==============================] - 1s 910us/step - loss: 0.9785 - acc: 0.6231 - val_loss: 1.0257 - val_acc: 0.5860\n",
      "Epoch 70/100\n",
      "934/934 [==============================] - 1s 905us/step - loss: 0.9764 - acc: 0.6274 - val_loss: 1.0356 - val_acc: 0.5761\n",
      "Epoch 71/100\n",
      "934/934 [==============================] - 1s 907us/step - loss: 0.9769 - acc: 0.6392 - val_loss: 1.0298 - val_acc: 0.5810\n",
      "Epoch 72/100\n",
      "934/934 [==============================] - 1s 914us/step - loss: 0.9760 - acc: 0.6306 - val_loss: 1.0345 - val_acc: 0.5786\n",
      "Epoch 73/100\n",
      "934/934 [==============================] - 1s 915us/step - loss: 0.9726 - acc: 0.6370 - val_loss: 1.0366 - val_acc: 0.5810\n",
      "Epoch 74/100\n",
      "934/934 [==============================] - 1s 914us/step - loss: 0.9747 - acc: 0.6296 - val_loss: 1.0243 - val_acc: 0.5860\n",
      "Epoch 75/100\n",
      "934/934 [==============================] - 1s 901us/step - loss: 0.9719 - acc: 0.6338 - val_loss: 1.0245 - val_acc: 0.5960\n",
      "Epoch 76/100\n",
      "934/934 [==============================] - 1s 896us/step - loss: 0.9727 - acc: 0.6381 - val_loss: 1.0325 - val_acc: 0.5686\n",
      "Epoch 77/100\n",
      "934/934 [==============================] - 1s 925us/step - loss: 0.9708 - acc: 0.6231 - val_loss: 1.0249 - val_acc: 0.5786\n",
      "Epoch 78/100\n",
      "934/934 [==============================] - 1s 941us/step - loss: 0.9690 - acc: 0.6349 - val_loss: 1.0291 - val_acc: 0.5860\n",
      "Epoch 79/100\n",
      "934/934 [==============================] - 1s 925us/step - loss: 0.9662 - acc: 0.6285 - val_loss: 1.0205 - val_acc: 0.5935\n",
      "Epoch 80/100\n",
      "934/934 [==============================] - 1s 921us/step - loss: 0.9680 - acc: 0.6328 - val_loss: 1.0231 - val_acc: 0.5835\n",
      "Epoch 81/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9680 - acc: 0.6370 - val_loss: 1.0247 - val_acc: 0.5835\n",
      "Epoch 82/100\n",
      "934/934 [==============================] - 1s 907us/step - loss: 0.9618 - acc: 0.6253 - val_loss: 1.0538 - val_acc: 0.5736\n",
      "Epoch 83/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9620 - acc: 0.6338 - val_loss: 1.0243 - val_acc: 0.5860\n",
      "Epoch 84/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9643 - acc: 0.6392 - val_loss: 1.0234 - val_acc: 0.5761\n",
      "Epoch 85/100\n",
      "934/934 [==============================] - 1s 969us/step - loss: 0.9627 - acc: 0.6403 - val_loss: 1.0227 - val_acc: 0.5761\n",
      "Epoch 86/100\n",
      "934/934 [==============================] - 1s 996us/step - loss: 0.9610 - acc: 0.6338 - val_loss: 1.0270 - val_acc: 0.5985\n",
      "Epoch 87/100\n",
      "934/934 [==============================] - 1s 891us/step - loss: 0.9623 - acc: 0.6338 - val_loss: 1.0172 - val_acc: 0.5835\n",
      "Epoch 88/100\n",
      "934/934 [==============================] - 1s 891us/step - loss: 0.9594 - acc: 0.6328 - val_loss: 1.0208 - val_acc: 0.5885\n",
      "Epoch 89/100\n",
      "934/934 [==============================] - 1s 890us/step - loss: 0.9580 - acc: 0.6381 - val_loss: 1.0169 - val_acc: 0.6010\n",
      "Epoch 90/100\n",
      "934/934 [==============================] - 1s 886us/step - loss: 0.9598 - acc: 0.6370 - val_loss: 1.0256 - val_acc: 0.5736\n",
      "Epoch 91/100\n",
      "934/934 [==============================] - 1s 894us/step - loss: 0.9576 - acc: 0.6424 - val_loss: 1.0320 - val_acc: 0.5860\n",
      "Epoch 92/100\n",
      "934/934 [==============================] - 1s 889us/step - loss: 0.9564 - acc: 0.6478 - val_loss: 1.0220 - val_acc: 0.5860\n",
      "Epoch 93/100\n",
      "934/934 [==============================] - 1s 889us/step - loss: 0.9582 - acc: 0.6381 - val_loss: 1.0178 - val_acc: 0.5960\n",
      "Epoch 94/100\n",
      "934/934 [==============================] - 1s 897us/step - loss: 0.9530 - acc: 0.6478 - val_loss: 1.0289 - val_acc: 0.6010\n",
      "Epoch 95/100\n",
      "934/934 [==============================] - 1s 912us/step - loss: 0.9559 - acc: 0.6306 - val_loss: 1.0241 - val_acc: 0.5910\n",
      "Epoch 96/100\n",
      "934/934 [==============================] - 1s 916us/step - loss: 0.9542 - acc: 0.6370 - val_loss: 1.0186 - val_acc: 0.5910\n",
      "Epoch 97/100\n",
      "934/934 [==============================] - 1s 939us/step - loss: 0.9542 - acc: 0.6499 - val_loss: 1.0241 - val_acc: 0.5885\n",
      "Epoch 98/100\n",
      "934/934 [==============================] - 1s 889us/step - loss: 0.9500 - acc: 0.6467 - val_loss: 1.0206 - val_acc: 0.5960\n",
      "Epoch 99/100\n",
      "934/934 [==============================] - 1s 889us/step - loss: 0.9477 - acc: 0.6467 - val_loss: 1.0145 - val_acc: 0.6035\n",
      "Epoch 100/100\n",
      "934/934 [==============================] - 1s 885us/step - loss: 0.9498 - acc: 0.6413 - val_loss: 1.0173 - val_acc: 0.5960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 401 samples\n",
      "Epoch 1/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.8949 - acc: 0.3073 - val_loss: 1.7455 - val_acc: 0.3292\n",
      "Epoch 2/100\n",
      "934/934 [==============================] - 1s 934us/step - loss: 1.7363 - acc: 0.3255 - val_loss: 1.7073 - val_acc: 0.3392\n",
      "Epoch 3/100\n",
      "934/934 [==============================] - 1s 936us/step - loss: 1.7150 - acc: 0.3448 - val_loss: 1.6943 - val_acc: 0.3766\n",
      "Epoch 4/100\n",
      "934/934 [==============================] - 1s 936us/step - loss: 1.7041 - acc: 0.3448 - val_loss: 1.6876 - val_acc: 0.3292\n",
      "Epoch 5/100\n",
      "934/934 [==============================] - 1s 951us/step - loss: 1.6933 - acc: 0.3522 - val_loss: 1.6720 - val_acc: 0.3441\n",
      "Epoch 6/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6806 - acc: 0.3469 - val_loss: 1.6608 - val_acc: 0.3666\n",
      "Epoch 7/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6651 - acc: 0.3576 - val_loss: 1.6403 - val_acc: 0.3416\n",
      "Epoch 8/100\n",
      "934/934 [==============================] - 1s 985us/step - loss: 1.6482 - acc: 0.3533 - val_loss: 1.6242 - val_acc: 0.3890\n",
      "Epoch 9/100\n",
      "934/934 [==============================] - 1s 943us/step - loss: 1.6272 - acc: 0.3812 - val_loss: 1.6030 - val_acc: 0.3716\n",
      "Epoch 10/100\n",
      "934/934 [==============================] - 1s 938us/step - loss: 1.6023 - acc: 0.3812 - val_loss: 1.5754 - val_acc: 0.3641\n",
      "Epoch 11/100\n",
      "934/934 [==============================] - 1s 935us/step - loss: 1.5765 - acc: 0.3694 - val_loss: 1.5489 - val_acc: 0.3766\n",
      "Epoch 12/100\n",
      "934/934 [==============================] - 1s 934us/step - loss: 1.5482 - acc: 0.3833 - val_loss: 1.5183 - val_acc: 0.3691\n",
      "Epoch 13/100\n",
      "934/934 [==============================] - 1s 945us/step - loss: 1.5170 - acc: 0.3844 - val_loss: 1.4898 - val_acc: 0.3466\n",
      "Epoch 14/100\n",
      "934/934 [==============================] - 1s 935us/step - loss: 1.4862 - acc: 0.4111 - val_loss: 1.4555 - val_acc: 0.4090\n",
      "Epoch 15/100\n",
      "934/934 [==============================] - 1s 934us/step - loss: 1.4544 - acc: 0.4251 - val_loss: 1.4297 - val_acc: 0.4190\n",
      "Epoch 16/100\n",
      "934/934 [==============================] - 1s 940us/step - loss: 1.4249 - acc: 0.4422 - val_loss: 1.3997 - val_acc: 0.4389\n",
      "Epoch 17/100\n",
      "934/934 [==============================] - 1s 937us/step - loss: 1.3961 - acc: 0.4732 - val_loss: 1.3743 - val_acc: 0.4464\n",
      "Epoch 18/100\n",
      "934/934 [==============================] - 1s 949us/step - loss: 1.3724 - acc: 0.4979 - val_loss: 1.3553 - val_acc: 0.4788\n",
      "Epoch 19/100\n",
      "934/934 [==============================] - 1s 944us/step - loss: 1.3501 - acc: 0.5086 - val_loss: 1.3345 - val_acc: 0.4863\n",
      "Epoch 20/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3304 - acc: 0.5161 - val_loss: 1.3166 - val_acc: 0.4863\n",
      "Epoch 21/100\n",
      "934/934 [==============================] - 1s 945us/step - loss: 1.3151 - acc: 0.5193 - val_loss: 1.3030 - val_acc: 0.4838\n",
      "Epoch 22/100\n",
      "934/934 [==============================] - 1s 946us/step - loss: 1.3004 - acc: 0.5193 - val_loss: 1.2961 - val_acc: 0.4963\n",
      "Epoch 23/100\n",
      "934/934 [==============================] - 1s 950us/step - loss: 1.2888 - acc: 0.5128 - val_loss: 1.2848 - val_acc: 0.4888\n",
      "Epoch 24/100\n",
      "934/934 [==============================] - 1s 961us/step - loss: 1.2793 - acc: 0.5118 - val_loss: 1.2727 - val_acc: 0.4888\n",
      "Epoch 25/100\n",
      "934/934 [==============================] - 1s 950us/step - loss: 1.2695 - acc: 0.5107 - val_loss: 1.2660 - val_acc: 0.4888\n",
      "Epoch 26/100\n",
      "934/934 [==============================] - 1s 955us/step - loss: 1.2597 - acc: 0.5310 - val_loss: 1.2668 - val_acc: 0.4963\n",
      "Epoch 27/100\n",
      "934/934 [==============================] - 1s 956us/step - loss: 1.2530 - acc: 0.5150 - val_loss: 1.2544 - val_acc: 0.5062\n",
      "Epoch 28/100\n",
      "934/934 [==============================] - 1s 959us/step - loss: 1.2484 - acc: 0.5236 - val_loss: 1.2474 - val_acc: 0.4913\n",
      "Epoch 29/100\n",
      "934/934 [==============================] - 1s 967us/step - loss: 1.2423 - acc: 0.5300 - val_loss: 1.2429 - val_acc: 0.4913\n",
      "Epoch 30/100\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.2370 - acc: 0.5193 - val_loss: 1.2408 - val_acc: 0.5237\n",
      "Epoch 31/100\n",
      "934/934 [==============================] - 1s 964us/step - loss: 1.2294 - acc: 0.5332 - val_loss: 1.2394 - val_acc: 0.5062\n",
      "Epoch 32/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.2247 - acc: 0.5332 - val_loss: 1.2337 - val_acc: 0.5137\n",
      "Epoch 33/100\n",
      "934/934 [==============================] - 1s 964us/step - loss: 1.2203 - acc: 0.5278 - val_loss: 1.2267 - val_acc: 0.5262\n",
      "Epoch 34/100\n",
      "934/934 [==============================] - 1s 953us/step - loss: 1.2151 - acc: 0.5343 - val_loss: 1.2197 - val_acc: 0.5237\n",
      "Epoch 35/100\n",
      "934/934 [==============================] - 1s 949us/step - loss: 1.2125 - acc: 0.5343 - val_loss: 1.2231 - val_acc: 0.5287\n",
      "Epoch 36/100\n",
      "934/934 [==============================] - 1s 947us/step - loss: 1.2079 - acc: 0.5364 - val_loss: 1.2171 - val_acc: 0.5362\n",
      "Epoch 37/100\n",
      "934/934 [==============================] - 1s 951us/step - loss: 1.2052 - acc: 0.5332 - val_loss: 1.2125 - val_acc: 0.5237\n",
      "Epoch 38/100\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.1997 - acc: 0.5418 - val_loss: 1.2055 - val_acc: 0.5337\n",
      "Epoch 39/100\n",
      "934/934 [==============================] - 1s 964us/step - loss: 1.1955 - acc: 0.5300 - val_loss: 1.2047 - val_acc: 0.5237\n",
      "Epoch 40/100\n",
      "934/934 [==============================] - 1s 944us/step - loss: 1.1927 - acc: 0.5482 - val_loss: 1.1998 - val_acc: 0.5362\n",
      "Epoch 41/100\n",
      "934/934 [==============================] - 1s 950us/step - loss: 1.1873 - acc: 0.5535 - val_loss: 1.1991 - val_acc: 0.5237\n",
      "Epoch 42/100\n",
      "934/934 [==============================] - 1s 956us/step - loss: 1.1844 - acc: 0.5460 - val_loss: 1.1994 - val_acc: 0.5187\n",
      "Epoch 43/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.1810 - acc: 0.5535 - val_loss: 1.1938 - val_acc: 0.5312\n",
      "Epoch 44/100\n",
      "934/934 [==============================] - 1s 954us/step - loss: 1.1768 - acc: 0.5503 - val_loss: 1.1837 - val_acc: 0.5312\n",
      "Epoch 45/100\n",
      "934/934 [==============================] - 1s 950us/step - loss: 1.1716 - acc: 0.5610 - val_loss: 1.1842 - val_acc: 0.5237\n",
      "Epoch 46/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.1720 - acc: 0.5610 - val_loss: 1.1788 - val_acc: 0.5337\n",
      "Epoch 47/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.1658 - acc: 0.5685 - val_loss: 1.1704 - val_acc: 0.5411\n",
      "Epoch 48/100\n",
      "934/934 [==============================] - 1s 955us/step - loss: 1.1633 - acc: 0.5653 - val_loss: 1.1684 - val_acc: 0.5411\n",
      "Epoch 49/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.1607 - acc: 0.5664 - val_loss: 1.1725 - val_acc: 0.5112\n",
      "Epoch 50/100\n",
      "934/934 [==============================] - 1s 958us/step - loss: 1.1573 - acc: 0.5760 - val_loss: 1.1648 - val_acc: 0.5162\n",
      "Epoch 51/100\n",
      "934/934 [==============================] - 1s 951us/step - loss: 1.1526 - acc: 0.5717 - val_loss: 1.1696 - val_acc: 0.5212\n",
      "Epoch 52/100\n",
      "934/934 [==============================] - 1s 935us/step - loss: 1.1513 - acc: 0.5824 - val_loss: 1.1629 - val_acc: 0.5237\n",
      "Epoch 53/100\n",
      "934/934 [==============================] - 1s 936us/step - loss: 1.1472 - acc: 0.5707 - val_loss: 1.1498 - val_acc: 0.5312\n",
      "Epoch 54/100\n",
      "934/934 [==============================] - 1s 931us/step - loss: 1.1459 - acc: 0.5878 - val_loss: 1.1559 - val_acc: 0.5087\n",
      "Epoch 55/100\n",
      "934/934 [==============================] - 1s 942us/step - loss: 1.1406 - acc: 0.5760 - val_loss: 1.1429 - val_acc: 0.5511\n",
      "Epoch 56/100\n",
      "934/934 [==============================] - 1s 939us/step - loss: 1.1408 - acc: 0.5846 - val_loss: 1.1439 - val_acc: 0.5362\n",
      "Epoch 57/100\n",
      "934/934 [==============================] - 1s 955us/step - loss: 1.1360 - acc: 0.5910 - val_loss: 1.1421 - val_acc: 0.5387\n",
      "Epoch 58/100\n",
      "934/934 [==============================] - 1s 956us/step - loss: 1.1359 - acc: 0.5878 - val_loss: 1.1390 - val_acc: 0.5312\n",
      "Epoch 59/100\n",
      "934/934 [==============================] - 1s 940us/step - loss: 1.1340 - acc: 0.5814 - val_loss: 1.1407 - val_acc: 0.5362\n",
      "Epoch 60/100\n",
      "934/934 [==============================] - 1s 942us/step - loss: 1.1323 - acc: 0.5857 - val_loss: 1.1440 - val_acc: 0.5237\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934/934 [==============================] - 1s 936us/step - loss: 1.1311 - acc: 0.5878 - val_loss: 1.1328 - val_acc: 0.5436\n",
      "Epoch 62/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.1296 - acc: 0.5867 - val_loss: 1.1313 - val_acc: 0.5586\n",
      "Epoch 63/100\n",
      "934/934 [==============================] - 1s 956us/step - loss: 1.1274 - acc: 0.5878 - val_loss: 1.1365 - val_acc: 0.5387\n",
      "Epoch 64/100\n",
      "934/934 [==============================] - 1s 943us/step - loss: 1.1247 - acc: 0.5749 - val_loss: 1.1287 - val_acc: 0.5511\n",
      "Epoch 65/100\n",
      "934/934 [==============================] - 1s 945us/step - loss: 1.1237 - acc: 0.5921 - val_loss: 1.1449 - val_acc: 0.5162\n",
      "Epoch 66/100\n",
      "934/934 [==============================] - 1s 938us/step - loss: 1.1252 - acc: 0.5878 - val_loss: 1.1289 - val_acc: 0.5436\n",
      "Epoch 67/100\n",
      "934/934 [==============================] - 1s 946us/step - loss: 1.1239 - acc: 0.5835 - val_loss: 1.1247 - val_acc: 0.5486\n",
      "Epoch 68/100\n",
      "934/934 [==============================] - 1s 956us/step - loss: 1.1194 - acc: 0.5824 - val_loss: 1.1269 - val_acc: 0.5536\n",
      "Epoch 69/100\n",
      "934/934 [==============================] - 1s 939us/step - loss: 1.1216 - acc: 0.5857 - val_loss: 1.1282 - val_acc: 0.5586\n",
      "Epoch 70/100\n",
      "934/934 [==============================] - 1s 940us/step - loss: 1.1183 - acc: 0.5867 - val_loss: 1.1275 - val_acc: 0.5511\n",
      "Epoch 71/100\n",
      "934/934 [==============================] - 1s 944us/step - loss: 1.1174 - acc: 0.5878 - val_loss: 1.1305 - val_acc: 0.5536\n",
      "Epoch 72/100\n",
      "934/934 [==============================] - 1s 953us/step - loss: 1.1175 - acc: 0.5889 - val_loss: 1.1343 - val_acc: 0.5436\n",
      "Epoch 73/100\n",
      "934/934 [==============================] - 1s 924us/step - loss: 1.1184 - acc: 0.5910 - val_loss: 1.1220 - val_acc: 0.5362\n",
      "Epoch 74/100\n",
      "934/934 [==============================] - 1s 997us/step - loss: 1.1160 - acc: 0.5878 - val_loss: 1.1199 - val_acc: 0.5536\n",
      "Epoch 75/100\n",
      "934/934 [==============================] - 1s 951us/step - loss: 1.1150 - acc: 0.5867 - val_loss: 1.1225 - val_acc: 0.5337\n",
      "Epoch 76/100\n",
      "934/934 [==============================] - 1s 975us/step - loss: 1.1107 - acc: 0.5910 - val_loss: 1.1296 - val_acc: 0.5237\n",
      "Epoch 77/100\n",
      "934/934 [==============================] - 1s 950us/step - loss: 1.1135 - acc: 0.5878 - val_loss: 1.1127 - val_acc: 0.5686\n",
      "Epoch 78/100\n",
      "934/934 [==============================] - 1s 977us/step - loss: 1.1114 - acc: 0.5899 - val_loss: 1.1128 - val_acc: 0.5586\n",
      "Epoch 79/100\n",
      "934/934 [==============================] - 1s 945us/step - loss: 1.1100 - acc: 0.5942 - val_loss: 1.1140 - val_acc: 0.5661\n",
      "Epoch 80/100\n",
      "934/934 [==============================] - 1s 944us/step - loss: 1.1129 - acc: 0.5899 - val_loss: 1.1155 - val_acc: 0.5611\n",
      "Epoch 81/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.1114 - acc: 0.5878 - val_loss: 1.1158 - val_acc: 0.5611\n",
      "Epoch 82/100\n",
      "934/934 [==============================] - 1s 943us/step - loss: 1.1107 - acc: 0.5835 - val_loss: 1.1227 - val_acc: 0.5411\n",
      "Epoch 83/100\n",
      "934/934 [==============================] - 1s 943us/step - loss: 1.1084 - acc: 0.5899 - val_loss: 1.1161 - val_acc: 0.5436\n",
      "Epoch 84/100\n",
      "934/934 [==============================] - 1s 942us/step - loss: 1.1081 - acc: 0.5878 - val_loss: 1.1168 - val_acc: 0.5387\n",
      "Epoch 85/100\n",
      "934/934 [==============================] - 1s 959us/step - loss: 1.1085 - acc: 0.5889 - val_loss: 1.1181 - val_acc: 0.5387\n",
      "Epoch 86/100\n",
      "934/934 [==============================] - 1s 938us/step - loss: 1.1061 - acc: 0.5889 - val_loss: 1.1068 - val_acc: 0.5761\n",
      "Epoch 87/100\n",
      "934/934 [==============================] - 1s 939us/step - loss: 1.1059 - acc: 0.5899 - val_loss: 1.1226 - val_acc: 0.5536\n",
      "Epoch 88/100\n",
      "934/934 [==============================] - 1s 933us/step - loss: 1.1072 - acc: 0.5953 - val_loss: 1.1113 - val_acc: 0.5362\n",
      "Epoch 89/100\n",
      "934/934 [==============================] - 1s 939us/step - loss: 1.1052 - acc: 0.5964 - val_loss: 1.1169 - val_acc: 0.5536\n",
      "Epoch 90/100\n",
      "934/934 [==============================] - 1s 937us/step - loss: 1.1050 - acc: 0.5899 - val_loss: 1.1128 - val_acc: 0.5636\n",
      "Epoch 91/100\n",
      "934/934 [==============================] - 1s 947us/step - loss: 1.1032 - acc: 0.5942 - val_loss: 1.1109 - val_acc: 0.5536\n",
      "Epoch 92/100\n",
      "934/934 [==============================] - 1s 946us/step - loss: 1.1043 - acc: 0.5910 - val_loss: 1.1164 - val_acc: 0.5362\n",
      "Epoch 93/100\n",
      "934/934 [==============================] - 1s 956us/step - loss: 1.1040 - acc: 0.5931 - val_loss: 1.1135 - val_acc: 0.5411\n",
      "Epoch 94/100\n",
      "934/934 [==============================] - 1s 966us/step - loss: 1.1036 - acc: 0.5899 - val_loss: 1.1141 - val_acc: 0.5436\n",
      "Epoch 95/100\n",
      "934/934 [==============================] - 1s 938us/step - loss: 1.1036 - acc: 0.5857 - val_loss: 1.1111 - val_acc: 0.5536\n",
      "Epoch 96/100\n",
      "934/934 [==============================] - 1s 941us/step - loss: 1.1028 - acc: 0.5964 - val_loss: 1.1037 - val_acc: 0.5686\n",
      "Epoch 97/100\n",
      "934/934 [==============================] - 1s 938us/step - loss: 1.1023 - acc: 0.5899 - val_loss: 1.1064 - val_acc: 0.5686\n",
      "Epoch 98/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1005 - acc: 0.5931 - val_loss: 1.1174 - val_acc: 0.5436\n",
      "Epoch 99/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0989 - acc: 0.5996 - val_loss: 1.1190 - val_acc: 0.5411\n",
      "Epoch 100/100\n",
      "934/934 [==============================] - 1s 930us/step - loss: 1.1005 - acc: 0.5878 - val_loss: 1.1104 - val_acc: 0.5461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 401 samples\n",
      "Epoch 1/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.8424 - acc: 0.3073 - val_loss: 1.7102 - val_acc: 0.3292\n",
      "Epoch 2/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.7132 - acc: 0.3019 - val_loss: 1.6799 - val_acc: 0.3292\n",
      "Epoch 3/100\n",
      "934/934 [==============================] - 1s 960us/step - loss: 1.6898 - acc: 0.3126 - val_loss: 1.6580 - val_acc: 0.3317\n",
      "Epoch 4/100\n",
      "934/934 [==============================] - 1s 956us/step - loss: 1.6677 - acc: 0.3126 - val_loss: 1.6338 - val_acc: 0.3691\n",
      "Epoch 5/100\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.6375 - acc: 0.3608 - val_loss: 1.6010 - val_acc: 0.3416\n",
      "Epoch 6/100\n",
      "934/934 [==============================] - 1s 966us/step - loss: 1.6021 - acc: 0.3544 - val_loss: 1.5611 - val_acc: 0.3890\n",
      "Epoch 7/100\n",
      "934/934 [==============================] - 1s 956us/step - loss: 1.5590 - acc: 0.3983 - val_loss: 1.5172 - val_acc: 0.4190\n",
      "Epoch 8/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.5152 - acc: 0.4154 - val_loss: 1.4752 - val_acc: 0.4239\n",
      "Epoch 9/100\n",
      "934/934 [==============================] - 1s 948us/step - loss: 1.4713 - acc: 0.4186 - val_loss: 1.4316 - val_acc: 0.4140\n",
      "Epoch 10/100\n",
      "934/934 [==============================] - 1s 950us/step - loss: 1.4284 - acc: 0.4229 - val_loss: 1.3944 - val_acc: 0.4713\n",
      "Epoch 11/100\n",
      "934/934 [==============================] - 1s 951us/step - loss: 1.3888 - acc: 0.4786 - val_loss: 1.3554 - val_acc: 0.4738\n",
      "Epoch 12/100\n",
      "934/934 [==============================] - 1s 958us/step - loss: 1.3508 - acc: 0.4914 - val_loss: 1.3156 - val_acc: 0.5062\n",
      "Epoch 13/100\n",
      "934/934 [==============================] - 1s 999us/step - loss: 1.3213 - acc: 0.5043 - val_loss: 1.2852 - val_acc: 0.4938\n",
      "Epoch 14/100\n",
      "934/934 [==============================] - 1s 981us/step - loss: 1.2933 - acc: 0.5150 - val_loss: 1.2662 - val_acc: 0.5087\n",
      "Epoch 15/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.2701 - acc: 0.5150 - val_loss: 1.2462 - val_acc: 0.5137\n",
      "Epoch 16/100\n",
      "934/934 [==============================] - 1s 951us/step - loss: 1.2517 - acc: 0.5246 - val_loss: 1.2315 - val_acc: 0.5112\n",
      "Epoch 17/100\n",
      "934/934 [==============================] - 1s 950us/step - loss: 1.2361 - acc: 0.5171 - val_loss: 1.2216 - val_acc: 0.4963\n",
      "Epoch 18/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.2228 - acc: 0.5193 - val_loss: 1.2088 - val_acc: 0.5037\n",
      "Epoch 19/100\n",
      "934/934 [==============================] - 1s 954us/step - loss: 1.2138 - acc: 0.5193 - val_loss: 1.2019 - val_acc: 0.5137\n",
      "Epoch 20/100\n",
      "934/934 [==============================] - 1s 949us/step - loss: 1.2042 - acc: 0.5300 - val_loss: 1.1984 - val_acc: 0.5062\n",
      "Epoch 21/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.1949 - acc: 0.5310 - val_loss: 1.1969 - val_acc: 0.4938\n",
      "Epoch 22/100\n",
      "934/934 [==============================] - 1s 948us/step - loss: 1.1902 - acc: 0.5257 - val_loss: 1.1916 - val_acc: 0.5212\n",
      "Epoch 23/100\n",
      "934/934 [==============================] - 1s 957us/step - loss: 1.1816 - acc: 0.5193 - val_loss: 1.1860 - val_acc: 0.5212\n",
      "Epoch 24/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.1769 - acc: 0.5375 - val_loss: 1.1837 - val_acc: 0.5187\n",
      "Epoch 25/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1721 - acc: 0.5225 - val_loss: 1.1805 - val_acc: 0.5262\n",
      "Epoch 26/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1654 - acc: 0.5353 - val_loss: 1.1799 - val_acc: 0.5112\n",
      "Epoch 27/100\n",
      "934/934 [==============================] - 1s 975us/step - loss: 1.1628 - acc: 0.5236 - val_loss: 1.1774 - val_acc: 0.5137\n",
      "Epoch 28/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.1589 - acc: 0.5471 - val_loss: 1.1685 - val_acc: 0.5212\n",
      "Epoch 29/100\n",
      "934/934 [==============================] - 1s 953us/step - loss: 1.1544 - acc: 0.5439 - val_loss: 1.1654 - val_acc: 0.5187\n",
      "Epoch 30/100\n",
      "934/934 [==============================] - 1s 948us/step - loss: 1.1504 - acc: 0.5600 - val_loss: 1.1630 - val_acc: 0.5212\n",
      "Epoch 31/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.1456 - acc: 0.5493 - val_loss: 1.1824 - val_acc: 0.5012\n",
      "Epoch 32/100\n",
      "934/934 [==============================] - 1s 947us/step - loss: 1.1437 - acc: 0.5460 - val_loss: 1.1609 - val_acc: 0.5137\n",
      "Epoch 33/100\n",
      "934/934 [==============================] - 1s 951us/step - loss: 1.1410 - acc: 0.5546 - val_loss: 1.1636 - val_acc: 0.5212\n",
      "Epoch 34/100\n",
      "934/934 [==============================] - 1s 949us/step - loss: 1.1382 - acc: 0.5578 - val_loss: 1.1558 - val_acc: 0.5362\n",
      "Epoch 35/100\n",
      "934/934 [==============================] - 1s 947us/step - loss: 1.1354 - acc: 0.5642 - val_loss: 1.1595 - val_acc: 0.5411\n",
      "Epoch 36/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.1315 - acc: 0.5578 - val_loss: 1.1574 - val_acc: 0.5262\n",
      "Epoch 37/100\n",
      "934/934 [==============================] - 1s 979us/step - loss: 1.1268 - acc: 0.5696 - val_loss: 1.1502 - val_acc: 0.5461\n",
      "Epoch 38/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1232 - acc: 0.5578 - val_loss: 1.1516 - val_acc: 0.5312\n",
      "Epoch 39/100\n",
      "934/934 [==============================] - 1s 972us/step - loss: 1.1229 - acc: 0.5578 - val_loss: 1.1482 - val_acc: 0.5187\n",
      "Epoch 40/100\n",
      "934/934 [==============================] - 1s 957us/step - loss: 1.1165 - acc: 0.5717 - val_loss: 1.1473 - val_acc: 0.5536\n",
      "Epoch 41/100\n",
      "934/934 [==============================] - 1s 978us/step - loss: 1.1142 - acc: 0.5610 - val_loss: 1.1659 - val_acc: 0.5162\n",
      "Epoch 42/100\n",
      "934/934 [==============================] - 1s 985us/step - loss: 1.1118 - acc: 0.5653 - val_loss: 1.1417 - val_acc: 0.5461\n",
      "Epoch 43/100\n",
      "934/934 [==============================] - 1s 979us/step - loss: 1.1092 - acc: 0.5535 - val_loss: 1.1348 - val_acc: 0.5337\n",
      "Epoch 44/100\n",
      "934/934 [==============================] - 1s 985us/step - loss: 1.1064 - acc: 0.5707 - val_loss: 1.1343 - val_acc: 0.5362\n",
      "Epoch 45/100\n",
      "934/934 [==============================] - 1s 992us/step - loss: 1.1047 - acc: 0.5717 - val_loss: 1.1351 - val_acc: 0.5411\n",
      "Epoch 46/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.0995 - acc: 0.5771 - val_loss: 1.1293 - val_acc: 0.5387\n",
      "Epoch 47/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.0971 - acc: 0.5782 - val_loss: 1.1294 - val_acc: 0.5536\n",
      "Epoch 48/100\n",
      "934/934 [==============================] - 1s 951us/step - loss: 1.0938 - acc: 0.5824 - val_loss: 1.1266 - val_acc: 0.5362\n",
      "Epoch 49/100\n",
      "934/934 [==============================] - 1s 979us/step - loss: 1.0920 - acc: 0.5782 - val_loss: 1.1236 - val_acc: 0.5436\n",
      "Epoch 50/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0890 - acc: 0.5803 - val_loss: 1.1294 - val_acc: 0.5287\n",
      "Epoch 51/100\n",
      "934/934 [==============================] - 1s 951us/step - loss: 1.0887 - acc: 0.5696 - val_loss: 1.1219 - val_acc: 0.5461\n",
      "Epoch 52/100\n",
      "934/934 [==============================] - 1s 954us/step - loss: 1.0863 - acc: 0.5782 - val_loss: 1.1201 - val_acc: 0.5411\n",
      "Epoch 53/100\n",
      "934/934 [==============================] - 1s 954us/step - loss: 1.0838 - acc: 0.5749 - val_loss: 1.1242 - val_acc: 0.5387\n",
      "Epoch 54/100\n",
      "934/934 [==============================] - 1s 953us/step - loss: 1.0812 - acc: 0.5696 - val_loss: 1.1211 - val_acc: 0.5362\n",
      "Epoch 55/100\n",
      "934/934 [==============================] - 1s 948us/step - loss: 1.0781 - acc: 0.5728 - val_loss: 1.1208 - val_acc: 0.5337\n",
      "Epoch 56/100\n",
      "934/934 [==============================] - 1s 951us/step - loss: 1.0722 - acc: 0.5675 - val_loss: 1.1187 - val_acc: 0.5536\n",
      "Epoch 57/100\n",
      "934/934 [==============================] - 1s 955us/step - loss: 1.0762 - acc: 0.5707 - val_loss: 1.1188 - val_acc: 0.5561\n",
      "Epoch 58/100\n",
      "934/934 [==============================] - 1s 954us/step - loss: 1.0702 - acc: 0.5803 - val_loss: 1.1272 - val_acc: 0.5312\n",
      "Epoch 59/100\n",
      "934/934 [==============================] - 1s 954us/step - loss: 1.0731 - acc: 0.5792 - val_loss: 1.1170 - val_acc: 0.5436\n",
      "Epoch 60/100\n",
      "934/934 [==============================] - 1s 950us/step - loss: 1.0690 - acc: 0.5857 - val_loss: 1.1127 - val_acc: 0.5611\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934/934 [==============================] - 1s 985us/step - loss: 1.0671 - acc: 0.5782 - val_loss: 1.1119 - val_acc: 0.5536\n",
      "Epoch 62/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0667 - acc: 0.5835 - val_loss: 1.1096 - val_acc: 0.5486\n",
      "Epoch 63/100\n",
      "934/934 [==============================] - 1s 953us/step - loss: 1.0632 - acc: 0.5846 - val_loss: 1.1124 - val_acc: 0.5312\n",
      "Epoch 64/100\n",
      "934/934 [==============================] - 1s 953us/step - loss: 1.0600 - acc: 0.5782 - val_loss: 1.1160 - val_acc: 0.5436\n",
      "Epoch 65/100\n",
      "934/934 [==============================] - 1s 954us/step - loss: 1.0594 - acc: 0.5749 - val_loss: 1.1076 - val_acc: 0.5536\n",
      "Epoch 66/100\n",
      "934/934 [==============================] - 1s 955us/step - loss: 1.0610 - acc: 0.5782 - val_loss: 1.1102 - val_acc: 0.5387\n",
      "Epoch 67/100\n",
      "934/934 [==============================] - 1s 966us/step - loss: 1.0583 - acc: 0.5899 - val_loss: 1.1056 - val_acc: 0.5461\n",
      "Epoch 68/100\n",
      "934/934 [==============================] - 1s 951us/step - loss: 1.0552 - acc: 0.5803 - val_loss: 1.1047 - val_acc: 0.5611\n",
      "Epoch 69/100\n",
      "934/934 [==============================] - 1s 956us/step - loss: 1.0543 - acc: 0.5835 - val_loss: 1.1015 - val_acc: 0.5686\n",
      "Epoch 70/100\n",
      "934/934 [==============================] - 1s 961us/step - loss: 1.0537 - acc: 0.5921 - val_loss: 1.1060 - val_acc: 0.5486\n",
      "Epoch 71/100\n",
      "934/934 [==============================] - 1s 970us/step - loss: 1.0529 - acc: 0.5899 - val_loss: 1.1014 - val_acc: 0.5486\n",
      "Epoch 72/100\n",
      "934/934 [==============================] - 1s 966us/step - loss: 1.0523 - acc: 0.5857 - val_loss: 1.1028 - val_acc: 0.5536\n",
      "Epoch 73/100\n",
      "934/934 [==============================] - 1s 977us/step - loss: 1.0494 - acc: 0.6028 - val_loss: 1.1079 - val_acc: 0.5436\n",
      "Epoch 74/100\n",
      "934/934 [==============================] - 1s 995us/step - loss: 1.0500 - acc: 0.5942 - val_loss: 1.1001 - val_acc: 0.5661\n",
      "Epoch 75/100\n",
      "934/934 [==============================] - 1s 984us/step - loss: 1.0478 - acc: 0.5953 - val_loss: 1.1050 - val_acc: 0.5436\n",
      "Epoch 76/100\n",
      "934/934 [==============================] - 1s 978us/step - loss: 1.0472 - acc: 0.5867 - val_loss: 1.0942 - val_acc: 0.5736\n",
      "Epoch 77/100\n",
      "934/934 [==============================] - 1s 961us/step - loss: 1.0457 - acc: 0.5964 - val_loss: 1.0927 - val_acc: 0.5711\n",
      "Epoch 78/100\n",
      "934/934 [==============================] - 1s 964us/step - loss: 1.0449 - acc: 0.5964 - val_loss: 1.0943 - val_acc: 0.5486\n",
      "Epoch 79/100\n",
      "934/934 [==============================] - 1s 954us/step - loss: 1.0430 - acc: 0.5985 - val_loss: 1.0965 - val_acc: 0.5486\n",
      "Epoch 80/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0422 - acc: 0.5867 - val_loss: 1.1014 - val_acc: 0.5486\n",
      "Epoch 81/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.0396 - acc: 0.5985 - val_loss: 1.1086 - val_acc: 0.5486\n",
      "Epoch 82/100\n",
      "934/934 [==============================] - 1s 950us/step - loss: 1.0397 - acc: 0.5953 - val_loss: 1.0930 - val_acc: 0.5586\n",
      "Epoch 83/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.0396 - acc: 0.5846 - val_loss: 1.0937 - val_acc: 0.5486\n",
      "Epoch 84/100\n",
      "934/934 [==============================] - 1s 946us/step - loss: 1.0360 - acc: 0.5931 - val_loss: 1.0939 - val_acc: 0.5636\n",
      "Epoch 85/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.0362 - acc: 0.5899 - val_loss: 1.0889 - val_acc: 0.5661\n",
      "Epoch 86/100\n",
      "934/934 [==============================] - 1s 944us/step - loss: 1.0366 - acc: 0.6028 - val_loss: 1.0953 - val_acc: 0.5461\n",
      "Epoch 87/100\n",
      "934/934 [==============================] - 1s 958us/step - loss: 1.0366 - acc: 0.5792 - val_loss: 1.0904 - val_acc: 0.5436\n",
      "Epoch 88/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.0339 - acc: 0.5974 - val_loss: 1.0899 - val_acc: 0.5486\n",
      "Epoch 89/100\n",
      "934/934 [==============================] - 1s 946us/step - loss: 1.0335 - acc: 0.5974 - val_loss: 1.0842 - val_acc: 0.5511\n",
      "Epoch 90/100\n",
      "934/934 [==============================] - 1s 958us/step - loss: 1.0331 - acc: 0.5974 - val_loss: 1.0889 - val_acc: 0.5486\n",
      "Epoch 91/100\n",
      "934/934 [==============================] - 1s 953us/step - loss: 1.0305 - acc: 0.6006 - val_loss: 1.0870 - val_acc: 0.5461\n",
      "Epoch 92/100\n",
      "934/934 [==============================] - 1s 948us/step - loss: 1.0306 - acc: 0.5974 - val_loss: 1.0861 - val_acc: 0.5486\n",
      "Epoch 93/100\n",
      "934/934 [==============================] - 1s 954us/step - loss: 1.0280 - acc: 0.6017 - val_loss: 1.0862 - val_acc: 0.5511\n",
      "Epoch 94/100\n",
      "934/934 [==============================] - 1s 953us/step - loss: 1.0255 - acc: 0.5953 - val_loss: 1.1077 - val_acc: 0.5536\n",
      "Epoch 95/100\n",
      "934/934 [==============================] - 1s 960us/step - loss: 1.0278 - acc: 0.6092 - val_loss: 1.0844 - val_acc: 0.5486\n",
      "Epoch 96/100\n",
      "934/934 [==============================] - 1s 950us/step - loss: 1.0275 - acc: 0.5996 - val_loss: 1.0839 - val_acc: 0.5611\n",
      "Epoch 97/100\n",
      "934/934 [==============================] - 1s 949us/step - loss: 1.0233 - acc: 0.6039 - val_loss: 1.0767 - val_acc: 0.5786\n",
      "Epoch 98/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.0228 - acc: 0.6049 - val_loss: 1.0826 - val_acc: 0.5611\n",
      "Epoch 99/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.0227 - acc: 0.6060 - val_loss: 1.0841 - val_acc: 0.5486\n",
      "Epoch 100/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.0239 - acc: 0.6006 - val_loss: 1.0792 - val_acc: 0.5611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 401 samples\n",
      "Epoch 1/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.8468 - acc: 0.2805 - val_loss: 1.7110 - val_acc: 0.3292\n",
      "Epoch 2/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.7236 - acc: 0.3041 - val_loss: 1.6959 - val_acc: 0.3392\n",
      "Epoch 3/100\n",
      "934/934 [==============================] - 1s 997us/step - loss: 1.7048 - acc: 0.3255 - val_loss: 1.6727 - val_acc: 0.3292\n",
      "Epoch 4/100\n",
      "934/934 [==============================] - 1s 977us/step - loss: 1.6839 - acc: 0.3169 - val_loss: 1.6479 - val_acc: 0.3317\n",
      "Epoch 5/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6543 - acc: 0.3308 - val_loss: 1.6184 - val_acc: 0.4190\n",
      "Epoch 6/100\n",
      "934/934 [==============================] - 1s 989us/step - loss: 1.6202 - acc: 0.4015 - val_loss: 1.5811 - val_acc: 0.4264\n",
      "Epoch 7/100\n",
      "934/934 [==============================] - 1s 967us/step - loss: 1.5811 - acc: 0.4122 - val_loss: 1.5548 - val_acc: 0.4140\n",
      "Epoch 8/100\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.5441 - acc: 0.4261 - val_loss: 1.5163 - val_acc: 0.42390s - loss: 1.5574 - acc: 0.4\n",
      "Epoch 9/100\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.5125 - acc: 0.4379 - val_loss: 1.4923 - val_acc: 0.4589\n",
      "Epoch 10/100\n",
      "934/934 [==============================] - 1s 961us/step - loss: 1.4860 - acc: 0.4454 - val_loss: 1.4580 - val_acc: 0.4613\n",
      "Epoch 11/100\n",
      "934/934 [==============================] - 1s 957us/step - loss: 1.4562 - acc: 0.4475 - val_loss: 1.4488 - val_acc: 0.4090\n",
      "Epoch 12/100\n",
      "934/934 [==============================] - 1s 954us/step - loss: 1.4287 - acc: 0.4454 - val_loss: 1.3996 - val_acc: 0.4564\n",
      "Epoch 13/100\n",
      "934/934 [==============================] - 1s 955us/step - loss: 1.3972 - acc: 0.4400 - val_loss: 1.3644 - val_acc: 0.4364\n",
      "Epoch 14/100\n",
      "934/934 [==============================] - 1s 955us/step - loss: 1.3596 - acc: 0.4572 - val_loss: 1.3237 - val_acc: 0.4489\n",
      "Epoch 15/100\n",
      "934/934 [==============================] - 1s 956us/step - loss: 1.3183 - acc: 0.4925 - val_loss: 1.2929 - val_acc: 0.5062\n",
      "Epoch 16/100\n",
      "934/934 [==============================] - 1s 961us/step - loss: 1.2821 - acc: 0.5278 - val_loss: 1.2523 - val_acc: 0.5312\n",
      "Epoch 17/100\n",
      "934/934 [==============================] - 1s 958us/step - loss: 1.2512 - acc: 0.5225 - val_loss: 1.2202 - val_acc: 0.5262\n",
      "Epoch 18/100\n",
      "934/934 [==============================] - 1s 957us/step - loss: 1.2254 - acc: 0.5450 - val_loss: 1.2008 - val_acc: 0.5362\n",
      "Epoch 19/100\n",
      "934/934 [==============================] - 1s 953us/step - loss: 1.2010 - acc: 0.5460 - val_loss: 1.1788 - val_acc: 0.5362\n",
      "Epoch 20/100\n",
      "934/934 [==============================] - 1s 960us/step - loss: 1.1857 - acc: 0.5675 - val_loss: 1.1664 - val_acc: 0.5411\n",
      "Epoch 21/100\n",
      "934/934 [==============================] - 1s 961us/step - loss: 1.1727 - acc: 0.5664 - val_loss: 1.1606 - val_acc: 0.5337\n",
      "Epoch 22/100\n",
      "934/934 [==============================] - 1s 954us/step - loss: 1.1608 - acc: 0.5675 - val_loss: 1.1544 - val_acc: 0.5337\n",
      "Epoch 23/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1530 - acc: 0.5717 - val_loss: 1.1523 - val_acc: 0.5411\n",
      "Epoch 24/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1446 - acc: 0.5610 - val_loss: 1.1522 - val_acc: 0.5486\n",
      "Epoch 25/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1369 - acc: 0.5717 - val_loss: 1.1352 - val_acc: 0.5611\n",
      "Epoch 26/100\n",
      "934/934 [==============================] - 1s 956us/step - loss: 1.1295 - acc: 0.5835 - val_loss: 1.1323 - val_acc: 0.5486\n",
      "Epoch 27/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.1239 - acc: 0.5782 - val_loss: 1.1339 - val_acc: 0.5511\n",
      "Epoch 28/100\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.1216 - acc: 0.5835 - val_loss: 1.1282 - val_acc: 0.5586\n",
      "Epoch 29/100\n",
      "934/934 [==============================] - 1s 956us/step - loss: 1.1158 - acc: 0.5782 - val_loss: 1.1262 - val_acc: 0.5661\n",
      "Epoch 30/100\n",
      "934/934 [==============================] - 1s 953us/step - loss: 1.1130 - acc: 0.5878 - val_loss: 1.1238 - val_acc: 0.5536\n",
      "Epoch 31/100\n",
      "934/934 [==============================] - 1s 959us/step - loss: 1.1093 - acc: 0.5749 - val_loss: 1.1184 - val_acc: 0.5486\n",
      "Epoch 32/100\n",
      "934/934 [==============================] - 1s 959us/step - loss: 1.1044 - acc: 0.5717 - val_loss: 1.1257 - val_acc: 0.5561\n",
      "Epoch 33/100\n",
      "934/934 [==============================] - 1s 958us/step - loss: 1.1005 - acc: 0.5824 - val_loss: 1.1177 - val_acc: 0.5511\n",
      "Epoch 34/100\n",
      "934/934 [==============================] - 1s 955us/step - loss: 1.0986 - acc: 0.5803 - val_loss: 1.1157 - val_acc: 0.5586\n",
      "Epoch 35/100\n",
      "934/934 [==============================] - 1s 959us/step - loss: 1.0923 - acc: 0.5846 - val_loss: 1.1123 - val_acc: 0.5611\n",
      "Epoch 36/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.0900 - acc: 0.5867 - val_loss: 1.1179 - val_acc: 0.5611\n",
      "Epoch 37/100\n",
      "934/934 [==============================] - 1s 958us/step - loss: 1.0903 - acc: 0.5749 - val_loss: 1.1147 - val_acc: 0.5611\n",
      "Epoch 38/100\n",
      "934/934 [==============================] - 1s 957us/step - loss: 1.0864 - acc: 0.5803 - val_loss: 1.1052 - val_acc: 0.5611\n",
      "Epoch 39/100\n",
      "934/934 [==============================] - 1s 955us/step - loss: 1.0850 - acc: 0.5867 - val_loss: 1.1031 - val_acc: 0.5686\n",
      "Epoch 40/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 1.0828 - acc: 0.5910 - val_loss: 1.1016 - val_acc: 0.5661\n",
      "Epoch 41/100\n",
      "934/934 [==============================] - 1s 959us/step - loss: 1.0760 - acc: 0.5878 - val_loss: 1.1078 - val_acc: 0.5661\n",
      "Epoch 42/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.0712 - acc: 0.5974 - val_loss: 1.1031 - val_acc: 0.5586\n",
      "Epoch 43/100\n",
      "934/934 [==============================] - 1s 954us/step - loss: 1.0699 - acc: 0.5878 - val_loss: 1.0954 - val_acc: 0.5736\n",
      "Epoch 44/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.0691 - acc: 0.5985 - val_loss: 1.0996 - val_acc: 0.5636\n",
      "Epoch 45/100\n",
      "934/934 [==============================] - 1s 960us/step - loss: 1.0686 - acc: 0.5867 - val_loss: 1.1116 - val_acc: 0.5436\n",
      "Epoch 46/100\n",
      "934/934 [==============================] - 1s 959us/step - loss: 1.0658 - acc: 0.6049 - val_loss: 1.0936 - val_acc: 0.5810\n",
      "Epoch 47/100\n",
      "934/934 [==============================] - 1s 953us/step - loss: 1.0643 - acc: 0.5964 - val_loss: 1.0893 - val_acc: 0.5711\n",
      "Epoch 48/100\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.0620 - acc: 0.6103 - val_loss: 1.0926 - val_acc: 0.5586\n",
      "Epoch 49/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0579 - acc: 0.6103 - val_loss: 1.0909 - val_acc: 0.5611\n",
      "Epoch 50/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0554 - acc: 0.5878 - val_loss: 1.0870 - val_acc: 0.5661\n",
      "Epoch 51/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0558 - acc: 0.5931 - val_loss: 1.0930 - val_acc: 0.5711\n",
      "Epoch 52/100\n",
      "934/934 [==============================] - 1s 971us/step - loss: 1.0521 - acc: 0.5921 - val_loss: 1.0883 - val_acc: 0.5786\n",
      "Epoch 53/100\n",
      "934/934 [==============================] - 1s 998us/step - loss: 1.0488 - acc: 0.5953 - val_loss: 1.0890 - val_acc: 0.5511\n",
      "Epoch 54/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0488 - acc: 0.6060 - val_loss: 1.0821 - val_acc: 0.5636\n",
      "Epoch 55/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0409 - acc: 0.6092 - val_loss: 1.1087 - val_acc: 0.5486\n",
      "Epoch 56/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0434 - acc: 0.6028 - val_loss: 1.0792 - val_acc: 0.5761\n",
      "Epoch 57/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0414 - acc: 0.6028 - val_loss: 1.0819 - val_acc: 0.5711\n",
      "Epoch 58/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0369 - acc: 0.6071 - val_loss: 1.0767 - val_acc: 0.5711\n",
      "Epoch 59/100\n",
      "934/934 [==============================] - 1s 974us/step - loss: 1.0388 - acc: 0.6060 - val_loss: 1.0776 - val_acc: 0.5711\n",
      "Epoch 60/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0351 - acc: 0.6081 - val_loss: 1.0746 - val_acc: 0.5736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "934/934 [==============================] - 1s 970us/step - loss: 1.0338 - acc: 0.6049 - val_loss: 1.0772 - val_acc: 0.5761\n",
      "Epoch 62/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0331 - acc: 0.6124 - val_loss: 1.0780 - val_acc: 0.5736\n",
      "Epoch 63/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0311 - acc: 0.6049 - val_loss: 1.0773 - val_acc: 0.5661\n",
      "Epoch 64/100\n",
      "934/934 [==============================] - 1s 966us/step - loss: 1.0294 - acc: 0.6092 - val_loss: 1.0738 - val_acc: 0.5686\n",
      "Epoch 65/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0257 - acc: 0.6103 - val_loss: 1.0927 - val_acc: 0.5536\n",
      "Epoch 66/100\n",
      "934/934 [==============================] - 1s 983us/step - loss: 1.0276 - acc: 0.6017 - val_loss: 1.0744 - val_acc: 0.5761\n",
      "Epoch 67/100\n",
      "934/934 [==============================] - 1s 979us/step - loss: 1.0252 - acc: 0.6146 - val_loss: 1.0759 - val_acc: 0.5761\n",
      "Epoch 68/100\n",
      "934/934 [==============================] - 1s 959us/step - loss: 1.0209 - acc: 0.6199 - val_loss: 1.0885 - val_acc: 0.5611\n",
      "Epoch 69/100\n",
      "934/934 [==============================] - 1s 967us/step - loss: 1.0212 - acc: 0.6113 - val_loss: 1.0800 - val_acc: 0.5711\n",
      "Epoch 70/100\n",
      "934/934 [==============================] - 1s 960us/step - loss: 1.0207 - acc: 0.6146 - val_loss: 1.0680 - val_acc: 0.5661\n",
      "Epoch 71/100\n",
      "934/934 [==============================] - 1s 955us/step - loss: 1.0197 - acc: 0.6006 - val_loss: 1.0763 - val_acc: 0.5611\n",
      "Epoch 72/100\n",
      "934/934 [==============================] - 1s 956us/step - loss: 1.0150 - acc: 0.6124 - val_loss: 1.0677 - val_acc: 0.5711\n",
      "Epoch 73/100\n",
      "934/934 [==============================] - 1s 960us/step - loss: 1.0134 - acc: 0.6113 - val_loss: 1.0715 - val_acc: 0.5611\n",
      "Epoch 74/100\n",
      "934/934 [==============================] - 1s 954us/step - loss: 1.0150 - acc: 0.6039 - val_loss: 1.0692 - val_acc: 0.5736\n",
      "Epoch 75/100\n",
      "934/934 [==============================] - 1s 958us/step - loss: 1.0124 - acc: 0.6135 - val_loss: 1.0709 - val_acc: 0.5686\n",
      "Epoch 76/100\n",
      "934/934 [==============================] - 1s 957us/step - loss: 1.0102 - acc: 0.6039 - val_loss: 1.0773 - val_acc: 0.5486\n",
      "Epoch 77/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0110 - acc: 0.6188 - val_loss: 1.0790 - val_acc: 0.5486\n",
      "Epoch 78/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0092 - acc: 0.6071 - val_loss: 1.0734 - val_acc: 0.5511\n",
      "Epoch 79/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0044 - acc: 0.6124 - val_loss: 1.0674 - val_acc: 0.5711\n",
      "Epoch 80/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0060 - acc: 0.6103 - val_loss: 1.0736 - val_acc: 0.5486\n",
      "Epoch 81/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0026 - acc: 0.6178 - val_loss: 1.0798 - val_acc: 0.5736\n",
      "Epoch 82/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0039 - acc: 0.6253 - val_loss: 1.0668 - val_acc: 0.5711\n",
      "Epoch 83/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0007 - acc: 0.6146 - val_loss: 1.0832 - val_acc: 0.5711\n",
      "Epoch 84/100\n",
      "934/934 [==============================] - 1s 982us/step - loss: 1.0019 - acc: 0.6071 - val_loss: 1.0764 - val_acc: 0.5786\n",
      "Epoch 85/100\n",
      "934/934 [==============================] - 1s 994us/step - loss: 1.0009 - acc: 0.6146 - val_loss: 1.0809 - val_acc: 0.5486\n",
      "Epoch 86/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9968 - acc: 0.6178 - val_loss: 1.0835 - val_acc: 0.5536\n",
      "Epoch 87/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9932 - acc: 0.6135 - val_loss: 1.0723 - val_acc: 0.5561\n",
      "Epoch 88/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9965 - acc: 0.6156 - val_loss: 1.0752 - val_acc: 0.5611\n",
      "Epoch 89/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9925 - acc: 0.6113 - val_loss: 1.0633 - val_acc: 0.5711\n",
      "Epoch 90/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9950 - acc: 0.6188 - val_loss: 1.0670 - val_acc: 0.5761\n",
      "Epoch 91/100\n",
      "934/934 [==============================] - 1s 952us/step - loss: 0.9912 - acc: 0.6060 - val_loss: 1.0665 - val_acc: 0.5736\n",
      "Epoch 92/100\n",
      "934/934 [==============================] - 1s 998us/step - loss: 0.9887 - acc: 0.6306 - val_loss: 1.0847 - val_acc: 0.5736\n",
      "Epoch 93/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9934 - acc: 0.6274 - val_loss: 1.0606 - val_acc: 0.5711\n",
      "Epoch 94/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9907 - acc: 0.6199 - val_loss: 1.0604 - val_acc: 0.5661\n",
      "Epoch 95/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9897 - acc: 0.6146 - val_loss: 1.0638 - val_acc: 0.5636\n",
      "Epoch 96/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9893 - acc: 0.6081 - val_loss: 1.0723 - val_acc: 0.5411\n",
      "Epoch 97/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9887 - acc: 0.6274 - val_loss: 1.0687 - val_acc: 0.5611\n",
      "Epoch 98/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9874 - acc: 0.6253 - val_loss: 1.0629 - val_acc: 0.5786\n",
      "Epoch 99/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9857 - acc: 0.6231 - val_loss: 1.0637 - val_acc: 0.5636\n",
      "Epoch 100/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9847 - acc: 0.6146 - val_loss: 1.0773 - val_acc: 0.5486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 401 samples\n",
      "Epoch 1/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.8177 - acc: 0.2944 - val_loss: 1.6967 - val_acc: 0.3192\n",
      "Epoch 2/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7093 - acc: 0.3244 - val_loss: 1.6714 - val_acc: 0.3342\n",
      "Epoch 3/100\n",
      "934/934 [==============================] - 1s 947us/step - loss: 1.6773 - acc: 0.3426 - val_loss: 1.6632 - val_acc: 0.3491\n",
      "Epoch 4/100\n",
      "934/934 [==============================] - 1s 970us/step - loss: 1.6530 - acc: 0.3415 - val_loss: 1.6167 - val_acc: 0.3766\n",
      "Epoch 5/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6094 - acc: 0.3672 - val_loss: 1.5765 - val_acc: 0.4090\n",
      "Epoch 6/100\n",
      "934/934 [==============================] - 1s 977us/step - loss: 1.5512 - acc: 0.3961 - val_loss: 1.5148 - val_acc: 0.3940\n",
      "Epoch 7/100\n",
      "934/934 [==============================] - 1s 973us/step - loss: 1.4908 - acc: 0.4143 - val_loss: 1.4415 - val_acc: 0.3890\n",
      "Epoch 8/100\n",
      "934/934 [==============================] - 1s 974us/step - loss: 1.4242 - acc: 0.4540 - val_loss: 1.3762 - val_acc: 0.4713\n",
      "Epoch 9/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.3638 - acc: 0.5107 - val_loss: 1.3172 - val_acc: 0.5362\n",
      "Epoch 10/100\n",
      "934/934 [==============================] - 1s 958us/step - loss: 1.3153 - acc: 0.5450 - val_loss: 1.2693 - val_acc: 0.5337\n",
      "Epoch 11/100\n",
      "934/934 [==============================] - 1s 964us/step - loss: 1.2747 - acc: 0.5632 - val_loss: 1.2432 - val_acc: 0.5162\n",
      "Epoch 12/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.2418 - acc: 0.5428 - val_loss: 1.2134 - val_acc: 0.5337\n",
      "Epoch 13/100\n",
      "934/934 [==============================] - 1s 957us/step - loss: 1.2222 - acc: 0.5514 - val_loss: 1.2001 - val_acc: 0.5362\n",
      "Epoch 14/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.2044 - acc: 0.5439 - val_loss: 1.1844 - val_acc: 0.5312\n",
      "Epoch 15/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.1843 - acc: 0.5460 - val_loss: 1.1879 - val_acc: 0.5362\n",
      "Epoch 16/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1761 - acc: 0.5600 - val_loss: 1.1728 - val_acc: 0.5287\n",
      "Epoch 17/100\n",
      "934/934 [==============================] - 1s 959us/step - loss: 1.1631 - acc: 0.5675 - val_loss: 1.1527 - val_acc: 0.5362\n",
      "Epoch 18/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.1571 - acc: 0.5653 - val_loss: 1.1467 - val_acc: 0.5436\n",
      "Epoch 19/100\n",
      "934/934 [==============================] - 1s 989us/step - loss: 1.1472 - acc: 0.5685 - val_loss: 1.1388 - val_acc: 0.5486\n",
      "Epoch 20/100\n",
      "934/934 [==============================] - 1s 997us/step - loss: 1.1391 - acc: 0.5728 - val_loss: 1.1461 - val_acc: 0.5486\n",
      "Epoch 21/100\n",
      "934/934 [==============================] - 1s 968us/step - loss: 1.1331 - acc: 0.5739 - val_loss: 1.1310 - val_acc: 0.5486\n",
      "Epoch 22/100\n",
      "934/934 [==============================] - 1s 964us/step - loss: 1.1285 - acc: 0.5792 - val_loss: 1.1240 - val_acc: 0.5536\n",
      "Epoch 23/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.1214 - acc: 0.5921 - val_loss: 1.1254 - val_acc: 0.5486\n",
      "Epoch 24/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.1163 - acc: 0.5803 - val_loss: 1.1238 - val_acc: 0.5611\n",
      "Epoch 25/100\n",
      "934/934 [==============================] - 1s 957us/step - loss: 1.1143 - acc: 0.5792 - val_loss: 1.1186 - val_acc: 0.5586\n",
      "Epoch 26/100\n",
      "934/934 [==============================] - 1s 961us/step - loss: 1.1062 - acc: 0.5889 - val_loss: 1.1212 - val_acc: 0.5586\n",
      "Epoch 27/100\n",
      "934/934 [==============================] - 1s 982us/step - loss: 1.1043 - acc: 0.5931 - val_loss: 1.1192 - val_acc: 0.5486\n",
      "Epoch 28/100\n",
      "934/934 [==============================] - 1s 981us/step - loss: 1.0985 - acc: 0.6006 - val_loss: 1.1088 - val_acc: 0.5586\n",
      "Epoch 29/100\n",
      "934/934 [==============================] - 1s 958us/step - loss: 1.0948 - acc: 0.5996 - val_loss: 1.1062 - val_acc: 0.5711\n",
      "Epoch 30/100\n",
      "934/934 [==============================] - 1s 960us/step - loss: 1.0941 - acc: 0.5953 - val_loss: 1.0965 - val_acc: 0.5586\n",
      "Epoch 31/100\n",
      "934/934 [==============================] - 1s 975us/step - loss: 1.0904 - acc: 0.6017 - val_loss: 1.1196 - val_acc: 0.5486\n",
      "Epoch 32/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.0879 - acc: 0.5910 - val_loss: 1.0996 - val_acc: 0.5611\n",
      "Epoch 33/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0830 - acc: 0.5899 - val_loss: 1.0983 - val_acc: 0.5536\n",
      "Epoch 34/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0807 - acc: 0.6113 - val_loss: 1.0927 - val_acc: 0.5586\n",
      "Epoch 35/100\n",
      "934/934 [==============================] - 1s 959us/step - loss: 1.0772 - acc: 0.5931 - val_loss: 1.0946 - val_acc: 0.5711\n",
      "Epoch 36/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.0723 - acc: 0.6006 - val_loss: 1.1069 - val_acc: 0.5561\n",
      "Epoch 37/100\n",
      "934/934 [==============================] - 1s 973us/step - loss: 1.0693 - acc: 0.5942 - val_loss: 1.0869 - val_acc: 0.5711\n",
      "Epoch 38/100\n",
      "934/934 [==============================] - 1s 967us/step - loss: 1.0658 - acc: 0.6113 - val_loss: 1.0993 - val_acc: 0.5586\n",
      "Epoch 39/100\n",
      "934/934 [==============================] - 1s 992us/step - loss: 1.0655 - acc: 0.6017 - val_loss: 1.0829 - val_acc: 0.5711\n",
      "Epoch 40/100\n",
      "934/934 [==============================] - 1s 969us/step - loss: 1.0630 - acc: 0.6006 - val_loss: 1.0829 - val_acc: 0.5736\n",
      "Epoch 41/100\n",
      "934/934 [==============================] - 1s 970us/step - loss: 1.0602 - acc: 0.6049 - val_loss: 1.0817 - val_acc: 0.5761\n",
      "Epoch 42/100\n",
      "934/934 [==============================] - 1s 979us/step - loss: 1.0594 - acc: 0.5985 - val_loss: 1.0790 - val_acc: 0.5810\n",
      "Epoch 43/100\n",
      "934/934 [==============================] - 1s 964us/step - loss: 1.0541 - acc: 0.5996 - val_loss: 1.0770 - val_acc: 0.5786\n",
      "Epoch 44/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.0528 - acc: 0.6124 - val_loss: 1.0802 - val_acc: 0.5835\n",
      "Epoch 45/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.0475 - acc: 0.5953 - val_loss: 1.0748 - val_acc: 0.5935\n",
      "Epoch 46/100\n",
      "934/934 [==============================] - 1s 959us/step - loss: 1.0439 - acc: 0.6113 - val_loss: 1.0715 - val_acc: 0.5885\n",
      "Epoch 47/100\n",
      "934/934 [==============================] - 1s 960us/step - loss: 1.0454 - acc: 0.6049 - val_loss: 1.0781 - val_acc: 0.5736\n",
      "Epoch 48/100\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.0408 - acc: 0.6124 - val_loss: 1.0733 - val_acc: 0.5736\n",
      "Epoch 49/100\n",
      "934/934 [==============================] - 1s 964us/step - loss: 1.0418 - acc: 0.6135 - val_loss: 1.0613 - val_acc: 0.5810\n",
      "Epoch 50/100\n",
      "934/934 [==============================] - 1s 960us/step - loss: 1.0371 - acc: 0.5985 - val_loss: 1.0669 - val_acc: 0.5935\n",
      "Epoch 51/100\n",
      "934/934 [==============================] - 1s 971us/step - loss: 1.0383 - acc: 0.6092 - val_loss: 1.0663 - val_acc: 0.5810\n",
      "Epoch 52/100\n",
      "934/934 [==============================] - 1s 960us/step - loss: 1.0365 - acc: 0.6156 - val_loss: 1.0692 - val_acc: 0.5761\n",
      "Epoch 53/100\n",
      "934/934 [==============================] - 1s 964us/step - loss: 1.0310 - acc: 0.6253 - val_loss: 1.0663 - val_acc: 0.5786\n",
      "Epoch 54/100\n",
      "934/934 [==============================] - 1s 974us/step - loss: 1.0291 - acc: 0.6071 - val_loss: 1.0541 - val_acc: 0.5860\n",
      "Epoch 55/100\n",
      "934/934 [==============================] - 1s 973us/step - loss: 1.0245 - acc: 0.6263 - val_loss: 1.0709 - val_acc: 0.5835\n",
      "Epoch 56/100\n",
      "934/934 [==============================] - 1s 969us/step - loss: 1.0185 - acc: 0.6253 - val_loss: 1.0561 - val_acc: 0.5835\n",
      "Epoch 57/100\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.0214 - acc: 0.6253 - val_loss: 1.0592 - val_acc: 0.5810\n",
      "Epoch 58/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.0213 - acc: 0.6188 - val_loss: 1.0623 - val_acc: 0.5810\n",
      "Epoch 59/100\n",
      "934/934 [==============================] - 1s 959us/step - loss: 1.0219 - acc: 0.6071 - val_loss: 1.0544 - val_acc: 0.5786\n",
      "Epoch 60/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.0191 - acc: 0.6274 - val_loss: 1.0543 - val_acc: 0.5786\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934/934 [==============================] - 1s 964us/step - loss: 1.0177 - acc: 0.6178 - val_loss: 1.0620 - val_acc: 0.5860\n",
      "Epoch 62/100\n",
      "934/934 [==============================] - 1s 960us/step - loss: 1.0128 - acc: 0.6274 - val_loss: 1.0570 - val_acc: 0.5935\n",
      "Epoch 63/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 1.0097 - acc: 0.6199 - val_loss: 1.0582 - val_acc: 0.5711\n",
      "Epoch 64/100\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.0093 - acc: 0.6285 - val_loss: 1.0620 - val_acc: 0.5810\n",
      "Epoch 65/100\n",
      "934/934 [==============================] - 1s 982us/step - loss: 1.0107 - acc: 0.6328 - val_loss: 1.0742 - val_acc: 0.5686\n",
      "Epoch 66/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.0052 - acc: 0.6360 - val_loss: 1.0608 - val_acc: 0.5786\n",
      "Epoch 67/100\n",
      "934/934 [==============================] - 1s 960us/step - loss: 1.0076 - acc: 0.6296 - val_loss: 1.0562 - val_acc: 0.5686\n",
      "Epoch 68/100\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.0058 - acc: 0.6296 - val_loss: 1.0505 - val_acc: 0.5835\n",
      "Epoch 69/100\n",
      "934/934 [==============================] - 1s 962us/step - loss: 1.0046 - acc: 0.6253 - val_loss: 1.0452 - val_acc: 0.5885\n",
      "Epoch 70/100\n",
      "934/934 [==============================] - 1s 986us/step - loss: 1.0032 - acc: 0.6242 - val_loss: 1.0472 - val_acc: 0.5910\n",
      "Epoch 71/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 1.0032 - acc: 0.6210 - val_loss: 1.0594 - val_acc: 0.5736\n",
      "Epoch 72/100\n",
      "934/934 [==============================] - 1s 997us/step - loss: 1.0016 - acc: 0.6263 - val_loss: 1.0437 - val_acc: 0.5935\n",
      "Epoch 73/100\n",
      "934/934 [==============================] - 1s 966us/step - loss: 1.0010 - acc: 0.6274 - val_loss: 1.0570 - val_acc: 0.5885\n",
      "Epoch 74/100\n",
      "934/934 [==============================] - 1s 961us/step - loss: 1.0007 - acc: 0.6274 - val_loss: 1.0430 - val_acc: 0.5935\n",
      "Epoch 75/100\n",
      "934/934 [==============================] - 1s 962us/step - loss: 0.9955 - acc: 0.6210 - val_loss: 1.0459 - val_acc: 0.5835\n",
      "Epoch 76/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 0.9977 - acc: 0.6231 - val_loss: 1.0483 - val_acc: 0.5810\n",
      "Epoch 77/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 0.9935 - acc: 0.6285 - val_loss: 1.0445 - val_acc: 0.5960\n",
      "Epoch 78/100\n",
      "934/934 [==============================] - 1s 964us/step - loss: 0.9921 - acc: 0.6167 - val_loss: 1.0424 - val_acc: 0.5935\n",
      "Epoch 79/100\n",
      "934/934 [==============================] - 1s 960us/step - loss: 0.9935 - acc: 0.6285 - val_loss: 1.0444 - val_acc: 0.5736\n",
      "Epoch 80/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 0.9910 - acc: 0.6274 - val_loss: 1.0412 - val_acc: 0.5910\n",
      "Epoch 81/100\n",
      "934/934 [==============================] - 1s 961us/step - loss: 0.9872 - acc: 0.6424 - val_loss: 1.0381 - val_acc: 0.6010\n",
      "Epoch 82/100\n",
      "934/934 [==============================] - 1s 963us/step - loss: 0.9890 - acc: 0.6146 - val_loss: 1.0492 - val_acc: 0.5736\n",
      "Epoch 83/100\n",
      "934/934 [==============================] - 1s 965us/step - loss: 0.9877 - acc: 0.6328 - val_loss: 1.0723 - val_acc: 0.5686\n",
      "Epoch 84/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9868 - acc: 0.6285 - val_loss: 1.0353 - val_acc: 0.5985\n",
      "Epoch 85/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9851 - acc: 0.6403 - val_loss: 1.0444 - val_acc: 0.5985\n",
      "Epoch 86/100\n",
      "934/934 [==============================] - 1s 986us/step - loss: 0.9861 - acc: 0.6274 - val_loss: 1.0392 - val_acc: 0.5761\n",
      "Epoch 87/100\n",
      "934/934 [==============================] - 1s 967us/step - loss: 0.9850 - acc: 0.6253 - val_loss: 1.0435 - val_acc: 0.5810\n",
      "Epoch 88/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9838 - acc: 0.6231 - val_loss: 1.0437 - val_acc: 0.5761\n",
      "Epoch 89/100\n",
      "934/934 [==============================] - 1s 975us/step - loss: 0.9795 - acc: 0.6338 - val_loss: 1.0549 - val_acc: 0.5686\n",
      "Epoch 90/100\n",
      "934/934 [==============================] - 1s 968us/step - loss: 0.9793 - acc: 0.6263 - val_loss: 1.0366 - val_acc: 0.5810\n",
      "Epoch 91/100\n",
      "934/934 [==============================] - 1s 974us/step - loss: 0.9821 - acc: 0.6253 - val_loss: 1.0347 - val_acc: 0.5910\n",
      "Epoch 92/100\n",
      "934/934 [==============================] - 1s 976us/step - loss: 0.9766 - acc: 0.6263 - val_loss: 1.0422 - val_acc: 0.6010\n",
      "Epoch 93/100\n",
      "934/934 [==============================] - 1s 997us/step - loss: 0.9812 - acc: 0.6370 - val_loss: 1.0356 - val_acc: 0.6035\n",
      "Epoch 94/100\n",
      "934/934 [==============================] - 1s 971us/step - loss: 0.9777 - acc: 0.6338 - val_loss: 1.0390 - val_acc: 0.5835\n",
      "Epoch 95/100\n",
      "934/934 [==============================] - 1s 971us/step - loss: 0.9772 - acc: 0.6338 - val_loss: 1.0443 - val_acc: 0.5786\n",
      "Epoch 96/100\n",
      "934/934 [==============================] - 1s 967us/step - loss: 0.9753 - acc: 0.6392 - val_loss: 1.0328 - val_acc: 0.6035\n",
      "Epoch 97/100\n",
      "934/934 [==============================] - 1s 968us/step - loss: 0.9726 - acc: 0.6381 - val_loss: 1.0510 - val_acc: 0.5636\n",
      "Epoch 98/100\n",
      "934/934 [==============================] - 1s 964us/step - loss: 0.9769 - acc: 0.6338 - val_loss: 1.0339 - val_acc: 0.5786\n",
      "Epoch 99/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9714 - acc: 0.6296 - val_loss: 1.0442 - val_acc: 0.5985\n",
      "Epoch 100/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.9736 - acc: 0.6263 - val_loss: 1.0290 - val_acc: 0.5960: 0s - loss: 0.9756 - acc: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 401 samples\n",
      "Epoch 1/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.9331 - acc: 0.2859 - val_loss: 1.7641 - val_acc: 0.2793\n",
      "Epoch 2/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7522 - acc: 0.2944 - val_loss: 1.7237 - val_acc: 0.3292\n",
      "Epoch 3/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7361 - acc: 0.2955 - val_loss: 1.7155 - val_acc: 0.2544\n",
      "Epoch 4/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7301 - acc: 0.3009 - val_loss: 1.7103 - val_acc: 0.3292\n",
      "Epoch 5/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7284 - acc: 0.3084 - val_loss: 1.7056 - val_acc: 0.3292\n",
      "Epoch 6/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7246 - acc: 0.2955 - val_loss: 1.7004 - val_acc: 0.3292\n",
      "Epoch 7/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7207 - acc: 0.3126 - val_loss: 1.6959 - val_acc: 0.3292\n",
      "Epoch 8/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7164 - acc: 0.3073 - val_loss: 1.6936 - val_acc: 0.2494\n",
      "Epoch 9/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7114 - acc: 0.2934 - val_loss: 1.6833 - val_acc: 0.3292\n",
      "Epoch 10/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7016 - acc: 0.3009 - val_loss: 1.6740 - val_acc: 0.3292\n",
      "Epoch 11/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6914 - acc: 0.3062 - val_loss: 1.6620 - val_acc: 0.3292\n",
      "Epoch 12/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6756 - acc: 0.3041 - val_loss: 1.6391 - val_acc: 0.3292\n",
      "Epoch 13/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6550 - acc: 0.3084 - val_loss: 1.6174 - val_acc: 0.3292\n",
      "Epoch 14/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6302 - acc: 0.3105 - val_loss: 1.5905 - val_acc: 0.3292\n",
      "Epoch 15/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6012 - acc: 0.3180 - val_loss: 1.5618 - val_acc: 0.2818\n",
      "Epoch 16/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.5724 - acc: 0.3084 - val_loss: 1.5312 - val_acc: 0.3666\n",
      "Epoch 17/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.5454 - acc: 0.3448 - val_loss: 1.5096 - val_acc: 0.3691\n",
      "Epoch 18/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.5232 - acc: 0.3651 - val_loss: 1.4928 - val_acc: 0.3791\n",
      "Epoch 19/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.5071 - acc: 0.3608 - val_loss: 1.4758 - val_acc: 0.3815\n",
      "Epoch 20/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4914 - acc: 0.3769 - val_loss: 1.4647 - val_acc: 0.3791\n",
      "Epoch 21/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4829 - acc: 0.3694 - val_loss: 1.4574 - val_acc: 0.3815\n",
      "Epoch 22/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4747 - acc: 0.3704 - val_loss: 1.4522 - val_acc: 0.4115\n",
      "Epoch 23/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4671 - acc: 0.3876 - val_loss: 1.4502 - val_acc: 0.4040\n",
      "Epoch 24/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4622 - acc: 0.3908 - val_loss: 1.4467 - val_acc: 0.3791\n",
      "Epoch 25/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4571 - acc: 0.3822 - val_loss: 1.4502 - val_acc: 0.3242\n",
      "Epoch 26/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4530 - acc: 0.3887 - val_loss: 1.4418 - val_acc: 0.4214\n",
      "Epoch 27/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4492 - acc: 0.3844 - val_loss: 1.4360 - val_acc: 0.4140\n",
      "Epoch 28/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4447 - acc: 0.3844 - val_loss: 1.4409 - val_acc: 0.4190\n",
      "Epoch 29/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4433 - acc: 0.3704 - val_loss: 1.4354 - val_acc: 0.4115\n",
      "Epoch 30/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4417 - acc: 0.3961 - val_loss: 1.4350 - val_acc: 0.4140\n",
      "Epoch 31/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4369 - acc: 0.4058 - val_loss: 1.4465 - val_acc: 0.3591\n",
      "Epoch 32/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4375 - acc: 0.3758 - val_loss: 1.4318 - val_acc: 0.4140\n",
      "Epoch 33/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4358 - acc: 0.3758 - val_loss: 1.4324 - val_acc: 0.3541\n",
      "Epoch 34/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4304 - acc: 0.4047 - val_loss: 1.4295 - val_acc: 0.4090\n",
      "Epoch 35/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4323 - acc: 0.3854 - val_loss: 1.4284 - val_acc: 0.4140\n",
      "Epoch 36/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4292 - acc: 0.3961 - val_loss: 1.4285 - val_acc: 0.4364\n",
      "Epoch 37/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4276 - acc: 0.3726 - val_loss: 1.4318 - val_acc: 0.4165\n",
      "Epoch 38/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4274 - acc: 0.3908 - val_loss: 1.4287 - val_acc: 0.4289\n",
      "Epoch 39/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4254 - acc: 0.3961 - val_loss: 1.4332 - val_acc: 0.3566\n",
      "Epoch 40/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4241 - acc: 0.3994 - val_loss: 1.4246 - val_acc: 0.4115\n",
      "Epoch 41/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4237 - acc: 0.3994 - val_loss: 1.4240 - val_acc: 0.4115\n",
      "Epoch 42/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4230 - acc: 0.3876 - val_loss: 1.4232 - val_acc: 0.4140\n",
      "Epoch 43/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4217 - acc: 0.3833 - val_loss: 1.4234 - val_acc: 0.4115\n",
      "Epoch 44/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4183 - acc: 0.4069 - val_loss: 1.4326 - val_acc: 0.3591\n",
      "Epoch 45/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4175 - acc: 0.4079 - val_loss: 1.4229 - val_acc: 0.4115\n",
      "Epoch 46/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4164 - acc: 0.3994 - val_loss: 1.4200 - val_acc: 0.4190\n",
      "Epoch 47/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4155 - acc: 0.3908 - val_loss: 1.4199 - val_acc: 0.3716\n",
      "Epoch 48/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4114 - acc: 0.4176 - val_loss: 1.4310 - val_acc: 0.3741\n",
      "Epoch 49/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4127 - acc: 0.4047 - val_loss: 1.4152 - val_acc: 0.4165\n",
      "Epoch 50/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4116 - acc: 0.4101 - val_loss: 1.4141 - val_acc: 0.4663\n",
      "Epoch 51/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4090 - acc: 0.3940 - val_loss: 1.4112 - val_acc: 0.4289\n",
      "Epoch 52/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4075 - acc: 0.4079 - val_loss: 1.4131 - val_acc: 0.3815\n",
      "Epoch 53/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4048 - acc: 0.4315 - val_loss: 1.4104 - val_acc: 0.3791\n",
      "Epoch 54/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4041 - acc: 0.4251 - val_loss: 1.4059 - val_acc: 0.4314\n",
      "Epoch 55/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4029 - acc: 0.4090 - val_loss: 1.4065 - val_acc: 0.4414\n",
      "Epoch 56/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4022 - acc: 0.4079 - val_loss: 1.4028 - val_acc: 0.4439\n",
      "Epoch 57/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4007 - acc: 0.4218 - val_loss: 1.4028 - val_acc: 0.3940\n",
      "Epoch 58/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3971 - acc: 0.4272 - val_loss: 1.3992 - val_acc: 0.4389\n",
      "Epoch 59/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3987 - acc: 0.4218 - val_loss: 1.3962 - val_acc: 0.4414\n",
      "Epoch 60/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3950 - acc: 0.4443 - val_loss: 1.3948 - val_acc: 0.4414\n",
      "Epoch 61/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3935 - acc: 0.4400 - val_loss: 1.3940 - val_acc: 0.4464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3905 - acc: 0.4400 - val_loss: 1.3987 - val_acc: 0.4140\n",
      "Epoch 63/100\n",
      "934/934 [==============================] - 1s 2ms/step - loss: 1.3892 - acc: 0.4604 - val_loss: 1.3908 - val_acc: 0.4489\n",
      "Epoch 64/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3897 - acc: 0.4368 - val_loss: 1.3906 - val_acc: 0.4514\n",
      "Epoch 65/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3868 - acc: 0.4261 - val_loss: 1.3900 - val_acc: 0.4564\n",
      "Epoch 66/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3846 - acc: 0.4497 - val_loss: 1.3939 - val_acc: 0.4040\n",
      "Epoch 67/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3813 - acc: 0.4465 - val_loss: 1.4005 - val_acc: 0.4015\n",
      "Epoch 68/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3837 - acc: 0.4315 - val_loss: 1.3868 - val_acc: 0.4638\n",
      "Epoch 69/100\n",
      "934/934 [==============================] - 1s 2ms/step - loss: 1.3805 - acc: 0.4400 - val_loss: 1.3863 - val_acc: 0.4539\n",
      "Epoch 70/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3766 - acc: 0.4283 - val_loss: 1.3848 - val_acc: 0.4564\n",
      "Epoch 71/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3770 - acc: 0.4475 - val_loss: 1.3830 - val_acc: 0.4564\n",
      "Epoch 72/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3712 - acc: 0.4497 - val_loss: 1.3870 - val_acc: 0.4564\n",
      "Epoch 73/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3717 - acc: 0.4433 - val_loss: 1.3866 - val_acc: 0.5012\n",
      "Epoch 74/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3708 - acc: 0.4465 - val_loss: 1.3893 - val_acc: 0.5012\n",
      "Epoch 75/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3691 - acc: 0.4507 - val_loss: 1.3845 - val_acc: 0.5012\n",
      "Epoch 76/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3661 - acc: 0.4443 - val_loss: 1.3853 - val_acc: 0.4638\n",
      "Epoch 77/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3651 - acc: 0.4636 - val_loss: 1.3903 - val_acc: 0.4364\n",
      "Epoch 78/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3613 - acc: 0.4593 - val_loss: 1.3867 - val_acc: 0.4289\n",
      "Epoch 79/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3628 - acc: 0.4400 - val_loss: 1.3815 - val_acc: 0.4713\n",
      "Epoch 80/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3575 - acc: 0.4668 - val_loss: 1.3831 - val_acc: 0.4688\n",
      "Epoch 81/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3582 - acc: 0.4529 - val_loss: 1.3844 - val_acc: 0.4339\n",
      "Epoch 82/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3567 - acc: 0.4679 - val_loss: 1.3832 - val_acc: 0.4763\n",
      "Epoch 83/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3554 - acc: 0.4722 - val_loss: 1.3804 - val_acc: 0.4988\n",
      "Epoch 84/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3517 - acc: 0.4722 - val_loss: 1.3808 - val_acc: 0.4564\n",
      "Epoch 85/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3523 - acc: 0.4572 - val_loss: 1.3784 - val_acc: 0.4988\n",
      "Epoch 86/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3498 - acc: 0.4540 - val_loss: 1.3781 - val_acc: 0.4663\n",
      "Epoch 87/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3484 - acc: 0.4743 - val_loss: 1.3806 - val_acc: 0.4663\n",
      "Epoch 88/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3481 - acc: 0.4657 - val_loss: 1.3794 - val_acc: 0.4713\n",
      "Epoch 89/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3471 - acc: 0.4743 - val_loss: 1.3803 - val_acc: 0.5062\n",
      "Epoch 90/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3442 - acc: 0.4700 - val_loss: 1.3784 - val_acc: 0.4439\n",
      "Epoch 91/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3430 - acc: 0.4604 - val_loss: 1.3858 - val_acc: 0.4314\n",
      "Epoch 92/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3408 - acc: 0.4732 - val_loss: 1.3791 - val_acc: 0.4738\n",
      "Epoch 93/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3417 - acc: 0.4754 - val_loss: 1.3749 - val_acc: 0.4938\n",
      "Epoch 94/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3389 - acc: 0.4700 - val_loss: 1.3776 - val_acc: 0.4414\n",
      "Epoch 95/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3363 - acc: 0.4914 - val_loss: 1.3832 - val_acc: 0.4289\n",
      "Epoch 96/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3377 - acc: 0.4818 - val_loss: 1.3705 - val_acc: 0.5012\n",
      "Epoch 97/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3341 - acc: 0.4722 - val_loss: 1.3781 - val_acc: 0.4813 - loss: 1.3211 - acc: 0.4\n",
      "Epoch 98/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3334 - acc: 0.4775 - val_loss: 1.3735 - val_acc: 0.4663ETA: 0s - loss: 1.2990 - acc: 0 - ETA: 0s - loss: 1.3230 - acc: \n",
      "Epoch 99/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3317 - acc: 0.4807 - val_loss: 1.3687 - val_acc: 0.5137\n",
      "Epoch 100/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3303 - acc: 0.4989 - val_loss: 1.3698 - val_acc: 0.5162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 401 samples\n",
      "Epoch 1/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.8507 - acc: 0.3073 - val_loss: 1.7370 - val_acc: 0.3317\n",
      "Epoch 2/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7431 - acc: 0.3009 - val_loss: 1.7138 - val_acc: 0.3292\n",
      "Epoch 3/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7374 - acc: 0.3041 - val_loss: 1.7144 - val_acc: 0.2793\n",
      "Epoch 4/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7304 - acc: 0.3105 - val_loss: 1.7087 - val_acc: 0.3292\n",
      "Epoch 5/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7322 - acc: 0.3084 - val_loss: 1.7062 - val_acc: 0.3292\n",
      "Epoch 6/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7290 - acc: 0.3073 - val_loss: 1.7079 - val_acc: 0.2793\n",
      "Epoch 7/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7235 - acc: 0.3169 - val_loss: 1.7174 - val_acc: 0.2793\n",
      "Epoch 8/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7260 - acc: 0.2966 - val_loss: 1.7040 - val_acc: 0.2793\n",
      "Epoch 9/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7236 - acc: 0.3041 - val_loss: 1.6973 - val_acc: 0.3292\n",
      "Epoch 10/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7195 - acc: 0.2987 - val_loss: 1.6988 - val_acc: 0.3292\n",
      "Epoch 11/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7171 - acc: 0.2955 - val_loss: 1.6907 - val_acc: 0.3292\n",
      "Epoch 12/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7118 - acc: 0.3105 - val_loss: 1.6948 - val_acc: 0.2768\n",
      "Epoch 13/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7054 - acc: 0.3062 - val_loss: 1.6778 - val_acc: 0.3292\n",
      "Epoch 14/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6951 - acc: 0.3223 - val_loss: 1.6769 - val_acc: 0.3042\n",
      "Epoch 15/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6856 - acc: 0.3158 - val_loss: 1.6538 - val_acc: 0.3292\n",
      "Epoch 16/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6684 - acc: 0.3340 - val_loss: 1.6560 - val_acc: 0.2793\n",
      "Epoch 17/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6507 - acc: 0.3405 - val_loss: 1.6131 - val_acc: 0.3491\n",
      "Epoch 18/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6215 - acc: 0.3415 - val_loss: 1.5853 - val_acc: 0.3416\n",
      "Epoch 19/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.5869 - acc: 0.3587 - val_loss: 1.5502 - val_acc: 0.3317\n",
      "Epoch 20/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.5471 - acc: 0.3876 - val_loss: 1.5364 - val_acc: 0.3416\n",
      "Epoch 21/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.5208 - acc: 0.4015 - val_loss: 1.4869 - val_acc: 0.3791\n",
      "Epoch 22/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4958 - acc: 0.4090 - val_loss: 1.4668 - val_acc: 0.3915\n",
      "Epoch 23/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4785 - acc: 0.3983 - val_loss: 1.4554 - val_acc: 0.3990\n",
      "Epoch 24/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4663 - acc: 0.3983 - val_loss: 1.4543 - val_acc: 0.3541\n",
      "Epoch 25/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4600 - acc: 0.3929 - val_loss: 1.4442 - val_acc: 0.3815\n",
      "Epoch 26/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4508 - acc: 0.4036 - val_loss: 1.4425 - val_acc: 0.3791\n",
      "Epoch 27/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4418 - acc: 0.3908 - val_loss: 1.4526 - val_acc: 0.3342\n",
      "Epoch 28/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4432 - acc: 0.4047 - val_loss: 1.4327 - val_acc: 0.4364\n",
      "Epoch 29/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4361 - acc: 0.4111 - val_loss: 1.4291 - val_acc: 0.4364\n",
      "Epoch 30/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4312 - acc: 0.4047 - val_loss: 1.4230 - val_acc: 0.4389\n",
      "Epoch 31/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4271 - acc: 0.4229 - val_loss: 1.4254 - val_acc: 0.3791\n",
      "Epoch 32/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4184 - acc: 0.4122 - val_loss: 1.4408 - val_acc: 0.3641\n",
      "Epoch 33/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4158 - acc: 0.4111 - val_loss: 1.4166 - val_acc: 0.4065\n",
      "Epoch 34/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4161 - acc: 0.4058 - val_loss: 1.4156 - val_acc: 0.4040\n",
      "Epoch 35/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4120 - acc: 0.4154 - val_loss: 1.4121 - val_acc: 0.4564\n",
      "Epoch 36/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4081 - acc: 0.4197 - val_loss: 1.4223 - val_acc: 0.3716\n",
      "Epoch 37/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4089 - acc: 0.4015 - val_loss: 1.4088 - val_acc: 0.4489\n",
      "Epoch 38/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4038 - acc: 0.4208 - val_loss: 1.4091 - val_acc: 0.4289\n",
      "Epoch 39/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4018 - acc: 0.4283 - val_loss: 1.4085 - val_acc: 0.3766\n",
      "Epoch 40/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3969 - acc: 0.3983 - val_loss: 1.4067 - val_acc: 0.4289\n",
      "Epoch 41/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3974 - acc: 0.4165 - val_loss: 1.3997 - val_acc: 0.4239\n",
      "Epoch 42/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3924 - acc: 0.4315 - val_loss: 1.4013 - val_acc: 0.4165\n",
      "Epoch 43/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3916 - acc: 0.4390 - val_loss: 1.4073 - val_acc: 0.3815\n",
      "Epoch 44/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3910 - acc: 0.4379 - val_loss: 1.3995 - val_acc: 0.3815\n",
      "Epoch 45/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.3868 - acc: 0.4358 - val_loss: 1.3987 - val_acc: 0.3865\n",
      "Epoch 46/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3836 - acc: 0.4165 - val_loss: 1.4059 - val_acc: 0.3890\n",
      "Epoch 47/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3857 - acc: 0.4272 - val_loss: 1.3901 - val_acc: 0.4289\n",
      "Epoch 48/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3838 - acc: 0.4143 - val_loss: 1.3917 - val_acc: 0.4713\n",
      "Epoch 49/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3816 - acc: 0.4336 - val_loss: 1.3872 - val_acc: 0.4339\n",
      "Epoch 50/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3795 - acc: 0.4411 - val_loss: 1.3873 - val_acc: 0.4339\n",
      "Epoch 51/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3793 - acc: 0.4443 - val_loss: 1.3866 - val_acc: 0.4439\n",
      "Epoch 52/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3756 - acc: 0.4400 - val_loss: 1.3927 - val_acc: 0.4564\n",
      "Epoch 53/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3761 - acc: 0.4497 - val_loss: 1.3835 - val_acc: 0.4813\n",
      "Epoch 54/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3720 - acc: 0.4486 - val_loss: 1.3997 - val_acc: 0.4264\n",
      "Epoch 55/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3730 - acc: 0.4529 - val_loss: 1.3804 - val_acc: 0.4439\n",
      "Epoch 56/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3688 - acc: 0.4422 - val_loss: 1.3906 - val_acc: 0.4414\n",
      "Epoch 57/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3671 - acc: 0.4497 - val_loss: 1.3770 - val_acc: 0.4439\n",
      "Epoch 58/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3685 - acc: 0.4625 - val_loss: 1.3763 - val_acc: 0.4514\n",
      "Epoch 59/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3653 - acc: 0.4582 - val_loss: 1.3778 - val_acc: 0.4539\n",
      "Epoch 60/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3632 - acc: 0.4475 - val_loss: 1.3849 - val_acc: 0.4090\n",
      "Epoch 61/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3613 - acc: 0.4657 - val_loss: 1.3724 - val_acc: 0.4963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3616 - acc: 0.4593 - val_loss: 1.3724 - val_acc: 0.4838\n",
      "Epoch 63/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3580 - acc: 0.4690 - val_loss: 1.3736 - val_acc: 0.4963\n",
      "Epoch 64/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3569 - acc: 0.4518 - val_loss: 1.3706 - val_acc: 0.4863\n",
      "Epoch 65/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3505 - acc: 0.4861 - val_loss: 1.3741 - val_acc: 0.4389\n",
      "Epoch 66/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3520 - acc: 0.4465 - val_loss: 1.3753 - val_acc: 0.5037\n",
      "Epoch 67/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3460 - acc: 0.4732 - val_loss: 1.3692 - val_acc: 0.4913\n",
      "Epoch 68/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3482 - acc: 0.4582 - val_loss: 1.3712 - val_acc: 0.4963\n",
      "Epoch 69/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3412 - acc: 0.4690 - val_loss: 1.3757 - val_acc: 0.4190\n",
      "Epoch 70/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3425 - acc: 0.4604 - val_loss: 1.3692 - val_acc: 0.4788\n",
      "Epoch 71/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3365 - acc: 0.4882 - val_loss: 1.3762 - val_acc: 0.4663\n",
      "Epoch 72/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3363 - acc: 0.4572 - val_loss: 1.3665 - val_acc: 0.4963\n",
      "Epoch 73/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3304 - acc: 0.4593 - val_loss: 1.3636 - val_acc: 0.5012\n",
      "Epoch 74/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3306 - acc: 0.4818 - val_loss: 1.3621 - val_acc: 0.4838s: 1.3267 - acc: 0.482\n",
      "Epoch 75/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3296 - acc: 0.4764 - val_loss: 1.3628 - val_acc: 0.5062\n",
      "Epoch 76/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3265 - acc: 0.4732 - val_loss: 1.3682 - val_acc: 0.4539\n",
      "Epoch 77/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3226 - acc: 0.4722 - val_loss: 1.3640 - val_acc: 0.4638\n",
      "Epoch 78/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3170 - acc: 0.4764 - val_loss: 1.3661 - val_acc: 0.4414\n",
      "Epoch 79/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3155 - acc: 0.4647 - val_loss: 1.3644 - val_acc: 0.5087\n",
      "Epoch 80/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3140 - acc: 0.4861 - val_loss: 1.3483 - val_acc: 0.5037\n",
      "Epoch 81/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3079 - acc: 0.4936 - val_loss: 1.3621 - val_acc: 0.4364\n",
      "Epoch 82/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3062 - acc: 0.4850 - val_loss: 1.3459 - val_acc: 0.5162\n",
      "Epoch 83/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3010 - acc: 0.4979 - val_loss: 1.3437 - val_acc: 0.4763\n",
      "Epoch 84/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2957 - acc: 0.5043 - val_loss: 1.3361 - val_acc: 0.4938\n",
      "Epoch 85/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2890 - acc: 0.4925 - val_loss: 1.3364 - val_acc: 0.4763\n",
      "Epoch 86/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2871 - acc: 0.4904 - val_loss: 1.3377 - val_acc: 0.4589\n",
      "Epoch 87/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2815 - acc: 0.5043 - val_loss: 1.3360 - val_acc: 0.5187\n",
      "Epoch 88/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2746 - acc: 0.5182 - val_loss: 1.3301 - val_acc: 0.4663\n",
      "Epoch 89/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2734 - acc: 0.4936 - val_loss: 1.3235 - val_acc: 0.5187\n",
      "Epoch 90/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2658 - acc: 0.5011 - val_loss: 1.3190 - val_acc: 0.4888\n",
      "Epoch 91/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2633 - acc: 0.5086 - val_loss: 1.3180 - val_acc: 0.5187\n",
      "Epoch 92/100\n",
      "934/934 [==============================] - 1s 2ms/step - loss: 1.2623 - acc: 0.5054 - val_loss: 1.3109 - val_acc: 0.5162\n",
      "Epoch 93/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2570 - acc: 0.5128 - val_loss: 1.3139 - val_acc: 0.4988\n",
      "Epoch 94/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2545 - acc: 0.4968 - val_loss: 1.3069 - val_acc: 0.5162\n",
      "Epoch 95/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2494 - acc: 0.5107 - val_loss: 1.3054 - val_acc: 0.4938\n",
      "Epoch 96/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2493 - acc: 0.5139 - val_loss: 1.3028 - val_acc: 0.4738\n",
      "Epoch 97/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2455 - acc: 0.5203 - val_loss: 1.3028 - val_acc: 0.4863\n",
      "Epoch 98/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2432 - acc: 0.5246 - val_loss: 1.2998 - val_acc: 0.5137\n",
      "Epoch 99/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.2404 - acc: 0.5118 - val_loss: 1.3010 - val_acc: 0.5112\n",
      "Epoch 100/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2389 - acc: 0.5310 - val_loss: 1.3028 - val_acc: 0.4788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 401 samples\n",
      "Epoch 1/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.7975 - acc: 0.2794 - val_loss: 1.7292 - val_acc: 0.2668\n",
      "Epoch 2/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7382 - acc: 0.3212 - val_loss: 1.7180 - val_acc: 0.2793\n",
      "Epoch 3/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7391 - acc: 0.3158 - val_loss: 1.7183 - val_acc: 0.3292\n",
      "Epoch 4/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7373 - acc: 0.3105 - val_loss: 1.7153 - val_acc: 0.3292\n",
      "Epoch 5/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7336 - acc: 0.3158 - val_loss: 1.7157 - val_acc: 0.3292\n",
      "Epoch 6/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7351 - acc: 0.3126 - val_loss: 1.7066 - val_acc: 0.3292\n",
      "Epoch 7/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7338 - acc: 0.2944 - val_loss: 1.7073 - val_acc: 0.3292\n",
      "Epoch 8/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7345 - acc: 0.2773 - val_loss: 1.7106 - val_acc: 0.32920s - loss: 1.7098 - acc: 0.2\n",
      "Epoch 9/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7330 - acc: 0.2901 - val_loss: 1.7069 - val_acc: 0.3292\n",
      "Epoch 10/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7301 - acc: 0.2901 - val_loss: 1.7042 - val_acc: 0.2793\n",
      "Epoch 11/100\n",
      "934/934 [==============================] - 1s 2ms/step - loss: 1.7281 - acc: 0.3073 - val_loss: 1.7020 - val_acc: 0.3292\n",
      "Epoch 12/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7271 - acc: 0.2934 - val_loss: 1.7054 - val_acc: 0.3267\n",
      "Epoch 13/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7249 - acc: 0.2891 - val_loss: 1.7006 - val_acc: 0.3292\n",
      "Epoch 14/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7204 - acc: 0.3051 - val_loss: 1.7089 - val_acc: 0.3292\n",
      "Epoch 15/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7198 - acc: 0.2901 - val_loss: 1.6925 - val_acc: 0.3292\n",
      "Epoch 16/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7107 - acc: 0.3255 - val_loss: 1.6977 - val_acc: 0.2793\n",
      "Epoch 17/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7080 - acc: 0.3062 - val_loss: 1.6798 - val_acc: 0.3292TA: 0s - loss: 1.6736 \n",
      "Epoch 18/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7001 - acc: 0.3041 - val_loss: 1.6777 - val_acc: 0.3192\n",
      "Epoch 19/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6876 - acc: 0.3137 - val_loss: 1.6568 - val_acc: 0.3292\n",
      "Epoch 20/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6710 - acc: 0.3212 - val_loss: 1.6412 - val_acc: 0.3292\n",
      "Epoch 21/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6500 - acc: 0.3319 - val_loss: 1.6134 - val_acc: 0.3392\n",
      "Epoch 22/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6239 - acc: 0.3576 - val_loss: 1.5869 - val_acc: 0.3641\n",
      "Epoch 23/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.5902 - acc: 0.3972 - val_loss: 1.5568 - val_acc: 0.3965\n",
      "Epoch 24/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.5592 - acc: 0.3983 - val_loss: 1.5237 - val_acc: 0.4115\n",
      "Epoch 25/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.5289 - acc: 0.4261 - val_loss: 1.5044 - val_acc: 0.4165\n",
      "Epoch 26/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.5002 - acc: 0.4133 - val_loss: 1.4657 - val_acc: 0.4165\n",
      "Epoch 27/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.4719 - acc: 0.4143 - val_loss: 1.4410 - val_acc: 0.4214\n",
      "Epoch 28/100\n",
      "934/934 [==============================] - 1s 2ms/step - loss: 1.4408 - acc: 0.4229 - val_loss: 1.4092 - val_acc: 0.4214\n",
      "Epoch 29/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.4060 - acc: 0.4443 - val_loss: 1.3878 - val_acc: 0.4738\n",
      "Epoch 30/100\n",
      "934/934 [==============================] - 1s 2ms/step - loss: 1.3731 - acc: 0.4764 - val_loss: 1.3354 - val_acc: 0.4863\n",
      "Epoch 31/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3375 - acc: 0.4872 - val_loss: 1.3033 - val_acc: 0.4938\n",
      "Epoch 32/100\n",
      "934/934 [==============================] - 1s 2ms/step - loss: 1.3076 - acc: 0.5043 - val_loss: 1.2706 - val_acc: 0.5012\n",
      "Epoch 33/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2851 - acc: 0.5150 - val_loss: 1.2536 - val_acc: 0.5037\n",
      "Epoch 34/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.2640 - acc: 0.5139 - val_loss: 1.2329 - val_acc: 0.5162\n",
      "Epoch 35/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.2488 - acc: 0.5128 - val_loss: 1.2219 - val_acc: 0.5187\n",
      "Epoch 36/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2353 - acc: 0.5214 - val_loss: 1.2167 - val_acc: 0.5187\n",
      "Epoch 37/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2243 - acc: 0.5236 - val_loss: 1.2137 - val_acc: 0.4963\n",
      "Epoch 38/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2139 - acc: 0.5171 - val_loss: 1.2037 - val_acc: 0.5137s - loss: 1.2139 - acc: 0.517\n",
      "Epoch 39/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2082 - acc: 0.5182 - val_loss: 1.1966 - val_acc: 0.5137\n",
      "Epoch 40/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2003 - acc: 0.5203 - val_loss: 1.1970 - val_acc: 0.5112\n",
      "Epoch 41/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1947 - acc: 0.5310 - val_loss: 1.1915 - val_acc: 0.5087\n",
      "Epoch 42/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1901 - acc: 0.5353 - val_loss: 1.1902 - val_acc: 0.5187\n",
      "Epoch 43/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1842 - acc: 0.5236 - val_loss: 1.2033 - val_acc: 0.4888\n",
      "Epoch 44/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1767 - acc: 0.5460 - val_loss: 1.1906 - val_acc: 0.5012\n",
      "Epoch 45/100\n",
      "934/934 [==============================] - 1s 2ms/step - loss: 1.1739 - acc: 0.5460 - val_loss: 1.1807 - val_acc: 0.5187\n",
      "Epoch 46/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.1719 - acc: 0.5310 - val_loss: 1.1784 - val_acc: 0.5212\n",
      "Epoch 47/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.1661 - acc: 0.5385 - val_loss: 1.1884 - val_acc: 0.5012\n",
      "Epoch 48/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1644 - acc: 0.5343 - val_loss: 1.1790 - val_acc: 0.5237\n",
      "Epoch 49/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1603 - acc: 0.5385 - val_loss: 1.1760 - val_acc: 0.5087\n",
      "Epoch 50/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1568 - acc: 0.5557 - val_loss: 1.1705 - val_acc: 0.5262\n",
      "Epoch 51/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1548 - acc: 0.5428 - val_loss: 1.1701 - val_acc: 0.5187\n",
      "Epoch 52/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1491 - acc: 0.5439 - val_loss: 1.1665 - val_acc: 0.5087\n",
      "Epoch 53/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1491 - acc: 0.5428 - val_loss: 1.1648 - val_acc: 0.5287\n",
      "Epoch 54/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1437 - acc: 0.5460 - val_loss: 1.1806 - val_acc: 0.5287\n",
      "Epoch 55/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1445 - acc: 0.5482 - val_loss: 1.1672 - val_acc: 0.5362\n",
      "Epoch 56/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1420 - acc: 0.5407 - val_loss: 1.1638 - val_acc: 0.5162\n",
      "Epoch 57/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1371 - acc: 0.5503 - val_loss: 1.1559 - val_acc: 0.5212\n",
      "Epoch 58/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1360 - acc: 0.5428 - val_loss: 1.1597 - val_acc: 0.5237\n",
      "Epoch 59/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1316 - acc: 0.5578 - val_loss: 1.1542 - val_acc: 0.5461\n",
      "Epoch 60/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1335 - acc: 0.5546 - val_loss: 1.1516 - val_acc: 0.5411\n",
      "Epoch 61/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1289 - acc: 0.5482 - val_loss: 1.1495 - val_acc: 0.5287\n",
      "Epoch 62/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1249 - acc: 0.5632 - val_loss: 1.1541 - val_acc: 0.5162\n",
      "Epoch 63/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1249 - acc: 0.5600 - val_loss: 1.1516 - val_acc: 0.5262\n",
      "Epoch 64/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1222 - acc: 0.5525 - val_loss: 1.1449 - val_acc: 0.5387\n",
      "Epoch 65/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1202 - acc: 0.5546 - val_loss: 1.1517 - val_acc: 0.5337\n",
      "Epoch 66/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1186 - acc: 0.5632 - val_loss: 1.1565 - val_acc: 0.5187s - loss: 1.1314 - acc: 0.5 - ETA: 0s - loss: 1.1266 - acc: 0.535 - ETA: 0s - loss: 1.1419 - acc: 0.5 - ETA: 0s - loss: 1.1308 - acc: 0.\n",
      "Epoch 67/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1185 - acc: 0.5642 - val_loss: 1.1438 - val_acc: 0.5312\n",
      "Epoch 68/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1162 - acc: 0.5557 - val_loss: 1.1395 - val_acc: 0.5237\n",
      "Epoch 69/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1140 - acc: 0.5418 - val_loss: 1.1451 - val_acc: 0.5387\n",
      "Epoch 70/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1136 - acc: 0.5600 - val_loss: 1.1423 - val_acc: 0.5312\n",
      "Epoch 71/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1120 - acc: 0.5653 - val_loss: 1.1345 - val_acc: 0.5337\n",
      "Epoch 72/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1073 - acc: 0.5675 - val_loss: 1.1421 - val_acc: 0.5212\n",
      "Epoch 73/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1052 - acc: 0.5621 - val_loss: 1.1426 - val_acc: 0.5237\n",
      "Epoch 74/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1023 - acc: 0.5664 - val_loss: 1.1616 - val_acc: 0.4938\n",
      "Epoch 75/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1031 - acc: 0.5664 - val_loss: 1.1346 - val_acc: 0.5362\n",
      "Epoch 76/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.1018 - acc: 0.5589 - val_loss: 1.1386 - val_acc: 0.5237\n",
      "Epoch 77/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1019 - acc: 0.5685 - val_loss: 1.1289 - val_acc: 0.5436\n",
      "Epoch 78/100\n",
      "934/934 [==============================] - 1s 2ms/step - loss: 1.0982 - acc: 0.5792 - val_loss: 1.1261 - val_acc: 0.5212\n",
      "Epoch 79/100\n",
      "934/934 [==============================] - 1s 2ms/step - loss: 1.0953 - acc: 0.5685 - val_loss: 1.1363 - val_acc: 0.5287\n",
      "Epoch 80/100\n",
      "934/934 [==============================] - 1s 2ms/step - loss: 1.0929 - acc: 0.5578 - val_loss: 1.1488 - val_acc: 0.5187\n",
      "Epoch 81/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0940 - acc: 0.5717 - val_loss: 1.1231 - val_acc: 0.5511\n",
      "Epoch 82/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0901 - acc: 0.5739 - val_loss: 1.1268 - val_acc: 0.5387\n",
      "Epoch 83/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0881 - acc: 0.5910 - val_loss: 1.1415 - val_acc: 0.5087\n",
      "Epoch 84/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0909 - acc: 0.5717 - val_loss: 1.1323 - val_acc: 0.5536\n",
      "Epoch 85/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0854 - acc: 0.5675 - val_loss: 1.1187 - val_acc: 0.5561\n",
      "Epoch 86/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0861 - acc: 0.5707 - val_loss: 1.1194 - val_acc: 0.5362\n",
      "Epoch 87/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0810 - acc: 0.5867 - val_loss: 1.1142 - val_acc: 0.5486\n",
      "Epoch 88/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0847 - acc: 0.5728 - val_loss: 1.1228 - val_acc: 0.5387\n",
      "Epoch 89/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0811 - acc: 0.5814 - val_loss: 1.1198 - val_acc: 0.5561\n",
      "Epoch 90/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0802 - acc: 0.5857 - val_loss: 1.1271 - val_acc: 0.5511\n",
      "Epoch 91/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0800 - acc: 0.5782 - val_loss: 1.1197 - val_acc: 0.5362\n",
      "Epoch 92/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0720 - acc: 0.5846 - val_loss: 1.1266 - val_acc: 0.5536\n",
      "Epoch 93/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0727 - acc: 0.5867 - val_loss: 1.1113 - val_acc: 0.5362\n",
      "Epoch 94/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0754 - acc: 0.5717 - val_loss: 1.1139 - val_acc: 0.5312\n",
      "Epoch 95/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0702 - acc: 0.5889 - val_loss: 1.1100 - val_acc: 0.5486\n",
      "Epoch 96/100\n",
      "934/934 [==============================] - 1s 2ms/step - loss: 1.0723 - acc: 0.5931 - val_loss: 1.1123 - val_acc: 0.5511\n",
      "Epoch 97/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0697 - acc: 0.6049 - val_loss: 1.1083 - val_acc: 0.5461\n",
      "Epoch 98/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0655 - acc: 0.5953 - val_loss: 1.1045 - val_acc: 0.5536\n",
      "Epoch 99/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0685 - acc: 0.5931 - val_loss: 1.1023 - val_acc: 0.5561\n",
      "Epoch 100/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0646 - acc: 0.5953 - val_loss: 1.1133 - val_acc: 0.5586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 401 samples\n",
      "Epoch 1/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.8143 - acc: 0.2752 - val_loss: 1.7337 - val_acc: 0.2793\n",
      "Epoch 2/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7400 - acc: 0.3009 - val_loss: 1.7217 - val_acc: 0.2793\n",
      "Epoch 3/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7375 - acc: 0.3019 - val_loss: 1.7076 - val_acc: 0.2768\n",
      "Epoch 4/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7304 - acc: 0.3084 - val_loss: 1.7066 - val_acc: 0.3292\n",
      "Epoch 5/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7299 - acc: 0.2859 - val_loss: 1.6999 - val_acc: 0.3292\n",
      "Epoch 6/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7244 - acc: 0.2827 - val_loss: 1.7026 - val_acc: 0.2793\n",
      "Epoch 7/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7180 - acc: 0.3041 - val_loss: 1.6946 - val_acc: 0.3292\n",
      "Epoch 8/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.7096 - acc: 0.2816 - val_loss: 1.6873 - val_acc: 0.2643\n",
      "Epoch 9/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6998 - acc: 0.2859 - val_loss: 1.6685 - val_acc: 0.3292\n",
      "Epoch 10/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6833 - acc: 0.2944 - val_loss: 1.6459 - val_acc: 0.3217\n",
      "Epoch 11/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6564 - acc: 0.3319 - val_loss: 1.6383 - val_acc: 0.3466\n",
      "Epoch 12/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.6261 - acc: 0.3672 - val_loss: 1.5823 - val_acc: 0.3940\n",
      "Epoch 13/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.5932 - acc: 0.3651 - val_loss: 1.5533 - val_acc: 0.4115\n",
      "Epoch 14/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.5607 - acc: 0.3790 - val_loss: 1.5162 - val_acc: 0.4165\n",
      "Epoch 15/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.5278 - acc: 0.3961 - val_loss: 1.4986 - val_acc: 0.3616\n",
      "Epoch 16/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.5017 - acc: 0.3844 - val_loss: 1.4609 - val_acc: 0.4190\n",
      "Epoch 17/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4785 - acc: 0.4015 - val_loss: 1.4465 - val_acc: 0.4165\n",
      "Epoch 18/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4570 - acc: 0.4154 - val_loss: 1.4260 - val_acc: 0.4389\n",
      "Epoch 19/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4365 - acc: 0.4101 - val_loss: 1.3997 - val_acc: 0.4838\n",
      "Epoch 20/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.4159 - acc: 0.4186 - val_loss: 1.3762 - val_acc: 0.5062\n",
      "Epoch 21/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3853 - acc: 0.4465 - val_loss: 1.3642 - val_acc: 0.4713\n",
      "Epoch 22/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3602 - acc: 0.4604 - val_loss: 1.3263 - val_acc: 0.5087\n",
      "Epoch 23/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3237 - acc: 0.4861 - val_loss: 1.3160 - val_acc: 0.4364\n",
      "Epoch 24/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.3078 - acc: 0.4722 - val_loss: 1.2724 - val_acc: 0.5337\n",
      "Epoch 25/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2849 - acc: 0.4615 - val_loss: 1.2533 - val_acc: 0.5012\n",
      "Epoch 26/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2638 - acc: 0.4732 - val_loss: 1.2358 - val_acc: 0.5062\n",
      "Epoch 27/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2490 - acc: 0.4839 - val_loss: 1.2264 - val_acc: 0.5012\n",
      "Epoch 28/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2347 - acc: 0.4839 - val_loss: 1.2116 - val_acc: 0.5262\n",
      "Epoch 29/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2235 - acc: 0.5000 - val_loss: 1.2142 - val_acc: 0.4838\n",
      "Epoch 30/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2129 - acc: 0.5021 - val_loss: 1.2121 - val_acc: 0.4638\n",
      "Epoch 31/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.2016 - acc: 0.5171 - val_loss: 1.1986 - val_acc: 0.4788\n",
      "Epoch 32/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1960 - acc: 0.5214 - val_loss: 1.1823 - val_acc: 0.5337\n",
      "Epoch 33/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1911 - acc: 0.5086 - val_loss: 1.1919 - val_acc: 0.4913\n",
      "Epoch 34/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1866 - acc: 0.5128 - val_loss: 1.1849 - val_acc: 0.5037\n",
      "Epoch 35/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1800 - acc: 0.5310 - val_loss: 1.1728 - val_acc: 0.5237\n",
      "Epoch 36/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1751 - acc: 0.5150 - val_loss: 1.1745 - val_acc: 0.5187\n",
      "Epoch 37/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1710 - acc: 0.5300 - val_loss: 1.1768 - val_acc: 0.5287\n",
      "Epoch 38/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1708 - acc: 0.5407 - val_loss: 1.1752 - val_acc: 0.5212\n",
      "Epoch 39/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1680 - acc: 0.5257 - val_loss: 1.1654 - val_acc: 0.5387\n",
      "Epoch 40/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1649 - acc: 0.5321 - val_loss: 1.1639 - val_acc: 0.5436\n",
      "Epoch 41/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1595 - acc: 0.5396 - val_loss: 1.1835 - val_acc: 0.5212\n",
      "Epoch 42/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1609 - acc: 0.5321 - val_loss: 1.1792 - val_acc: 0.5137\n",
      "Epoch 43/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1546 - acc: 0.5460 - val_loss: 1.1638 - val_acc: 0.5287\n",
      "Epoch 44/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1547 - acc: 0.5375 - val_loss: 1.1704 - val_acc: 0.5137\n",
      "Epoch 45/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1544 - acc: 0.5418 - val_loss: 1.1739 - val_acc: 0.5037\n",
      "Epoch 46/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1486 - acc: 0.5418 - val_loss: 1.1721 - val_acc: 0.5212\n",
      "Epoch 47/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1528 - acc: 0.5343 - val_loss: 1.1548 - val_acc: 0.5287TA: 0s - loss: 1.2353 - acc - ETA: 0s - loss: 1.1758 - acc: 0\n",
      "Epoch 48/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1495 - acc: 0.5385 - val_loss: 1.1571 - val_acc: 0.5337\n",
      "Epoch 49/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1477 - acc: 0.5418 - val_loss: 1.1559 - val_acc: 0.5312\n",
      "Epoch 50/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1416 - acc: 0.5460 - val_loss: 1.1568 - val_acc: 0.5162\n",
      "Epoch 51/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1429 - acc: 0.5428 - val_loss: 1.1576 - val_acc: 0.5187\n",
      "Epoch 52/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1406 - acc: 0.5471 - val_loss: 1.1558 - val_acc: 0.5312\n",
      "Epoch 53/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1429 - acc: 0.5343 - val_loss: 1.1516 - val_acc: 0.5262\n",
      "Epoch 54/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1334 - acc: 0.5482 - val_loss: 1.1595 - val_acc: 0.5312\n",
      "Epoch 55/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1387 - acc: 0.5460 - val_loss: 1.1516 - val_acc: 0.5337\n",
      "Epoch 56/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1341 - acc: 0.5535 - val_loss: 1.1437 - val_acc: 0.5362\n",
      "Epoch 57/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1346 - acc: 0.5332 - val_loss: 1.1520 - val_acc: 0.5312\n",
      "Epoch 58/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1307 - acc: 0.5482 - val_loss: 1.1510 - val_acc: 0.5411\n",
      "Epoch 59/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1286 - acc: 0.5557 - val_loss: 1.1596 - val_acc: 0.5461\n",
      "Epoch 60/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1295 - acc: 0.5632 - val_loss: 1.1491 - val_acc: 0.5461\n",
      "Epoch 61/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1248 - acc: 0.5525 - val_loss: 1.1497 - val_acc: 0.5237\n",
      "Epoch 62/100\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 1.1248 - acc: 0.5514 - val_loss: 1.1425 - val_acc: 0.5312\n",
      "Epoch 63/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1217 - acc: 0.5578 - val_loss: 1.1507 - val_acc: 0.5436\n",
      "Epoch 64/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1229 - acc: 0.5535 - val_loss: 1.1318 - val_acc: 0.5461\n",
      "Epoch 65/100\n",
      "934/934 [==============================] - 1s 2ms/step - loss: 1.1137 - acc: 0.5653 - val_loss: 1.1466 - val_acc: 0.5436\n",
      "Epoch 66/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1148 - acc: 0.5600 - val_loss: 1.1302 - val_acc: 0.5337\n",
      "Epoch 67/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1133 - acc: 0.5546 - val_loss: 1.1402 - val_acc: 0.5436\n",
      "Epoch 68/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1162 - acc: 0.5546 - val_loss: 1.1250 - val_acc: 0.5461\n",
      "Epoch 69/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1147 - acc: 0.5589 - val_loss: 1.1351 - val_acc: 0.5337\n",
      "Epoch 70/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1099 - acc: 0.5749 - val_loss: 1.1231 - val_acc: 0.5436\n",
      "Epoch 71/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1107 - acc: 0.5749 - val_loss: 1.1280 - val_acc: 0.5337\n",
      "Epoch 72/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1079 - acc: 0.5739 - val_loss: 1.1277 - val_acc: 0.5387\n",
      "Epoch 73/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1044 - acc: 0.5728 - val_loss: 1.1183 - val_acc: 0.5511\n",
      "Epoch 74/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1025 - acc: 0.5728 - val_loss: 1.1250 - val_acc: 0.5486\n",
      "Epoch 75/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1042 - acc: 0.5696 - val_loss: 1.1246 - val_acc: 0.5312\n",
      "Epoch 76/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.1003 - acc: 0.5760 - val_loss: 1.1145 - val_acc: 0.5411\n",
      "Epoch 77/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0995 - acc: 0.5782 - val_loss: 1.1141 - val_acc: 0.5511\n",
      "Epoch 78/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0968 - acc: 0.5835 - val_loss: 1.1068 - val_acc: 0.5536\n",
      "Epoch 79/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0950 - acc: 0.5835 - val_loss: 1.1175 - val_acc: 0.5511\n",
      "Epoch 80/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0901 - acc: 0.5878 - val_loss: 1.1153 - val_acc: 0.5636\n",
      "Epoch 81/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0900 - acc: 0.5814 - val_loss: 1.1093 - val_acc: 0.5436\n",
      "Epoch 82/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0884 - acc: 0.5803 - val_loss: 1.1087 - val_acc: 0.5611\n",
      "Epoch 83/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0865 - acc: 0.5942 - val_loss: 1.1076 - val_acc: 0.5661\n",
      "Epoch 84/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0828 - acc: 0.5814 - val_loss: 1.1041 - val_acc: 0.5436\n",
      "Epoch 85/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0820 - acc: 0.5846 - val_loss: 1.1025 - val_acc: 0.5611\n",
      "Epoch 86/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0818 - acc: 0.5889 - val_loss: 1.1009 - val_acc: 0.5686\n",
      "Epoch 87/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0777 - acc: 0.5931 - val_loss: 1.1071 - val_acc: 0.5312\n",
      "Epoch 88/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0787 - acc: 0.5996 - val_loss: 1.0995 - val_acc: 0.5486\n",
      "Epoch 89/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0740 - acc: 0.5867 - val_loss: 1.0944 - val_acc: 0.5636\n",
      "Epoch 90/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0746 - acc: 0.5931 - val_loss: 1.0956 - val_acc: 0.5511\n",
      "Epoch 91/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0722 - acc: 0.5942 - val_loss: 1.1040 - val_acc: 0.5586\n",
      "Epoch 92/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0719 - acc: 0.5964 - val_loss: 1.0938 - val_acc: 0.5736\n",
      "Epoch 93/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0694 - acc: 0.5974 - val_loss: 1.1067 - val_acc: 0.5611\n",
      "Epoch 94/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0681 - acc: 0.5964 - val_loss: 1.1021 - val_acc: 0.5661\n",
      "Epoch 95/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0659 - acc: 0.6006 - val_loss: 1.0935 - val_acc: 0.5611\n",
      "Epoch 96/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0636 - acc: 0.5942 - val_loss: 1.1029 - val_acc: 0.5486\n",
      "Epoch 97/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0630 - acc: 0.5985 - val_loss: 1.0835 - val_acc: 0.5686\n",
      "Epoch 98/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0566 - acc: 0.6049 - val_loss: 1.0838 - val_acc: 0.5561\n",
      "Epoch 99/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0557 - acc: 0.5985 - val_loss: 1.0803 - val_acc: 0.5636\n",
      "Epoch 100/100\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 1.0579 - acc: 0.5964 - val_loss: 1.0836 - val_acc: 0.5736\n"
     ]
    }
   ],
   "source": [
    "fnl_loss = {}\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        loss = ANN(grid[i,j][0],grid[i,j][1],X_tr,y_tr_class,X_te,y_te_class,100)\n",
    "        fnl_loss.update({str(grid[i,j]): loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[1 3]': 1.1128592935676438,\n",
       " '[1 6]': 1.0777995553880262,\n",
       " '[1 9]': 1.036334414759702,\n",
       " '[ 1 12]': 1.0172538856355626,\n",
       " '[2 3]': 1.1103506661264082,\n",
       " '[2 6]': 1.0792448195138775,\n",
       " '[2 9]': 1.0773173428867524,\n",
       " '[ 2 12]': 1.0289818542705211,\n",
       " '[3 3]': 1.3697657961946472,\n",
       " '[3 6]': 1.3027594449216886,\n",
       " '[3 9]': 1.1132501257662464,\n",
       " '[ 3 12]': 1.0836160527426109}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output, by comparing the losses, when there is 1 hidden layer with 4 nodes, the loss is the smallest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fnl = protein_new.iloc[:,1:-2].values\n",
    "y_fnl = protein_new.iloc[:,-1].values\n",
    "y_fnl_class = onehotencoder.fit_transform(np.array([y_fnl]).T).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fnl = Sequential()\n",
    "model_fnl.add(Dense(12, input_dim= X_fnl.shape[1], kernel_initializer='random_uniform',\n",
    "                bias_initializer='random_uniform',activation='sigmoid'))\n",
    "model_fnl.add(Dense(10, activation = \"softmax\"))\n",
    "model_fnl.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1335/1335 [==============================] - 2s 1ms/step - loss: 1.8094 - acc: 0.2981\n",
      "Epoch 2/200\n",
      "1335/1335 [==============================] - 1s 903us/step - loss: 1.7328 - acc: 0.3011\n",
      "Epoch 3/200\n",
      "1335/1335 [==============================] - 1s 913us/step - loss: 1.7272 - acc: 0.2929TA: 1s - loss\n",
      "Epoch 4/200\n",
      "1335/1335 [==============================] - 1s 895us/step - loss: 1.7212 - acc: 0.3131 0s - loss: 1.74\n",
      "Epoch 5/200\n",
      "1335/1335 [==============================] - 1s 881us/step - loss: 1.7162 - acc: 0.3011\n",
      "Epoch 6/200\n",
      "1335/1335 [==============================] - 1s 880us/step - loss: 1.7113 - acc: 0.3011\n",
      "Epoch 7/200\n",
      "1335/1335 [==============================] - 1s 887us/step - loss: 1.7079 - acc: 0.3004\n",
      "Epoch 8/200\n",
      "1335/1335 [==============================] - 1s 883us/step - loss: 1.6992 - acc: 0.3086\n",
      "Epoch 9/200\n",
      "1335/1335 [==============================] - 1s 903us/step - loss: 1.6929 - acc: 0.3064: 0s - loss: 1\n",
      "Epoch 10/200\n",
      "1335/1335 [==============================] - 1s 886us/step - loss: 1.6865 - acc: 0.3124\n",
      "Epoch 11/200\n",
      "1335/1335 [==============================] - 1s 886us/step - loss: 1.6763 - acc: 0.3221\n",
      "Epoch 12/200\n",
      "1335/1335 [==============================] - 1s 889us/step - loss: 1.6655 - acc: 0.3213\n",
      "Epoch 13/200\n",
      "1335/1335 [==============================] - 1s 903us/step - loss: 1.6569 - acc: 0.3199 0s - loss: 1.6618 - acc: 0 - ETA: 0s - loss: 1.6630 - acc: - ETA: 0s - loss: 1.6497 - acc: 0.322\n",
      "Epoch 14/200\n",
      "1335/1335 [==============================] - 1s 897us/step - loss: 1.6444 - acc: 0.3416\n",
      "Epoch 15/200\n",
      "1335/1335 [==============================] - 1s 884us/step - loss: 1.6326 - acc: 0.3363\n",
      "Epoch 16/200\n",
      "1335/1335 [==============================] - 1s 894us/step - loss: 1.6183 - acc: 0.3581\n",
      "Epoch 17/200\n",
      "1335/1335 [==============================] - 1s 897us/step - loss: 1.6057 - acc: 0.3753 0s - loss: 1.5999 - acc: 0.378\n",
      "Epoch 18/200\n",
      "1335/1335 [==============================] - 1s 887us/step - loss: 1.5923 - acc: 0.3813\n",
      "Epoch 19/200\n",
      "1335/1335 [==============================] - 1s 888us/step - loss: 1.5787 - acc: 0.4015\n",
      "Epoch 20/200\n",
      "1335/1335 [==============================] - 1s 882us/step - loss: 1.5642 - acc: 0.4037\n",
      "Epoch 21/200\n",
      "1335/1335 [==============================] - 1s 893us/step - loss: 1.5515 - acc: 0.4105\n",
      "Epoch 22/200\n",
      "1335/1335 [==============================] - 1s 895us/step - loss: 1.5379 - acc: 0.4165 0s - loss: 1.5188 - acc: 0.4\n",
      "Epoch 23/200\n",
      "1335/1335 [==============================] - 1s 899us/step - loss: 1.5284 - acc: 0.4112\n",
      "Epoch 24/200\n",
      "1335/1335 [==============================] - 1s 901us/step - loss: 1.5141 - acc: 0.4240\n",
      "Epoch 25/200\n",
      "1335/1335 [==============================] - 1s 886us/step - loss: 1.5024 - acc: 0.4232\n",
      "Epoch 26/200\n",
      "1335/1335 [==============================] - 1s 902us/step - loss: 1.4913 - acc: 0.4217\n",
      "Epoch 27/200\n",
      "1335/1335 [==============================] - 1s 892us/step - loss: 1.4816 - acc: 0.4187\n",
      "Epoch 28/200\n",
      "1335/1335 [==============================] - 1s 938us/step - loss: 1.4719 - acc: 0.4270\n",
      "Epoch 29/200\n",
      "1335/1335 [==============================] - 1s 900us/step - loss: 1.4613 - acc: 0.4165 0s - loss: 1.40 - ETA: 0s - loss: 1.4508 - acc: 0.42\n",
      "Epoch 30/200\n",
      "1335/1335 [==============================] - 1s 883us/step - loss: 1.4519 - acc: 0.4509\n",
      "Epoch 31/200\n",
      "1335/1335 [==============================] - 1s 892us/step - loss: 1.4420 - acc: 0.4427\n",
      "Epoch 32/200\n",
      "1335/1335 [==============================] - 1s 886us/step - loss: 1.4316 - acc: 0.4434 0s - loss: 1.4612 -\n",
      "Epoch 33/200\n",
      "1335/1335 [==============================] - 1s 886us/step - loss: 1.4230 - acc: 0.4300\n",
      "Epoch 34/200\n",
      "1335/1335 [==============================] - 1s 895us/step - loss: 1.4111 - acc: 0.4509\n",
      "Epoch 35/200\n",
      "1335/1335 [==============================] - 1s 881us/step - loss: 1.4035 - acc: 0.4419\n",
      "Epoch 36/200\n",
      "1335/1335 [==============================] - 1s 889us/step - loss: 1.3924 - acc: 0.4434\n",
      "Epoch 37/200\n",
      "1335/1335 [==============================] - 1s 884us/step - loss: 1.3817 - acc: 0.4502\n",
      "Epoch 38/200\n",
      "1335/1335 [==============================] - 1s 887us/step - loss: 1.3725 - acc: 0.4517\n",
      "Epoch 39/200\n",
      "1335/1335 [==============================] - 1s 901us/step - loss: 1.3644 - acc: 0.4562\n",
      "Epoch 40/200\n",
      "1335/1335 [==============================] - 1s 944us/step - loss: 1.3522 - acc: 0.4742\n",
      "Epoch 41/200\n",
      "1335/1335 [==============================] - 1s 959us/step - loss: 1.3464 - acc: 0.4727\n",
      "Epoch 42/200\n",
      "1335/1335 [==============================] - 1s 899us/step - loss: 1.3351 - acc: 0.4712\n",
      "Epoch 43/200\n",
      "1335/1335 [==============================] - 1s 897us/step - loss: 1.3238 - acc: 0.4816 0s - loss: 1.3424 -\n",
      "Epoch 44/200\n",
      "1335/1335 [==============================] - 1s 896us/step - loss: 1.3115 - acc: 0.4854 0s - loss: 1.3337 - a\n",
      "Epoch 45/200\n",
      "1335/1335 [==============================] - 1s 883us/step - loss: 1.3038 - acc: 0.4974\n",
      "Epoch 46/200\n",
      "1335/1335 [==============================] - 1s 895us/step - loss: 1.2932 - acc: 0.5041\n",
      "Epoch 47/200\n",
      "1335/1335 [==============================] - 1s 890us/step - loss: 1.2833 - acc: 0.5086 0s - loss: 1.2857 - acc: 0.508\n",
      "Epoch 48/200\n",
      "1335/1335 [==============================] - 1s 885us/step - loss: 1.2743 - acc: 0.5303\n",
      "Epoch 49/200\n",
      "1335/1335 [==============================] - 1s 905us/step - loss: 1.2695 - acc: 0.5169\n",
      "Epoch 50/200\n",
      "1335/1335 [==============================] - 1s 915us/step - loss: 1.2588 - acc: 0.5266\n",
      "Epoch 51/200\n",
      "1335/1335 [==============================] - 1s 895us/step - loss: 1.2524 - acc: 0.5288 0s - loss: 1.2510\n",
      "Epoch 52/200\n",
      "1335/1335 [==============================] - 1s 900us/step - loss: 1.2385 - acc: 0.5333 0s - loss: 1.2193 - acc: 0 - ETA: 0s - loss: 1.2221 - \n",
      "Epoch 53/200\n",
      "1335/1335 [==============================] - 1s 886us/step - loss: 1.2306 - acc: 0.5341\n",
      "Epoch 54/200\n",
      "1335/1335 [==============================] - 1s 902us/step - loss: 1.2291 - acc: 0.5371 0s - loss: 1.2\n",
      "Epoch 55/200\n",
      "1335/1335 [==============================] - 1s 881us/step - loss: 1.2204 - acc: 0.5416\n",
      "Epoch 56/200\n",
      "1335/1335 [==============================] - 1s 898us/step - loss: 1.2159 - acc: 0.5491\n",
      "Epoch 57/200\n",
      "1335/1335 [==============================] - 1s 895us/step - loss: 1.2099 - acc: 0.5513 0s - loss: 1.1860 \n",
      "Epoch 58/200\n",
      "1335/1335 [==============================] - 1s 924us/step - loss: 1.2021 - acc: 0.5446 0s - loss: 1.27\n",
      "Epoch 59/200\n",
      "1335/1335 [==============================] - 1s 950us/step - loss: 1.1961 - acc: 0.5491 0s - loss: 1.1766 - acc: 0\n",
      "Epoch 60/200\n",
      "1335/1335 [==============================] - 1s 1ms/step - loss: 1.1948 - acc: 0.5528\n",
      "Epoch 61/200\n",
      "1335/1335 [==============================] - 1s 904us/step - loss: 1.1869 - acc: 0.5558\n",
      "Epoch 62/200\n",
      "1335/1335 [==============================] - 1s 904us/step - loss: 1.1850 - acc: 0.5581: 0s - loss: 1\n",
      "Epoch 63/200\n",
      "1335/1335 [==============================] - 1s 900us/step - loss: 1.1771 - acc: 0.5581\n",
      "Epoch 64/200\n",
      "1335/1335 [==============================] - 1s 911us/step - loss: 1.1739 - acc: 0.5566: 0s - loss: \n",
      "Epoch 65/200\n",
      "1335/1335 [==============================] - 1s 889us/step - loss: 1.1696 - acc: 0.5625\n",
      "Epoch 66/200\n",
      "1335/1335 [==============================] - 1s 893us/step - loss: 1.1651 - acc: 0.5663\n",
      "Epoch 67/200\n",
      "1335/1335 [==============================] - 1s 893us/step - loss: 1.1613 - acc: 0.5618\n",
      "Epoch 68/200\n",
      "1335/1335 [==============================] - 1s 887us/step - loss: 1.1585 - acc: 0.5573\n",
      "Epoch 69/200\n",
      "1335/1335 [==============================] - 1s 895us/step - loss: 1.1552 - acc: 0.5655\n",
      "Epoch 70/200\n",
      "1335/1335 [==============================] - 1s 889us/step - loss: 1.1538 - acc: 0.5610 0s - loss: 1.1587 - acc: 0.5\n",
      "Epoch 71/200\n",
      "1335/1335 [==============================] - 1s 888us/step - loss: 1.1476 - acc: 0.5678\n",
      "Epoch 72/200\n",
      "1335/1335 [==============================] - 1s 899us/step - loss: 1.1449 - acc: 0.5648\n",
      "Epoch 73/200\n",
      "1335/1335 [==============================] - 1s 966us/step - loss: 1.1464 - acc: 0.5640: 1s - loss:\n",
      "Epoch 74/200\n",
      "1335/1335 [==============================] - 1s 900us/step - loss: 1.1403 - acc: 0.5633\n",
      "Epoch 75/200\n",
      "1335/1335 [==============================] - 1s 888us/step - loss: 1.1409 - acc: 0.5693\n",
      "Epoch 76/200\n",
      "1335/1335 [==============================] - 1s 880us/step - loss: 1.1348 - acc: 0.5655: 0s - loss: 1.11 - ETA: 0s - loss: 1.1319 - acc: 0.5\n",
      "Epoch 77/200\n",
      "1335/1335 [==============================] - 1s 826us/step - loss: 1.1364 - acc: 0.5753\n",
      "Epoch 78/200\n",
      "1335/1335 [==============================] - 1s 1ms/step - loss: 1.1300 - acc: 0.5685\n",
      "Epoch 79/200\n",
      "1335/1335 [==============================] - 1s 922us/step - loss: 1.1290 - acc: 0.5618 0s - loss: 1.1326 - acc: 0.558\n",
      "Epoch 80/200\n",
      "1335/1335 [==============================] - 1s 1ms/step - loss: 1.1284 - acc: 0.5813A: 0s - loss: 1.1153 - acc - ETA: 0s - loss: 1.1187 - acc\n",
      "Epoch 81/200\n",
      "1335/1335 [==============================] - 2s 2ms/step - loss: 1.1253 - acc: 0.5625\n",
      "Epoch 82/200\n",
      "1335/1335 [==============================] - 1s 1ms/step - loss: 1.1233 - acc: 0.5685\n",
      "Epoch 83/200\n",
      "1335/1335 [==============================] - 1s 1ms/step - loss: 1.1237 - acc: 0.5760\n",
      "Epoch 84/200\n",
      "1335/1335 [==============================] - 2s 1ms/step - loss: 1.1193 - acc: 0.5693A: 0s - loss: 1.16\n",
      "Epoch 85/200\n",
      "1335/1335 [==============================] - 1s 1ms/step - loss: 1.1215 - acc: 0.5730\n",
      "Epoch 86/200\n",
      "1335/1335 [==============================] - 1s 1ms/step - loss: 1.1173 - acc: 0.5610\n",
      "Epoch 87/200\n",
      "1335/1335 [==============================] - 1s 846us/step - loss: 1.1155 - acc: 0.5775\n",
      "Epoch 88/200\n",
      "1335/1335 [==============================] - 1s 827us/step - loss: 1.1136 - acc: 0.5670\n",
      "Epoch 89/200\n",
      "1335/1335 [==============================] - 1s 846us/step - loss: 1.1129 - acc: 0.5670\n",
      "Epoch 90/200\n",
      "1335/1335 [==============================] - 1s 859us/step - loss: 1.1119 - acc: 0.5760\n",
      "Epoch 91/200\n",
      "1335/1335 [==============================] - 1s 927us/step - loss: 1.1112 - acc: 0.5753\n",
      "Epoch 92/200\n",
      "1335/1335 [==============================] - 1s 1ms/step - loss: 1.1097 - acc: 0.5783\n",
      "Epoch 93/200\n",
      "1335/1335 [==============================] - 1s 1ms/step - loss: 1.1079 - acc: 0.5700\n",
      "Epoch 94/200\n",
      "1335/1335 [==============================] - 1s 882us/step - loss: 1.1062 - acc: 0.5708 0s - loss: 1.1047 - acc: 0.\n",
      "Epoch 95/200\n",
      "1335/1335 [==============================] - 1s 1ms/step - loss: 1.1048 - acc: 0.5775\n",
      "Epoch 96/200\n",
      "1335/1335 [==============================] - 1s 943us/step - loss: 1.1050 - acc: 0.5768\n",
      "Epoch 97/200\n",
      "1335/1335 [==============================] - 1s 950us/step - loss: 1.0998 - acc: 0.5693 0s - loss: 1.1061 - acc: 0.573 - ETA: 0s - loss: 1.0860\n",
      "Epoch 98/200\n",
      "1335/1335 [==============================] - 1s 1ms/step - loss: 1.1018 - acc: 0.5693\n",
      "Epoch 99/200\n",
      "1335/1335 [==============================] - 1s 921us/step - loss: 1.1010 - acc: 0.5708 0s - loss: 1.1145 \n",
      "Epoch 100/200\n",
      "1335/1335 [==============================] - 1s 876us/step - loss: 1.0980 - acc: 0.5738\n",
      "Epoch 101/200\n",
      "1335/1335 [==============================] - 1s 859us/step - loss: 1.0967 - acc: 0.5715 0s - loss: 1.0680 -\n",
      "Epoch 102/200\n",
      "1335/1335 [==============================] - 1s 848us/step - loss: 1.0994 - acc: 0.5670 0s - loss: 1.1091 - acc: \n",
      "Epoch 103/200\n",
      "1335/1335 [==============================] - 1s 847us/step - loss: 1.0917 - acc: 0.5783\n",
      "Epoch 104/200\n",
      "1335/1335 [==============================] - 1s 847us/step - loss: 1.0946 - acc: 0.5820 0s - loss: 1.0954 - acc: 0.57 - ETA: 0s - loss: 1.0736 - acc - ETA: 0s - loss: 1.0995 - acc: 0\n",
      "Epoch 105/200\n",
      "1335/1335 [==============================] - 1s 848us/step - loss: 1.0929 - acc: 0.5835\n",
      "Epoch 106/200\n",
      "1335/1335 [==============================] - 1s 846us/step - loss: 1.0905 - acc: 0.5753\n",
      "Epoch 107/200\n",
      "1335/1335 [==============================] - 1s 838us/step - loss: 1.0916 - acc: 0.5768\n",
      "Epoch 108/200\n",
      "1335/1335 [==============================] - 1s 843us/step - loss: 1.0916 - acc: 0.5798 0s - loss: 1.0927 - acc\n",
      "Epoch 109/200\n",
      "1335/1335 [==============================] - 1s 844us/step - loss: 1.0920 - acc: 0.5873\n",
      "Epoch 110/200\n",
      "1335/1335 [==============================] - 1s 851us/step - loss: 1.0866 - acc: 0.5918 0s - loss: 1.0819\n",
      "Epoch 111/200\n",
      "1335/1335 [==============================] - 1s 845us/step - loss: 1.0879 - acc: 0.5888\n",
      "Epoch 112/200\n",
      "1335/1335 [==============================] - 1s 843us/step - loss: 1.0870 - acc: 0.5828\n",
      "Epoch 113/200\n",
      "1335/1335 [==============================] - 1s 843us/step - loss: 1.0837 - acc: 0.5880 0s - loss: 1.0552 - \n",
      "Epoch 114/200\n",
      "1335/1335 [==============================] - 1s 855us/step - loss: 1.0854 - acc: 0.5858 0s - loss: 1.0755 - ETA: 0s - loss: 1.0811 - acc: 0.587\n",
      "Epoch 115/200\n",
      "1335/1335 [==============================] - 1s 844us/step - loss: 1.0830 - acc: 0.5963\n",
      "Epoch 116/200\n",
      "1335/1335 [==============================] - 1s 843us/step - loss: 1.0855 - acc: 0.5820\n",
      "Epoch 117/200\n",
      "1335/1335 [==============================] - 1s 844us/step - loss: 1.0849 - acc: 0.5783 0s - loss: 1.0882\n",
      "Epoch 118/200\n",
      "1335/1335 [==============================] - 1s 840us/step - loss: 1.0815 - acc: 0.5888\n",
      "Epoch 119/200\n",
      "1335/1335 [==============================] - 1s 847us/step - loss: 1.0815 - acc: 0.5948 0s - loss: 1.0\n",
      "Epoch 120/200\n",
      "1335/1335 [==============================] - 1s 841us/step - loss: 1.0815 - acc: 0.5858\n",
      "Epoch 121/200\n",
      "1335/1335 [==============================] - 1s 837us/step - loss: 1.0801 - acc: 0.5910\n",
      "Epoch 122/200\n",
      "1335/1335 [==============================] - 1s 843us/step - loss: 1.0784 - acc: 0.5783 0s - loss: 1.0559 -\n",
      "Epoch 123/200\n",
      "1335/1335 [==============================] - 1s 845us/step - loss: 1.0776 - acc: 0.5948\n",
      "Epoch 124/200\n",
      "1335/1335 [==============================] - 1s 846us/step - loss: 1.0800 - acc: 0.5888 0s - loss: 1.0870 - acc: 0.58\n",
      "Epoch 125/200\n",
      "1335/1335 [==============================] - 1s 838us/step - loss: 1.0743 - acc: 0.5805\n",
      "Epoch 126/200\n",
      "1335/1335 [==============================] - 1s 843us/step - loss: 1.0762 - acc: 0.5895\n",
      "Epoch 127/200\n",
      "1335/1335 [==============================] - 1s 843us/step - loss: 1.0756 - acc: 0.5888 0s - loss: 1.0497 - ac\n",
      "Epoch 128/200\n",
      "1335/1335 [==============================] - 1s 844us/step - loss: 1.0761 - acc: 0.5940\n",
      "Epoch 129/200\n",
      "1335/1335 [==============================] - 1s 847us/step - loss: 1.0725 - acc: 0.5955\n",
      "Epoch 130/200\n",
      "1335/1335 [==============================] - 1s 841us/step - loss: 1.0719 - acc: 0.5948\n",
      "Epoch 131/200\n",
      "1335/1335 [==============================] - 1s 842us/step - loss: 1.0714 - acc: 0.5940\n",
      "Epoch 132/200\n",
      "1335/1335 [==============================] - 1s 841us/step - loss: 1.0718 - acc: 0.5873\n",
      "Epoch 133/200\n",
      "1335/1335 [==============================] - 1s 858us/step - loss: 1.0728 - acc: 0.5865 0s - loss: 1.1298 \n",
      "Epoch 134/200\n",
      "1335/1335 [==============================] - 1s 845us/step - loss: 1.0683 - acc: 0.5858 0s - loss: 0.99\n",
      "Epoch 135/200\n",
      "1335/1335 [==============================] - 1s 851us/step - loss: 1.0695 - acc: 0.5880\n",
      "Epoch 136/200\n",
      "1335/1335 [==============================] - 1s 845us/step - loss: 1.0701 - acc: 0.5873 0s - loss: 1.0944 - ac\n",
      "Epoch 137/200\n",
      "1335/1335 [==============================] - 1s 847us/step - loss: 1.0683 - acc: 0.5925\n",
      "Epoch 138/200\n",
      "1335/1335 [==============================] - 1s 857us/step - loss: 1.0697 - acc: 0.5963\n",
      "Epoch 139/200\n",
      "1335/1335 [==============================] - 1s 846us/step - loss: 1.0650 - acc: 0.5970 0s - loss: 1.1126 -\n",
      "Epoch 140/200\n",
      "1335/1335 [==============================] - 1s 849us/step - loss: 1.0684 - acc: 0.5918\n",
      "Epoch 141/200\n",
      "1335/1335 [==============================] - 1s 840us/step - loss: 1.0673 - acc: 0.5933\n",
      "Epoch 142/200\n",
      "1335/1335 [==============================] - 1s 859us/step - loss: 1.0657 - acc: 0.5985\n",
      "Epoch 143/200\n",
      "1335/1335 [==============================] - 1s 844us/step - loss: 1.0632 - acc: 0.5925\n",
      "Epoch 144/200\n",
      "1335/1335 [==============================] - 1s 874us/step - loss: 1.0667 - acc: 0.5910\n",
      "Epoch 145/200\n",
      "1335/1335 [==============================] - 2s 1ms/step - loss: 1.0644 - acc: 0.6007\n",
      "Epoch 146/200\n",
      "1335/1335 [==============================] - 1s 1ms/step - loss: 1.0594 - acc: 0.6030\n",
      "Epoch 147/200\n",
      "1335/1335 [==============================] - 1s 1ms/step - loss: 1.0630 - acc: 0.5910\n",
      "Epoch 148/200\n",
      "1335/1335 [==============================] - 1s 931us/step - loss: 1.0610 - acc: 0.5970 0s - loss: 1.099\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1335/1335 [==============================] - 1s 847us/step - loss: 1.0606 - acc: 0.5858\n",
      "Epoch 150/200\n",
      "1335/1335 [==============================] - 1s 814us/step - loss: 1.0643 - acc: 0.5925 0s - loss: 1.0660 - acc: 0.590\n",
      "Epoch 151/200\n",
      "1335/1335 [==============================] - 1s 828us/step - loss: 1.0589 - acc: 0.6075\n",
      "Epoch 152/200\n",
      "1335/1335 [==============================] - 1s 813us/step - loss: 1.0607 - acc: 0.5903\n",
      "Epoch 153/200\n",
      "1335/1335 [==============================] - 1s 817us/step - loss: 1.0606 - acc: 0.5948\n",
      "Epoch 154/200\n",
      "1335/1335 [==============================] - 1s 826us/step - loss: 1.0616 - acc: 0.5835\n",
      "Epoch 155/200\n",
      "1335/1335 [==============================] - 1s 806us/step - loss: 1.0602 - acc: 0.5948 0s - loss: 1.0508\n",
      "Epoch 156/200\n",
      "1335/1335 [==============================] - 1s 805us/step - loss: 1.0614 - acc: 0.5813\n",
      "Epoch 157/200\n",
      "1335/1335 [==============================] - 1s 806us/step - loss: 1.0582 - acc: 0.5940\n",
      "Epoch 158/200\n",
      "1335/1335 [==============================] - 1s 841us/step - loss: 1.0585 - acc: 0.5978\n",
      "Epoch 159/200\n",
      "1335/1335 [==============================] - 1s 829us/step - loss: 1.0580 - acc: 0.6007\n",
      "Epoch 160/200\n",
      "1335/1335 [==============================] - 1s 816us/step - loss: 1.0605 - acc: 0.6022\n",
      "Epoch 161/200\n",
      "1335/1335 [==============================] - 1s 808us/step - loss: 1.0578 - acc: 0.5948\n",
      "Epoch 162/200\n",
      "1335/1335 [==============================] - 1s 826us/step - loss: 1.0599 - acc: 0.5985\n",
      "Epoch 163/200\n",
      "1335/1335 [==============================] - 1s 810us/step - loss: 1.0555 - acc: 0.6015\n",
      "Epoch 164/200\n",
      "1335/1335 [==============================] - 1s 868us/step - loss: 1.0595 - acc: 0.5903\n",
      "Epoch 165/200\n",
      "1335/1335 [==============================] - 1s 867us/step - loss: 1.0541 - acc: 0.5963\n",
      "Epoch 166/200\n",
      "1335/1335 [==============================] - 1s 867us/step - loss: 1.0576 - acc: 0.5948 0s - loss: 1.03\n",
      "Epoch 167/200\n",
      "1335/1335 [==============================] - 1s 977us/step - loss: 1.0546 - acc: 0.6037\n",
      "Epoch 168/200\n",
      "1335/1335 [==============================] - 1s 967us/step - loss: 1.0577 - acc: 0.5888\n",
      "Epoch 169/200\n",
      "1335/1335 [==============================] - 1s 1ms/step - loss: 1.0536 - acc: 0.5940\n",
      "Epoch 170/200\n",
      "1335/1335 [==============================] - 1s 915us/step - loss: 1.0527 - acc: 0.5835\n",
      "Epoch 171/200\n",
      "1335/1335 [==============================] - 1s 1ms/step - loss: 1.0525 - acc: 0.5910A: 0s - loss: 1.0391 - acc: 0 - ETA: 0s - loss: 1.0447 - acc: 0.59\n",
      "Epoch 172/200\n",
      "1335/1335 [==============================] - 1s 856us/step - loss: 1.0559 - acc: 0.6022\n",
      "Epoch 173/200\n",
      "1335/1335 [==============================] - 1s 843us/step - loss: 1.0553 - acc: 0.5948\n",
      "Epoch 174/200\n",
      "1335/1335 [==============================] - 1s 842us/step - loss: 1.0535 - acc: 0.6045 0s - loss: 1.0322 - acc: 0\n",
      "Epoch 175/200\n",
      "1335/1335 [==============================] - 1s 848us/step - loss: 1.0533 - acc: 0.5970 0s - loss: 1.074\n",
      "Epoch 176/200\n",
      "1335/1335 [==============================] - 1s 854us/step - loss: 1.0508 - acc: 0.5888\n",
      "Epoch 177/200\n",
      "1335/1335 [==============================] - 1s 842us/step - loss: 1.0523 - acc: 0.6060\n",
      "Epoch 178/200\n",
      "1335/1335 [==============================] - 1s 840us/step - loss: 1.0484 - acc: 0.5918 0s - loss: 1.0519 - acc: 0.59\n",
      "Epoch 179/200\n",
      "1335/1335 [==============================] - 1s 847us/step - loss: 1.0520 - acc: 0.5895\n",
      "Epoch 180/200\n",
      "1335/1335 [==============================] - 1s 878us/step - loss: 1.0525 - acc: 0.6000 0s - loss: 1.0475 - acc: 0.6\n",
      "Epoch 181/200\n",
      "1335/1335 [==============================] - 1s 851us/step - loss: 1.0508 - acc: 0.6015\n",
      "Epoch 182/200\n",
      "1335/1335 [==============================] - 1s 846us/step - loss: 1.0523 - acc: 0.5963 0s - loss: 1.0087 - acc: 0.603 - ETA: 0s - loss: 1.0014 -\n",
      "Epoch 183/200\n",
      "1335/1335 [==============================] - 1s 844us/step - loss: 1.0527 - acc: 0.5925 0s - loss: 1.\n",
      "Epoch 184/200\n",
      "1335/1335 [==============================] - 1s 852us/step - loss: 1.0512 - acc: 0.6105\n",
      "Epoch 185/200\n",
      "1335/1335 [==============================] - 1s 841us/step - loss: 1.0541 - acc: 0.5880\n",
      "Epoch 186/200\n",
      "1335/1335 [==============================] - 1s 843us/step - loss: 1.0518 - acc: 0.6022 0s - loss: 1.0770 - ac\n",
      "Epoch 187/200\n",
      "1335/1335 [==============================] - 1s 849us/step - loss: 1.0511 - acc: 0.6060 0s - loss: 1.0849 - acc: 0.6 - ETA: 0s - loss: 1.0795 - a - ETA: 0s - loss: 1.0575 - acc: 0.\n",
      "Epoch 188/200\n",
      "1335/1335 [==============================] - 1s 840us/step - loss: 1.0507 - acc: 0.5963\n",
      "Epoch 189/200\n",
      "1335/1335 [==============================] - 1s 854us/step - loss: 1.0496 - acc: 0.6000 0s - loss: 1.\n",
      "Epoch 190/200\n",
      "1335/1335 [==============================] - 1s 887us/step - loss: 1.0493 - acc: 0.5955\n",
      "Epoch 191/200\n",
      "1335/1335 [==============================] - 1s 842us/step - loss: 1.0497 - acc: 0.5955 0s - loss: 1.0271 \n",
      "Epoch 192/200\n",
      "1335/1335 [==============================] - 1s 849us/step - loss: 1.0461 - acc: 0.6030\n",
      "Epoch 193/200\n",
      "1335/1335 [==============================] - 1s 840us/step - loss: 1.0527 - acc: 0.5865\n",
      "Epoch 194/200\n",
      "1335/1335 [==============================] - 1s 842us/step - loss: 1.0465 - acc: 0.5948\n",
      "Epoch 195/200\n",
      "1335/1335 [==============================] - 1s 842us/step - loss: 1.0493 - acc: 0.5948\n",
      "Epoch 196/200\n",
      "1335/1335 [==============================] - 1s 845us/step - loss: 1.0482 - acc: 0.5955 0s - loss: 1.0681\n",
      "Epoch 197/200\n",
      "1335/1335 [==============================] - 1s 847us/step - loss: 1.0493 - acc: 0.6022 0s - loss: 1.0307 - acc:\n",
      "Epoch 198/200\n",
      "1335/1335 [==============================] - 1s 841us/step - loss: 1.0471 - acc: 0.5955\n",
      "Epoch 199/200\n",
      "1335/1335 [==============================] - 1s 842us/step - loss: 1.0495 - acc: 0.5940\n",
      "Epoch 200/200\n",
      "1335/1335 [==============================] - 1s 977us/step - loss: 1.0497 - acc: 0.5940\n"
     ]
    }
   ],
   "source": [
    "model_fnl_hist = model_fnl.fit(X_fnl, y_fnl_class, \n",
    "                  batch_size = 1, nb_epoch = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new instance where we do not know the answer\n",
    "Xnew = np.array([[0.52,0.47,0.52,0.23,0.55,0.03,0.52,0.39]])\n",
    "#Xnew = sc.transform(Xnew)\n",
    "# make a prediction\n",
    "ynew = model_fnl.predict_classes(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NUC'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein.loc[protein['y'] == ynew[0], 'class'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.052622576071689"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fnl_hist.history['loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
